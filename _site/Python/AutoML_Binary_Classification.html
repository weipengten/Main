<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.555">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ten Wei Peng">
<meta name="dcterms.date" content="2024-08-02">
<meta name="description" content="Automated Machine Learning (In-Progress)">

<title>Wei Peng’s Analytics Journey - AutoML for Binary Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Wei Peng’s Analytics Journey</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-rstudio" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">RStudio</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-rstudio">    
        <li>
    <a class="dropdown-item" href="../RStudio/Geospatial_Analytics/Analyzing_Bus_Traffic_Flows/Analyzing_Bus_Traffic_Flows.html">
 <span class="dropdown-text">Analyzing Bus Traffic Flows in Singapore</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../RStudio/Visual_Analytics/Creating_Better_Visualisations/Creating_Better_Visualisations.html">
 <span class="dropdown-text">Creating Better Visualisations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../RStudio/Geospatial_Analytics/Unveiling_spatio_temporal_mobility_patterns/Unveiling_spatio_temporal_mobility_patterns.html">
 <span class="dropdown-text">Unveiling spatial and spatio-temporal mobility patterns</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-tableau" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Tableau</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-tableau">    
        <li>
    <a class="dropdown-item" href="../Tableau/Quarterly_Private_Residential_Property_Watcher.html">
 <span class="dropdown-text">Quarterly Private Residential Property Watcher</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Tableau/Mapping_In_Tableau.html">
 <span class="dropdown-text">Mapping In Tableau</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Tableau/Bullet_Graph_and_Sparkline.html">
 <span class="dropdown-text">Bullet Graph and Sparkline</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-python" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Python</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-python">    
        <li>
    <a class="dropdown-item" href="../Python/ImageLearningCifar10.html">
 <span class="dropdown-text">Image Learning on CIFAR-10</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Python/AutoML_Binary_Classification.html">
 <span class="dropdown-text">AutoML for Binary Classification</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/weipengten"> <i class="bi bi-linkedin" role="img" aria-label="Linkedin">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/weipengten"> <i class="bi bi-github" role="img" aria-label="Github">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="3">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#context" id="toc-context" class="nav-link" data-scroll-target="#context">Context</a></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology">Methodology</a></li>
  <li><a href="#importing-libraries" id="toc-importing-libraries" class="nav-link" data-scroll-target="#importing-libraries">Importing Libraries</a></li>
  <li><a href="#load-the-dataset" id="toc-load-the-dataset" class="nav-link" data-scroll-target="#load-the-dataset">Load the Dataset</a></li>
  <li><a href="#data-cleaning" id="toc-data-cleaning" class="nav-link" data-scroll-target="#data-cleaning">Data Cleaning</a>
  <ul class="collapse">
  <li><a href="#replace-missing-values-with-nan" id="toc-replace-missing-values-with-nan" class="nav-link" data-scroll-target="#replace-missing-values-with-nan">Replace missing values with nan</a></li>
  <li><a href="#string-formatting" id="toc-string-formatting" class="nav-link" data-scroll-target="#string-formatting">String formatting</a></li>
  <li><a href="#replace-missing-values-with-nan-1" id="toc-replace-missing-values-with-nan-1" class="nav-link" data-scroll-target="#replace-missing-values-with-nan-1">Replace missing values with nan</a></li>
  <li><a href="#create-bins-for-age-as-age_bins" id="toc-create-bins-for-age-as-age_bins" class="nav-link" data-scroll-target="#create-bins-for-age-as-age_bins">Create bins for age as age_bins</a></li>
  <li><a href="#create-bins-for-rcri_score-as-rcri_bin" id="toc-create-bins-for-rcri_score-as-rcri_bin" class="nav-link" data-scroll-target="#create-bins-for-rcri_score-as-rcri_bin">Create bins for rcri_score as rcri_bin</a></li>
  <li><a href="#drop-rows-with-at-least-10-missing-values-in-columns-93.73-remaining" id="toc-drop-rows-with-at-least-10-missing-values-in-columns-93.73-remaining" class="nav-link" data-scroll-target="#drop-rows-with-at-least-10-missing-values-in-columns-93.73-remaining">Drop rows with at least 10 missing values in columns, 93.73% remaining</a></li>
  <li><a href="#numerical-columns-remaining-columns-except-for-daysbetweendeathandoperation-impute-missing-values-with-median" id="toc-numerical-columns-remaining-columns-except-for-daysbetweendeathandoperation-impute-missing-values-with-median" class="nav-link" data-scroll-target="#numerical-columns-remaining-columns-except-for-daysbetweendeathandoperation-impute-missing-values-with-median">NUMERICAL columns (remaining columns except for DaysbetweenDeathandoperation): impute missing values with median)</a></li>
  <li><a href="#categorical-columns-remaining-columns-except-for-mortality-daysbetweendeathandoperation-30daymortality-thirtydaymortality-impute-missing-values-with-none" id="toc-categorical-columns-remaining-columns-except-for-mortality-daysbetweendeathandoperation-30daymortality-thirtydaymortality-impute-missing-values-with-none" class="nav-link" data-scroll-target="#categorical-columns-remaining-columns-except-for-mortality-daysbetweendeathandoperation-30daymortality-thirtydaymortality-impute-missing-values-with-none">CATEGORICAL columns (remaining columns except for <span class="citation" data-cites="30daymortality">['mortality', 'daysbetweendeathandoperation', ' @30daymortality', 'thirtydaymortality']</span>): impute missing values with ‘None’</a></li>
  <li><a href="#frame-the-problem" id="toc-frame-the-problem" class="nav-link" data-scroll-target="#frame-the-problem">1. Frame the Problem</a></li>
  <li><a href="#data-sensing-preprocessing" id="toc-data-sensing-preprocessing" class="nav-link" data-scroll-target="#data-sensing-preprocessing">2. Data sensing, preprocessing:</a></li>
  <li><a href="#data-wrangling-transformation" id="toc-data-wrangling-transformation" class="nav-link" data-scroll-target="#data-wrangling-transformation">3. Data Wrangling, Transformation:</a></li>
  <li><a href="#in-depth-analysis-staistical-modelling-machine-learning" id="toc-in-depth-analysis-staistical-modelling-machine-learning" class="nav-link" data-scroll-target="#in-depth-analysis-staistical-modelling-machine-learning">4. In-depth analysis: Staistical modelling / Machine Learning</a></li>
  <li><a href="#comparison-and-evaluation-automate-the-evaluation-process" id="toc-comparison-and-evaluation-automate-the-evaluation-process" class="nav-link" data-scroll-target="#comparison-and-evaluation-automate-the-evaluation-process">5. Comparison and Evaluation: Automate the evaluation process</a></li>
  <li><a href="#tuning-model-to-industry-and-domain-knowledge-avoiding-false-negatives" id="toc-tuning-model-to-industry-and-domain-knowledge-avoiding-false-negatives" class="nav-link" data-scroll-target="#tuning-model-to-industry-and-domain-knowledge-avoiding-false-negatives">6. Tuning Model to industry and domain knowledge: avoiding false negatives</a></li>
  <li><a href="#model-evaluation-summary" id="toc-model-evaluation-summary" class="nav-link" data-scroll-target="#model-evaluation-summary">7. Model Evaluation Summary</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">AutoML for Binary Classification</h1>
</div>

<div>
  <div class="description">
    Automated Machine Learning (In-Progress)
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ten Wei Peng </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 2, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p><img src="images/Capture.PNG" class="img-fluid"></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Hello everyone, this post is intended to demonstrate how it is possible to automate some of the evaluation process in deciding which machine learning models to utilise to achieve the best desired results, which is commonly know as <strong>AutoML.</strong></p>
<p>I was intrigued that such a thing was possible and couldn’t wait to try it, here’s an attempt on my version of AutoML for a Binary Classification Model. Going forward, i would like to automate more of the common decision-making processes like pre-processing that is in tune with domain knowledge.</p>
<p><code>Changelog:</code></p>
<p><code>\[1.0.0\] - 2024-08-02 - Initial deployment after consolidating course work and initial refinement.</code></p>
<p><code>\[1.0.1\] - 2024-09-01 - Added Context, Logistic Regression, Fine-tuned Models, Evaluation of Results for Multivariate Analysis, Logistic Regression, Machine Learning Predictions</code></p>
</section>
<section id="context" class="level2">
<h2 class="anchored" data-anchor-id="context">Context</h2>
<p>Predicting surgical risks is crucial for enhancing patient safety and improving surgical outcomes by allowing healthcare providers to tailor care and allocate resources effectively.</p>
<p>By using real-world EMR data from obtained from Chan et al.&nbsp;(2018) [1], we aim to evaluate risk factors and develop predictive models to predict the following outcome: <strong>mortality within 30 days</strong>.</p>
</section>
<section id="methodology" class="level2">
<h2 class="anchored" data-anchor-id="methodology">Methodology</h2>
<p>The obtained data set includes 90,785 surgery patients (excluded Cardiac and Neurosurgery patients) from Singapore General Hospital from 1 January 2012 to 31 October 2016. For each outcome, we developed a respective multivariate model to evaluate the risks factors and test out different machine learning model to see which model best predict the outcome.</p>
</section>
<section id="importing-libraries" class="level2">
<h2 class="anchored" data-anchor-id="importing-libraries">Importing Libraries</h2>
<div id="a50b9300" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Importing necessary libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas.api.types <span class="im">import</span> CategoricalDtype</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputerfrom scipy.stats <span class="im">import</span> skew</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> PowerTransformer, QuantileTransformer,StandardScaler, MinMaxScaler</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split,RepeatedStratifiedKFold</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> label_binarize,LabelEncoder</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_score, recall_score, classification_report, confusion_matrix, roc_curve, auc</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.combine <span class="im">import</span> SMOTEENN</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skopt <span class="im">import</span> BayesSearchCV</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> skopt.space <span class="im">import</span> Real, Categorical, Integer</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lightgbm <span class="im">import</span> LGBMClassifier</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.outliers_influence <span class="im">import</span> variance_inflation_factor</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.tools.tools <span class="im">import</span> add_constant</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="load-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="load-the-dataset">Load the Dataset</h2>
<p>This Python code snippet uses TensorFlow’s Keras API to load the CIFAR-10 dataset and print the shapes of the training and test sets. The CIFAR-10 dataset is a popular dataset used for training machine learning and computer vision algorithms. It consists of 60,000 32x32 color images in 10 different classes, with 6,000 images per class.</p>
<div id="3c2574a1" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">'https://raw.githubusercontent.com/weipengten/ISSS623GroupProject--Applied-Healthcare-/main/CARES_data.xlsx'</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_excel(url, index_col<span class="op">=</span><span class="st">'Indexno'</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.shape)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-2209450693.png" class="img-fluid"></p>
</section>
<section id="data-cleaning" class="level2">
<h2 class="anchored" data-anchor-id="data-cleaning">Data Cleaning</h2>
<ul>
<li><p>Replace missing values with nan</p></li>
<li><p>String formatting</p></li>
<li><p>Create bins for age as age_bins</p></li>
<li><p>Create bins for rcri_score as rcri_bin</p></li>
<li><p>Drop rows with at least 10 missing values in columns, 93.73% remaining</p></li>
<li><p>NUMERICAL columns (remaining columns except for DaysbetweenDeathandoperation): impute missing values with median</p></li>
<li><p>CATEGORICAL columns (remaining columns except for [‘mortality’, ‘daysbetweendeathandoperation’, ‘@30daymortality’, ‘thirtydaymortality’]): impute missing values with ‘None’</p></li>
</ul>
<section id="replace-missing-values-with-nan" class="level3">
<h3 class="anchored" data-anchor-id="replace-missing-values-with-nan">Replace missing values with nan</h3>
<div id="223c521c" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># replace missing values with pd.NA</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>null_values <span class="op">=</span> [<span class="st">'#NULL!'</span>, <span class="st">'BLANK'</span>, <span class="st">'none'</span>, <span class="st">'NA'</span>, <span class="st">'&lt;NA&gt;'</span>, <span class="st">'None'</span>]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>df.replace(null_values, np.nan, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># check data types and missing values</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-4006132243.png" class="img-fluid"></p>
<div id="c95b81c9" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># statistical summary</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-62069690.png" class="img-fluid"></p>
</section>
<section id="string-formatting" class="level3">
<h3 class="anchored" data-anchor-id="string-formatting">String formatting</h3>
<div id="c00a64a9" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># replace all column names with lowercase and replace spaces with underscores</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df.columns <span class="op">=</span> df.columns.<span class="bu">str</span>.lower().<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># replace all string values in the DataFrame with lowercase</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.applymap(<span class="kw">lambda</span> x: x.lower() <span class="cf">if</span> <span class="bu">isinstance</span>(x, <span class="bu">str</span>) <span class="cf">else</span> x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="replace-missing-values-with-nan-1" class="level3">
<h3 class="anchored" data-anchor-id="replace-missing-values-with-nan-1">Replace missing values with nan</h3>
<div id="e73a9667" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># replace missing values with pd.NA</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>null_values <span class="op">=</span> [<span class="st">'#NULL!'</span>, <span class="st">'BLANK'</span>, <span class="st">'none'</span>, <span class="st">'NA'</span>, <span class="st">'&lt;NA&gt;'</span>, <span class="st">'None'</span>]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>df.replace(null_values, np.nan, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># check data types and missing values</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-263768488.png" class="img-fluid"></p>
<section id="check-potential-duplicates" class="level4">
<h4 class="anchored" data-anchor-id="check-potential-duplicates">Check potential duplicates</h4>
<div id="dc9a26e9" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check potential duplicates</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>df.duplicated().<span class="bu">sum</span>()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># We will not drop duplicates in this dataste as</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># they represent multiple legitimate entries representing different patients</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-1862191658.png" class="img-fluid"></p>
</section>
<section id="find-all-unique-values-for-categorical-features" class="level4">
<h4 class="anchored" data-anchor-id="find-all-unique-values-for-categorical-features">Find all unique values for categorical features</h4>
<div id="3a69aef7" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># find all unique values for categorical features</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> column <span class="kw">in</span> df.select_dtypes(include<span class="op">=</span>[<span class="st">'object'</span>]).columns:</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>column<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>df[column]<span class="sc">.</span>unique()<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-3989827221.png" class="img-fluid"></p>
</section>
</section>
<section id="create-bins-for-age-as-age_bins" class="level3">
<h3 class="anchored" data-anchor-id="create-bins-for-age-as-age_bins">Create bins for age as age_bins</h3>
<div id="0a218e75" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># bin the age column</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>age_bins <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">60</span>, <span class="dv">70</span>, <span class="dv">80</span>, <span class="dv">90</span>, <span class="dv">100</span>, <span class="dv">110</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>age_labels <span class="op">=</span> [<span class="st">'0-10'</span>, <span class="st">'11-20'</span>, <span class="st">'21-30'</span>, <span class="st">'31-40'</span>, <span class="st">'41-50'</span>, <span class="st">'51-60'</span>, <span class="st">'61-70'</span>, <span class="st">'71-80'</span>, <span class="st">'81-90'</span>, <span class="st">'91-100'</span>, <span class="st">'101-110'</span>]</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'age_binned'</span>] <span class="op">=</span> pd.cut(df[<span class="st">'age'</span>], bins<span class="op">=</span>age_bins, labels<span class="op">=</span>age_labels, right<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize frequency counts</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>age_binned_counts <span class="op">=</span> df[<span class="st">'age_binned'</span>].value_counts().sort_index()</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(age_binned_counts, <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>age_binned_counts.index, y<span class="op">=</span>age_binned_counts.values, palette<span class="op">=</span><span class="st">"viridis"</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Age Bins'</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Frequency of Age Bins'</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'age_binned'</span>] <span class="op">=</span> df[<span class="st">'age_binned'</span>].astype(<span class="st">'object'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-3669474606.png" class="img-fluid"></p>
</section>
<section id="create-bins-for-rcri_score-as-rcri_bin" class="level3">
<h3 class="anchored" data-anchor-id="create-bins-for-rcri_score-as-rcri_bin">Create bins for rcri_score as rcri_bin</h3>
<div id="eef910bf" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to bin 'RCRI score' into distinct ordinal categories</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> smart_binning(df, column_name, bin_column_name):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a copy of the DataFrame to avoid modifying the original</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    _df <span class="op">=</span> df.copy()</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a mapping for the bins, including a label for NaN values</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    bin_labels <span class="op">=</span> {<span class="dv">1</span>: <span class="st">'1'</span>, <span class="dv">2</span>: <span class="st">'2'</span>, <span class="dv">3</span>: <span class="st">'3'</span>, <span class="dv">4</span>: <span class="st">'4'</span>, <span class="dv">5</span>: <span class="st">'5'</span>, <span class="dv">6</span>: <span class="st">'6'</span>}</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    _df[bin_column_name] <span class="op">=</span> _df[column_name].<span class="bu">map</span>(bin_labels)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle NaN values by assigning them to a specific category</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    _df[bin_column_name] <span class="op">=</span> _df[bin_column_name].fillna(<span class="st">'No_RCRI'</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define the categorical type with ordered categories, including 'No_RCRI'</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    cat_type <span class="op">=</span> CategoricalDtype(categories<span class="op">=</span>[<span class="st">'1'</span>, <span class="st">'2'</span>, <span class="st">'3'</span>, <span class="st">'4'</span>, <span class="st">'5'</span>, <span class="st">'6'</span>, <span class="st">'No_RCRI'</span>], ordered<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert the new bin column to categorical type</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    _df[bin_column_name] <span class="op">=</span> _df[bin_column_name].astype(cat_type)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> _df</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the smart binning function</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> smart_binning(df, <span class="st">'rcri_score'</span>, <span class="st">'rcri_bin'</span>)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if the rcri_bin column is ordinal</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">isinstance</span>(df[<span class="st">'rcri_bin'</span>].dtype, CategoricalDtype) <span class="kw">and</span> df[<span class="st">'rcri_bin'</span>].dtype.ordered:</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"rcri_bin is ordinal."</span>)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"rcri_bin is not ordinal."</span>)</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the categories and their order</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Categories and order:"</span>, df[<span class="st">'rcri_bin'</span>].dtype.categories)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the distribution of data in 'rcri_bin'</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The distribution of data in 'rcri_bin' is as follows:</span><span class="ch">\n</span><span class="sc">{</span>df[<span class="st">'rcri_bin'</span>]<span class="sc">.</span>value_counts()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'rcri_bin'</span>] <span class="op">=</span> df[<span class="st">'rcri_bin'</span>].astype(<span class="st">'object'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-393517675.png" class="img-fluid"></p>
<section id="visualize-correlation-for-numerical-column" class="level4">
<h4 class="anchored" data-anchor-id="visualize-correlation-for-numerical-column">Visualize correlation for numerical column</h4>
<div id="1e4aff92" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>correlation_matrix <span class="op">=</span> df.select_dtypes(include<span class="op">=</span>[<span class="st">'number'</span>]).corr()</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>fontsize<span class="op">=</span><span class="dv">8</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">6</span>))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>sns.heatmap(correlation_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.2f'</span>, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, cbar<span class="op">=</span><span class="va">True</span>, annot_kws<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">8</span>})</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Correlation Matrix for Numerical Columns'</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span>fontsize)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span>fontsize)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-2942571460.png" class="img-fluid"></p>
</section>
</section>
<section id="drop-rows-with-at-least-10-missing-values-in-columns-93.73-remaining" class="level3">
<h3 class="anchored" data-anchor-id="drop-rows-with-at-least-10-missing-values-in-columns-93.73-remaining">Drop rows with at least 10 missing values in columns, 93.73% remaining</h3>
<div id="c8c98f3b" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define the threshold for missing values</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>missing_counts <span class="op">=</span> df.isna().<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the percentage of rows to keep</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>percentage_remaining <span class="op">=</span> <span class="bu">round</span>((df[missing_counts <span class="op">&lt;</span> threshold].shape[<span class="dv">0</span>] <span class="op">/</span> df.shape[<span class="dv">0</span>]) <span class="op">*</span> <span class="dv">100</span>, <span class="dv">2</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Percentage of rows with fewer than </span><span class="sc">{</span>threshold<span class="sc">}</span><span class="ss"> missing values: </span><span class="sc">{</span>percentage_remaining<span class="sc">}</span><span class="ss">%"</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop rows with at least the specified number of missing values</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[missing_counts <span class="op">&lt;</span> threshold]</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-2865351042.png" class="img-fluid"></p>
<section id="data-validation" class="level4">
<h4 class="anchored" data-anchor-id="data-validation">Data Validation</h4>
<div id="6564b7f0" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the condition</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>condition_check <span class="op">=</span> df[df[<span class="st">'thirtydaymortality'</span>] <span class="op">==</span> <span class="va">True</span>][<span class="st">'mortality'</span>] <span class="op">==</span> <span class="va">True</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify if all values meet the condition</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> condition_check.<span class="bu">all</span>():</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'----------------------------------------'</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"All instances where 'thirtydaymortality' is True, 'mortality' is also True."</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Data validation step 1, there's no logical errors found for mortality and thirtydaymortality"</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'----------------------------------------'</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"There are instances where 'thirtydaymortality' is True but 'mortality' is not True."</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Data validation:</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'mortality'</span> <span class="kw">in</span> df.columns <span class="kw">and</span> <span class="st">'daysbetweendeathandoperation'</span> <span class="kw">in</span> df.columns:</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check the conditions</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    condition_1 <span class="op">=</span> df.loc[df[<span class="st">'mortality'</span>] <span class="op">==</span> <span class="va">True</span>, <span class="st">'daysbetweendeathandoperation'</span>].notnull().<span class="bu">all</span>()</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    condition_2 <span class="op">=</span> df.loc[df[<span class="st">'mortality'</span>] <span class="op">==</span> <span class="va">False</span>, <span class="st">'daysbetweendeathandoperation'</span>].isnull().<span class="bu">all</span>()</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print the results</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'----------------------------------------'</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Condition 1 met:"</span>, condition_1)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Condition 2 met:"</span>, condition_2)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Data validation step 2, there's no logical errors found for mortality and daysbetweendeathandoperation"</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'----------------------------------------'</span>)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"The DataFrame does not contain the required columns."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-2261022608.png" class="img-fluid"></p>
</section>
<section id="outlier-detection-for-numerical-features" class="level4">
<h4 class="anchored" data-anchor-id="outlier-detection-for-numerical-features">Outlier detection for numerical features</h4>
<div id="ea7ab691" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>numerical_columns <span class="op">=</span> df.select_dtypes(include<span class="op">=</span>[<span class="st">'number'</span>]).columns</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Numerical columns:"</span>, numerical_columns)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">10</span>))</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, column <span class="kw">in</span> <span class="bu">enumerate</span>(numerical_columns, <span class="dv">1</span>):</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">4</span>, i)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    sns.boxplot(y<span class="op">=</span>df[column])</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    plt.title(column)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="images/clipboard-884694652.png"></a></p>
</section>
</section>
<section id="numerical-columns-remaining-columns-except-for-daysbetweendeathandoperation-impute-missing-values-with-median" class="level3">
<h3 class="anchored" data-anchor-id="numerical-columns-remaining-columns-except-for-daysbetweendeathandoperation-impute-missing-values-with-median">NUMERICAL columns (remaining columns except for DaysbetweenDeathandoperation): impute missing values with median)</h3>
<div id="88f9d5e3" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize SimpleImputer to fill missing values with the median</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>imp <span class="op">=</span> SimpleImputer(missing_values<span class="op">=</span>np.nan, strategy<span class="op">=</span><span class="st">'median'</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># List all numeric columns in the DataFrame</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>numeric_columns <span class="op">=</span> df.select_dtypes(include<span class="op">=</span>[<span class="st">'number'</span>]).columns</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Numeric columns:"</span>, <span class="bu">list</span>(numeric_columns))  <span class="co"># we have also checked that all the numerical columns are correct, no binary variables are mistakenly treated as numeric variables.</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define specific numeric columns for imputation</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>numeric_cols <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> numeric_columns <span class="cf">if</span> col <span class="op">!=</span> <span class="st">'daysbetweendeathandoperation'</span>]</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Numeric columns:"</span>, <span class="bu">list</span>(numeric_cols))</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the imputer on the specified numeric columns</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>imp.fit(df[numeric_cols])</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform the specified numeric columns by imputing missing values with the median</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>df[numeric_cols] <span class="op">=</span> imp.transform(df[numeric_cols])</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure the columns are of float32 type</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>df[numeric_cols] <span class="op">=</span> df[numeric_cols].astype(np.float32)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the DataFrame with imputed data to verify the changes</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"DataFrame with imputed numeric columns:"</span>)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[numeric_cols])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-3764274460.png" class="img-fluid"></p>
</section>
<section id="categorical-columns-remaining-columns-except-for-mortality-daysbetweendeathandoperation-30daymortality-thirtydaymortality-impute-missing-values-with-none" class="level3">
<h3 class="anchored" data-anchor-id="categorical-columns-remaining-columns-except-for-mortality-daysbetweendeathandoperation-30daymortality-thirtydaymortality-impute-missing-values-with-none">CATEGORICAL columns (remaining columns except for <span class="citation" data-cites="30daymortality">['mortality', 'daysbetweendeathandoperation', ' @30daymortality', 'thirtydaymortality']</span>): impute missing values with ‘None’</h3>
<div id="fd525c40" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize SimpleImputer for categorical columns to fill missing values with 'None'</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>cat_imp <span class="op">=</span> SimpleImputer(missing_values<span class="op">=</span>np.nan, strategy<span class="op">=</span><span class="st">'constant'</span>, fill_value<span class="op">=</span><span class="st">'None'</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># List all categorical columns in the DataFrame</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>categorical_columns  <span class="op">=</span> df.select_dtypes(include<span class="op">=</span>[<span class="st">'object'</span>]).columns</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Categorical columns:"</span>, <span class="bu">list</span>(categorical_columns))</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Columns to exclude</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>exclude_columns <span class="op">=</span> [<span class="st">'mortality'</span>, <span class="st">'daysbetweendeathandoperation'</span>, <span class="st">'@30daymortality'</span>, <span class="st">'thirtydaymortality'</span>]</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out the excluded columns from the list of categorical columns</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>categorical_columns <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> categorical_columns <span class="cf">if</span> col <span class="kw">not</span> <span class="kw">in</span> exclude_columns]</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the imputer on the categorical columns</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>cat_imp.fit(df[categorical_columns])</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform the categorical columns by imputing missing values with 'None'</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>df[categorical_columns] <span class="op">=</span> cat_imp.transform(df[categorical_columns])</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="co"># find all unique values for categorical features</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> column <span class="kw">in</span> df.select_dtypes(include<span class="op">=</span>[<span class="st">'object'</span>]).columns:</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>column<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>df[column]<span class="sc">.</span>unique()<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="images/clipboard-692645940.png"></a>Outcome 1: Mortality within 30 days (thirtydaymortality)</p>
</section>
<section id="frame-the-problem" class="level3">
<h3 class="anchored" data-anchor-id="frame-the-problem">1. Frame the Problem</h3>
<ul>
<li><p>Target variable: thirtydaymortality</p></li>
<li><p>Type: Classification Problem</p></li>
<li><p>Binary Outcome: (No,Yes)</p></li>
</ul>
</section>
<section id="data-sensing-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="data-sensing-preprocessing">2. Data sensing, preprocessing:</h3>
<ul>
<li><p><code>Feature Selection:</code> Exclusion of variables that deomonstrates high redundancy or Multicollinearity with thirtydaymortality:</p>
<ul>
<li><p>@30daymortality</p></li>
<li><p>mortality</p></li>
<li><p>daysbetweendeathandoperation</p></li>
</ul></li>
</ul>
<div id="2ba4645d" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature Selection:</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># drop unecessary columns, features that occur only after the target result should be excluded</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>features_to_exclude <span class="op">=</span> [<span class="st">'mortality'</span>, <span class="st">'daysbetweendeathandoperation'</span>, <span class="st">'@30daymortality'</span>]</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(columns<span class="op">=</span>features_to_exclude)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="data-wrangling-transformation" class="level3">
<h3 class="anchored" data-anchor-id="data-wrangling-transformation">3. Data Wrangling, Transformation:</h3>
<p>Numerical features Transformation:</p>
<ul>
<li><p>Test for normality of numeric columns: ALL are not normally distributed</p></li>
<li><p>DIstribution transfomation for columns</p></li>
<li><p>Distribution normalisation and standardisation for columns</p></li>
</ul>
<p>Cateogorical features Transformation:</p>
<ul>
<li>One-hot encoding to ensure smooth usage by tree learning algorithms</li>
</ul>
<section id="numerical-features-transformation" class="level4">
<h4 class="anchored" data-anchor-id="numerical-features-transformation">Numerical features Transformation</h4>
<section id="test-for-normality" class="level5">
<h5 class="anchored" data-anchor-id="test-for-normality">Test for Normality</h5>
<div id="fb9ba331" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test for normality of numeric columns: ALL are not normally distributed</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define specific numeric columns for imputation</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>numeric_cols <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> numeric_columns <span class="cf">if</span> col <span class="op">!=</span> <span class="st">'daysbetweendeathandoperation'</span>]</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Numeric columns:"</span>, <span class="bu">list</span>(numeric_cols))</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to test for normal distribution</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_normal_distribution(data, alpha<span class="op">=</span><span class="fl">0.05</span>):</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Test if the data follows a normal distribution.</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    shapiro_stat, shapiro_p <span class="op">=</span> stats.shapiro(data)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    ks_stat, ks_p <span class="op">=</span> stats.kstest(data, <span class="st">'norm'</span>, args<span class="op">=</span>(np.mean(data), np.std(data, ddof<span class="op">=</span><span class="dv">0</span>)))</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Shapiro-Wilk: Statistic=</span><span class="sc">{</span>shapiro_stat<span class="sc">:.3f}</span><span class="ss">, p-value=</span><span class="sc">{</span>shapiro_p<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Kolmogorov-Smirnov: Statistic=</span><span class="sc">{</span>ks_stat<span class="sc">:.3f}</span><span class="ss">, p-value=</span><span class="sc">{</span>ks_p<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Normally distributed:"</span> <span class="cf">if</span> shapiro_p <span class="op">&gt;</span> alpha <span class="kw">and</span> ks_p <span class="op">&gt;</span> alpha <span class="cf">else</span> <span class="st">"Not normally distributed."</span>)</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Test normal distribution</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing Normal Distribution:"</span>)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> numeric_cols:</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    test_normal_distribution(df[col])</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_qq_plots(columns):</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Number of columns to plot</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>    num_cols <span class="op">=</span> <span class="bu">len</span>(columns)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Determine grid size for subplots</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>    n_cols <span class="op">=</span> <span class="dv">3</span>  <span class="co"># Number of columns in the subplot grid</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>    n_rows <span class="op">=</span> (num_cols <span class="op">+</span> n_cols <span class="op">-</span> <span class="dv">1</span>) <span class="op">//</span> n_cols  <span class="co"># Calculate number of rows needed</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create subplots</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span> <span class="op">*</span> n_rows))  <span class="co"># Adjust figure size as needed</span></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(columns, <span class="dv">1</span>):</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>        plt.subplot(n_rows, n_cols, i)</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>        stats.probplot(df[col].dropna(), dist<span class="op">=</span><span class="st">"norm"</span>, plot<span class="op">=</span>plt)</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="ss">f'Q-Q Plot of </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'Theoretical Quantiles'</span>)</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Sample Quantiles'</span>)</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Create Q-Q plots for numeric columns</span></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>create_qq_plots(numeric_cols)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-1338966806.png" class="img-fluid"></p>
<p><img src="images/clipboard-1362939341.png" class="img-fluid"></p>
</section>
<section id="distribution-of-numeric-columns" class="level5">
<h5 class="anchored" data-anchor-id="distribution-of-numeric-columns">Distribution of numeric columns</h5>
<div id="8e82d8fd" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_histograms(df,columns):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Number of columns to plot</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    num_cols <span class="op">=</span> <span class="bu">len</span>(columns)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Determine grid size for subplots</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    n_cols <span class="op">=</span> <span class="dv">3</span>  <span class="co"># Number of columns in the subplot grid</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    n_rows <span class="op">=</span> (num_cols <span class="op">+</span> n_cols <span class="op">-</span> <span class="dv">1</span>) <span class="op">//</span> n_cols  <span class="co"># Calculate number of rows needed</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create subplots</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span> <span class="op">*</span> n_rows))  <span class="co"># Adjust figure size as needed</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(columns, <span class="dv">1</span>):</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        plt.subplot(n_rows, n_cols, i)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>        sns.histplot(df[col].dropna(), kde<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="dv">30</span>)  <span class="co"># Adjust bins as needed</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="ss">f'Distribution of </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(col)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Create histograms for numeric columns</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>create_histograms(df,numeric_cols)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-4289095336.png" class="img-fluid"></p>
</section>
<section id="automation-of-transforming-numeric-columns-based-on-skewness" class="level5">
<h5 class="anchored" data-anchor-id="automation-of-transforming-numeric-columns-based-on-skewness">Automation of transforming numeric columns based on skewness</h5>
<div id="055e321c" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_skewness(df,columns):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Dictionary to store skewness values</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    skewness_dict <span class="op">=</span> {}</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> columns:</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Drop NaN values for skewness calculation, there shouldn't be any left</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> df[col].dropna()</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate skewness</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>        skew_value <span class="op">=</span> skew(data, nan_policy<span class="op">=</span><span class="st">'omit'</span>)  <span class="co"># nan_policy='omit' ignores NaN values</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>        skewness_dict[col] <span class="op">=</span> skew_value</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert skewness dictionary to DataFrame for better readability</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    skewness_df <span class="op">=</span> pd.DataFrame(<span class="bu">list</span>(skewness_dict.items()), columns<span class="op">=</span>[<span class="st">'Column'</span>, <span class="st">'Skewness'</span>])</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> skewness_df</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate skewness for numeric columns</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>skewness_df <span class="op">=</span> calculate_skewness(df,numeric_cols)</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Print skewness values</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Skewness of Numeric Columns:"</span>)</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(skewness_df)</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> transform_based_on_skewness(df, columns):</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>    transformed_df <span class="op">=</span> df.copy()</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>    new_columns_numeric <span class="op">=</span> []</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>    column_mapping <span class="op">=</span> {}</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> columns:</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate skewness</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>        skewness <span class="op">=</span> skew(df[col].dropna(), nan_policy<span class="op">=</span><span class="st">'omit'</span>)</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize new_col to None</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>        new_col <span class="op">=</span> <span class="va">None</span></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print the skewness for debugging</span></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Skewness for column </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>skewness<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Choose transformation based on skewness</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> skewness <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Highly positively skewed</span></span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> (transformed_df[col] <span class="op">&gt;</span> <span class="dv">0</span>).<span class="bu">all</span>():  <span class="co"># Check if all values are positive</span></span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>                new_col <span class="op">=</span> col <span class="op">+</span> <span class="st">'_log'</span></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>                transformed_df[new_col] <span class="op">=</span> np.log1p(df[col])</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Applied log transformation on column </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Use Yeo-Johnson if data contains zero or negative values</span></span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>                new_col <span class="op">=</span> col <span class="op">+</span> <span class="st">'_yeojohnson'</span></span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>                pt <span class="op">=</span> PowerTransformer(method<span class="op">=</span><span class="st">'yeo-johnson'</span>)</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a>                transformed_df[new_col] <span class="op">=</span> pt.fit_transform(df[[col]])</span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Applied Yeo-Johnson transformation on column </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> skewness <span class="op">&gt;</span> <span class="fl">0.5</span>:</span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Moderately positively skewed</span></span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a>            new_col <span class="op">=</span> col <span class="op">+</span> <span class="st">'_sqrt'</span></span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a>            transformed_df[new_col] <span class="op">=</span> np.sqrt(df[col] <span class="op">+</span> <span class="dv">1</span>)  <span class="co"># Adding 1 to handle zero values</span></span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Applied square root transformation on column </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> skewness <span class="op">&lt;</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Highly negatively skewed</span></span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a>            new_col <span class="op">=</span> col <span class="op">+</span> <span class="st">'_inv'</span></span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a>            transformed_df[new_col] <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (df[col] <span class="op">+</span> <span class="dv">1</span>)  <span class="co"># Adding 1 to avoid division by zero</span></span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Applied inverse transformation on column </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> skewness <span class="op">&lt;</span> <span class="op">-</span><span class="fl">0.5</span>:</span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Moderately negatively skewed</span></span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a>            new_col <span class="op">=</span> col <span class="op">+</span> <span class="st">'_inv_sqrt'</span></span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a>            transformed_df[new_col] <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> np.sqrt(df[col] <span class="op">+</span> <span class="dv">1</span>)  <span class="co"># Adding 1 to handle zero values</span></span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Applied inverse square root transformation on column </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Data is close to normal, no transformation needed</span></span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a>            new_col <span class="op">=</span> col <span class="op">+</span> <span class="st">'_no_transform'</span></span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a>            transformed_df[new_col] <span class="op">=</span> df[col]</span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> new_col:</span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a>            new_columns_numeric.append(new_col)</span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a>            column_mapping[col] <span class="op">=</span> new_col</span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-84"><a href="#cb20-84" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> transformed_df, new_columns_numeric, column_mapping</span>
<span id="cb20-85"><a href="#cb20-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-86"><a href="#cb20-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb20-87"><a href="#cb20-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming df is your DataFrame</span></span>
<span id="cb20-88"><a href="#cb20-88" aria-hidden="true" tabindex="-1"></a>numeric_cols <span class="op">=</span> [<span class="st">'age'</span>, <span class="st">'rcri_score'</span>, <span class="st">'preopegfrmdrd'</span>, <span class="st">'preoptransfusionwithin30days'</span>,</span>
<span id="cb20-89"><a href="#cb20-89" aria-hidden="true" tabindex="-1"></a>                <span class="st">'intraop'</span>, <span class="st">'postopwithin30days'</span>, <span class="st">'transfusionintraandpostop'</span>]</span>
<span id="cb20-90"><a href="#cb20-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-91"><a href="#cb20-91" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply transformations based on skewness</span></span>
<span id="cb20-92"><a href="#cb20-92" aria-hidden="true" tabindex="-1"></a>transformed_df, new_columns_numeric, column_mapping <span class="op">=</span> transform_based_on_skewness(df, numeric_cols)</span>
<span id="cb20-93"><a href="#cb20-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-94"><a href="#cb20-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-95"><a href="#cb20-95" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the first few rows of the transformed DataFrame to verify</span></span>
<span id="cb20-96"><a href="#cb20-96" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(transformed_df.head())</span>
<span id="cb20-97"><a href="#cb20-97" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the list of newly transformed columns</span></span>
<span id="cb20-98"><a href="#cb20-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_columns_numeric)</span>
<span id="cb20-99"><a href="#cb20-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-100"><a href="#cb20-100" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify the columns are indeed in the DataFrame</span></span>
<span id="cb20-101"><a href="#cb20-101" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> new_columns_numeric:</span>
<span id="cb20-102"><a href="#cb20-102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> col <span class="kw">in</span> transformed_df.columns:</span>
<span id="cb20-103"><a href="#cb20-103" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Column </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> exists in the DataFrame."</span>)</span>
<span id="cb20-104"><a href="#cb20-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb20-105"><a href="#cb20-105" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Column </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> does NOT exist in the DataFrame."</span>)</span>
<span id="cb20-106"><a href="#cb20-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-107"><a href="#cb20-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-108"><a href="#cb20-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-109"><a href="#cb20-109" aria-hidden="true" tabindex="-1"></a><span class="co"># Create histograms for newly transformed columns</span></span>
<span id="cb20-110"><a href="#cb20-110" aria-hidden="true" tabindex="-1"></a>create_histograms(transformed_df,new_columns_numeric)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-1165382113.png" class="img-fluid"></p>
<p><img src="images/clipboard-2447623812.png" class="img-fluid"></p>
<p><img src="images/clipboard-917996487.png" class="img-fluid"></p>
</section>
<section id="comparison-of-newly-transformed-variables-as-compared-to-orignal-in-terms-of-skewness" class="level5">
<h5 class="anchored" data-anchor-id="comparison-of-newly-transformed-variables-as-compared-to-orignal-in-terms-of-skewness">Comparison of newly transformed variables as compared to orignal in terms of skewness</h5>
<div id="392ce6c1" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate skewness for original columns</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>skewness_original <span class="op">=</span> calculate_skewness(df,numeric_cols).set_index(<span class="st">'Column'</span>)[<span class="st">'Skewness'</span>].to_dict()</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate skewness for transformed columns</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>skewness_transformed <span class="op">=</span> calculate_skewness(transformed_df,new_columns_numeric).set_index(<span class="st">'Column'</span>)[<span class="st">'Skewness'</span>].to_dict()</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print column mapping</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Column Mapping:"</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(column_mapping)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Print skewness values</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Skewness of Numeric Columns:"</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(skewness_df)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(skewness_transformed)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Print column mapping</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (column_mapping)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a comparison DataFrame</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>comparison_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Original Column'</span>: numeric_cols,</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Original Skewness'</span>: [skewness_original[col] <span class="cf">for</span> col <span class="kw">in</span> numeric_cols],</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Transformed Column'</span>: [column_mapping[col] <span class="cf">if</span> col <span class="kw">in</span> column_mapping <span class="cf">else</span> col <span class="op">+</span> <span class="st">'_no_transform'</span> <span class="cf">for</span> col <span class="kw">in</span> numeric_cols],</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Transformed Skewness'</span>: [skewness_transformed[column_mapping[col]] <span class="cf">if</span> col <span class="kw">in</span> column_mapping <span class="cf">else</span> skewness_original[col] <span class="cf">for</span> col <span class="kw">in</span> numeric_cols]</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a column to indicate if skewness has decreased</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>comparison_df[<span class="st">'Skewness Decreased'</span>] <span class="op">=</span> <span class="bu">abs</span>(comparison_df[<span class="st">'Original Skewness'</span>]) <span class="op">&gt;</span> <span class="bu">abs</span>(comparison_df[<span class="st">'Transformed Skewness'</span>])</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Skewness Comparison:"</span>)</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>comparison_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-2181277663.png" class="img-fluid"></p>
</section>
<section id="standardize-all-newly-transformed-columns" class="level5">
<h5 class="anchored" data-anchor-id="standardize-all-newly-transformed-columns">Standardize all newly transformed columns</h5>
<div id="fdb668cb" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>std_scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>transformed_df[new_columns_numeric] <span class="op">=</span> std_scaler.fit_transform(transformed_df[new_columns_numeric])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="categorical-features-processing-one--hot-encoding-all-features" class="level4">
<h4 class="anchored" data-anchor-id="categorical-features-processing-one--hot-encoding-all-features">Categorical features processing: One- hot encoding all features</h4>
<div id="9fc92af8" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># List all categorical columns in the DataFrame</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>categorical_columns  <span class="op">=</span> transformed_df.select_dtypes(include<span class="op">=</span>[<span class="st">'object'</span>]).columns</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Columns to exclude (make sure names match exactly)</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>exclude_columns <span class="op">=</span> [<span class="st">'mortality'</span>, <span class="st">'daysbetweendeathandoperation'</span>, <span class="st">'@30daymortality'</span>, <span class="st">'thirtydaymortality'</span>]</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out the excluded columns from the list of categorical columns</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>categorical_columns <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> categorical_columns <span class="cf">if</span> col <span class="kw">not</span> <span class="kw">in</span> exclude_columns]</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encode categorical columns</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>one_hot_ed <span class="op">=</span> pd.get_dummies(transformed_df[categorical_columns],drop_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Concatenate the one-hot encoded columns with the original DataFrame</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>transformed_df <span class="op">=</span> pd.concat([transformed_df, one_hot_ed], axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="final-cleaning-and-consolidation-of-processed-numerical-and-categorical-columns" class="level4">
<h4 class="anchored" data-anchor-id="final-cleaning-and-consolidation-of-processed-numerical-and-categorical-columns">Final Cleaning and Consolidation of Processed Numerical and Categorical columns</h4>
<div id="6ae052df" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop the original categorical columns</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>transformed_df.drop(categorical_columns, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop the original numeric columns</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>transformed_df.drop(numeric_cols, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="9a8bfb9b" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>transformed_df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-3862374559.png" class="img-fluid"><img src="images/clipboard-3784664671.png" class="img-fluid"></p>
</section>
</section>
<section id="in-depth-analysis-staistical-modelling-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="in-depth-analysis-staistical-modelling-machine-learning">4. In-depth analysis: Staistical modelling / Machine Learning</h3>
<section id="multivariate-analysis" class="level4">
<h4 class="anchored" data-anchor-id="multivariate-analysis">Multivariate Analysis</h4>
<div id="8eba7e37" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultivariateAnalysis:</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, transformed_df, target_variable, vif_threshold<span class="op">=</span><span class="dv">10</span>, corr_threshold<span class="op">=</span><span class="fl">0.8</span>):</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> transformed_df</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.target_variable <span class="op">=</span> target_variable</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.vif_threshold <span class="op">=</span> vif_threshold</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.corr_threshold <span class="op">=</span> corr_threshold</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Drop target variable for analysis</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.features_df <span class="op">=</span> <span class="va">self</span>.df.drop(columns<span class="op">=</span>[<span class="va">self</span>.target_variable])</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> preprocess_data(<span class="va">self</span>):</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert Boolean columns to numeric</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>        bool_cols <span class="op">=</span> <span class="va">self</span>.features_df.select_dtypes(include<span class="op">=</span>[<span class="st">'bool'</span>]).columns</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.features_df[bool_cols] <span class="op">=</span> <span class="va">self</span>.features_df[bool_cols].astype(<span class="bu">int</span>)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> plot_correlation_heatmap(<span class="va">self</span>, high_corr_vars):</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">20</span>))</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>        corr <span class="op">=</span> <span class="va">self</span>.features_df[high_corr_vars].corr()</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>        ax <span class="op">=</span> sns.heatmap(corr, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'.2g'</span>, vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, center<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>                         cmap<span class="op">=</span><span class="st">'coolwarm_r'</span>, linecolor<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, annot_kws<span class="op">=</span>{<span class="st">"size"</span>: <span class="dv">12</span>})</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>        ax.set_ylim(<span class="bu">len</span>(corr), <span class="dv">0</span>)</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>        plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Correlation Heatmap of High Correlation Variables'</span>)</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> calculate_vif(<span class="va">self</span>, df):</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure only numeric columns are used</span></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>        numeric_df <span class="op">=</span> df.select_dtypes(include<span class="op">=</span>[<span class="st">'float64'</span>, <span class="st">'int64'</span>])</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> numeric_df.empty:</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"DataFrame contains no numeric columns."</span>)</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add constant to the feature set for VIF calculation</span></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>        numeric_df_with_const <span class="op">=</span> add_constant(numeric_df, has_constant<span class="op">=</span><span class="st">'add'</span>)</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>        vif_data <span class="op">=</span> pd.DataFrame()</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>        vif_data[<span class="st">"Variable"</span>] <span class="op">=</span> numeric_df_with_const.columns</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>        vif_data[<span class="st">"VIF"</span>] <span class="op">=</span> [variance_inflation_factor(numeric_df_with_const.values, i)</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>                           <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(numeric_df_with_const.shape[<span class="dv">1</span>])]</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> vif_data</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> plot_vif(<span class="va">self</span>, vif_data):</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>        sns.barplot(x<span class="op">=</span><span class="st">"VIF"</span>, y<span class="op">=</span><span class="st">"Variable"</span>, data<span class="op">=</span>vif_data.sort_values(<span class="st">"VIF"</span>, ascending<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Variance Inflation Factor (VIF)'</span>)</span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> identify_high_corr_pairs(<span class="va">self</span>):</span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a>        corr_matrix <span class="op">=</span> <span class="va">self</span>.features_df.corr().<span class="bu">abs</span>()</span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a>        high_corr_pairs <span class="op">=</span> (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k<span class="op">=</span><span class="dv">1</span>).astype(<span class="bu">bool</span>))</span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a>                           .stack()</span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a>                           .reset_index()</span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a>                           .rename(columns<span class="op">=</span>{<span class="dv">0</span>: <span class="st">'correlation'</span>, <span class="st">'level_0'</span>: <span class="st">'feature1'</span>, <span class="st">'level_1'</span>: <span class="st">'feature2'</span>}))</span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a>        high_corr_pairs <span class="op">=</span> high_corr_pairs[high_corr_pairs[<span class="st">'correlation'</span>] <span class="op">&gt;</span> <span class="va">self</span>.corr_threshold]</span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> high_corr_pairs</span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> drop_high_corr_vars(<span class="va">self</span>, high_corr_pairs):</span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a>        to_drop <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _, row <span class="kw">in</span> high_corr_pairs.iterrows():</span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> row[<span class="st">'feature1'</span>] <span class="kw">in</span> to_drop <span class="kw">or</span> row[<span class="st">'feature2'</span>] <span class="kw">in</span> to_drop:</span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a>            feature1_corr_sum <span class="op">=</span> <span class="va">self</span>.features_df.corr()[row[<span class="st">'feature1'</span>]].<span class="bu">abs</span>().<span class="bu">sum</span>()</span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a>            feature2_corr_sum <span class="op">=</span> <span class="va">self</span>.features_df.corr()[row[<span class="st">'feature2'</span>]].<span class="bu">abs</span>().<span class="bu">sum</span>()</span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> feature1_corr_sum <span class="op">&gt;</span> feature2_corr_sum:</span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a>                to_drop.add(row[<span class="st">'feature1'</span>])</span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a>                to_drop.add(row[<span class="st">'feature2'</span>])</span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.features_df.drop(columns<span class="op">=</span>to_drop, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> to_drop</span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_analysis(<span class="va">self</span>):</span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Preprocess data to include Boolean columns as numeric</span></span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.preprocess_data()</span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Identify and drop high correlation variables</span></span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a>        high_corr_pairs <span class="op">=</span> <span class="va">self</span>.identify_high_corr_pairs()</span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a>        dropped_corr_vars <span class="op">=</span> <span class="va">self</span>.drop_high_corr_vars(high_corr_pairs)</span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plot correlation heatmap for remaining variables</span></span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> high_corr_pairs.empty:</span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a>            high_corr_vars <span class="op">=</span> <span class="bu">list</span>(<span class="bu">set</span>(high_corr_pairs[<span class="st">'feature1'</span>]).union(<span class="bu">set</span>(high_corr_pairs[<span class="st">'feature2'</span>])))</span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a>            high_corr_vars <span class="op">=</span> [var <span class="cf">for</span> var <span class="kw">in</span> high_corr_vars <span class="cf">if</span> var <span class="kw">in</span> <span class="va">self</span>.features_df.columns]</span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.plot_correlation_heatmap(high_corr_vars)</span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate and plot VIF</span></span>
<span id="cb26-84"><a href="#cb26-84" aria-hidden="true" tabindex="-1"></a>        vif_data <span class="op">=</span> <span class="va">self</span>.calculate_vif(<span class="va">self</span>.features_df)</span>
<span id="cb26-85"><a href="#cb26-85" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Original VIF Data:"</span>)</span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(vif_data)</span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-88"><a href="#cb26-88" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Variables to keep for VIF reporting</span></span>
<span id="cb26-89"><a href="#cb26-89" aria-hidden="true" tabindex="-1"></a>        high_vif_vars <span class="op">=</span> vif_data[vif_data[<span class="st">"VIF"</span>] <span class="op">&gt;</span> <span class="va">self</span>.vif_threshold]</span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print table for high VIF variables</span></span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> high_vif_vars.empty:</span>
<span id="cb26-93"><a href="#cb26-93" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Variables with high VIF:"</span>)</span>
<span id="cb26-94"><a href="#cb26-94" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(high_vif_vars)</span>
<span id="cb26-95"><a href="#cb26-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb26-96"><a href="#cb26-96" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">No variables exceed the VIF threshold."</span>)</span>
<span id="cb26-97"><a href="#cb26-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-98"><a href="#cb26-98" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Drop variables with high VIF</span></span>
<span id="cb26-99"><a href="#cb26-99" aria-hidden="true" tabindex="-1"></a>        reduced_df <span class="op">=</span> <span class="va">self</span>.features_df.drop(columns<span class="op">=</span>high_vif_vars[<span class="st">'Variable'</span>], errors<span class="op">=</span><span class="st">'ignore'</span>)</span>
<span id="cb26-100"><a href="#cb26-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-101"><a href="#cb26-101" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Recalculate VIF on reduced dataset</span></span>
<span id="cb26-102"><a href="#cb26-102" aria-hidden="true" tabindex="-1"></a>        reduced_vif_data <span class="op">=</span> <span class="va">self</span>.calculate_vif(reduced_df)</span>
<span id="cb26-103"><a href="#cb26-103" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">New VIF Data after dropping high VIF variables:"</span>)</span>
<span id="cb26-104"><a href="#cb26-104" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(reduced_vif_data)</span>
<span id="cb26-105"><a href="#cb26-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-106"><a href="#cb26-106" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plot new VIF</span></span>
<span id="cb26-107"><a href="#cb26-107" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.plot_vif(reduced_vif_data)</span>
<span id="cb26-108"><a href="#cb26-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-109"><a href="#cb26-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add target variable back to reduced_df</span></span>
<span id="cb26-110"><a href="#cb26-110" aria-hidden="true" tabindex="-1"></a>        reduced_df[<span class="va">self</span>.target_variable] <span class="op">=</span> <span class="va">self</span>.df[<span class="va">self</span>.target_variable]</span>
<span id="cb26-111"><a href="#cb26-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-112"><a href="#cb26-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> reduced_df, dropped_corr_vars, high_vif_vars, reduced_vif_data</span>
<span id="cb26-113"><a href="#cb26-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-114"><a href="#cb26-114" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb26-115"><a href="#cb26-115" aria-hidden="true" tabindex="-1"></a><span class="co"># transformed_df is your DataFrame and 'target' is your target variable</span></span>
<span id="cb26-116"><a href="#cb26-116" aria-hidden="true" tabindex="-1"></a>ma <span class="op">=</span> MultivariateAnalysis(transformed_df, target_variable<span class="op">=</span><span class="st">'thirtydaymortality'</span>, corr_threshold<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb26-117"><a href="#cb26-117" aria-hidden="true" tabindex="-1"></a>reduced_df, dropped_corr_vars, high_vif_vars, new_vif <span class="op">=</span> ma.run_analysis()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-3373007464.png" class="img-fluid"></p>
<p><img src="images/clipboard-1854938830.png" class="img-fluid"></p>
<div class="notebox lightbulb">
<p>The <code>MultivariateAnalysis</code> class provides a comprehensive approach to handling multicollinearity in a dataset by leveraging Variance Inflation Factor (VIF) and correlation thresholds. This document summarizes the methods employed, presents the results, and evaluates the effectiveness of the analysis.</p>
<p><strong>Methods Used</strong></p>
<ol type="1">
<li><strong>Data Preprocessing</strong></li>
</ol>
<ul>
<li><p><em>Objective:</em> Convert Boolean columns to numeric values.</p></li>
<li><p><em>Implementation:</em> Boolean columns are cast to integers to ensure compatibility with further analyses.</p></li>
</ul>
<ol start="2" type="1">
<li><strong>Identifying High Correlation Pairs</strong></li>
</ol>
<ul>
<li><p><em>Objective:</em> Detect and address pairs of features with high correlation to mitigate multicollinearity.</p></li>
<li><p><em>Implementation:</em></p>
<ul>
<li><p>Compute the correlation matrix.</p></li>
<li><p>Identify pairs with correlation values exceeding the specified threshold.</p></li>
<li><p>Drop one feature from each high-correlation pair based on the overall sum of correlations.</p></li>
</ul></li>
</ul>
<ol start="3" type="1">
<li><strong>Variance Inflation Factor (VIF) Calculation</strong></li>
</ol>
<ul>
<li><p><em>Objective:</em> Assess multicollinearity for each feature.</p></li>
<li><p><em>Implementation:</em></p>
<ul>
<li><p>Compute VIF for all numeric features.</p></li>
<li><p>Features with VIF values above the specified threshold are flagged as problematic.</p></li>
</ul></li>
</ul>
<ol start="4" type="1">
<li><strong>Evaluation</strong></li>
</ol>
<ul>
<li><p>By identifying and removing highly correlated variables and variables with high VIF, we improved the multicollinearity in our dataset. This process helps in creating more robust and interpretable models.</p></li>
<li><p>The reduced dataset can now be used for further modeling and analysis with minimized multicollinearity issues.</p></li>
</ul>
</div>
</section>
<section id="estimate-the-logistic-regression-model" class="level4">
<h4 class="anchored" data-anchor-id="estimate-the-logistic-regression-model">Estimate the Logistic Regression Model:</h4>
<div id="a2ea6d36" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming 'transformed_df' is your DataFrame and 'thirtydaymortality' is your target variable</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> reduced_df.drop(columns<span class="op">=</span>[<span class="st">'thirtydaymortality'</span>])</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> reduced_df[<span class="st">'thirtydaymortality'</span>]</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert data to float</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X.astype(<span class="bu">float</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> LabelEncoder().fit_transform(y)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply SMOTE to balance the dataset</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>smote <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>X_resampled, y_resampled <span class="op">=</span> smote.fit_resample(X, y)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform Grid Search with Logistic Regression using scikit-learn</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>logreg <span class="op">=</span> LogisticRegression(solver<span class="op">=</span><span class="st">'liblinear'</span>)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {<span class="st">'C'</span>: [<span class="dv">1</span>, <span class="fl">0.1</span>, <span class="fl">0.01</span>], <span class="st">'penalty'</span>: [<span class="st">'l1'</span>, <span class="st">'l2'</span>]}</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>gs_logreg <span class="op">=</span> GridSearchCV(logreg, param_grid<span class="op">=</span>params, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'roc_auc'</span>)</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>gs_logreg.fit(X_resampled, y_resampled)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Display best parameters and score</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best estimator average accuracy on train set: </span><span class="sc">{:.4f}</span><span class="st">"</span>.<span class="bu">format</span>(gs_logreg.best_score_))</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best C = </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(gs_logreg.best_params_))</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test set</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X  <span class="co"># Assuming you're using the same data for demonstration purposes</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> y</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> gs_logreg.predict(X_test)</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> gs_logreg.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Print accuracy and classification report</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Accuracy on test set: </span><span class="sc">{:.4f}</span><span class="st">"</span>.<span class="bu">format</span>(gs_logreg.best_estimator_.score(X_test, y_test)))</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test set classification report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, y_pred))</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred, labels<span class="op">=</span>gs_logreg.classes_)</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>gs_logreg.classes_)</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>disp.plot()</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC Curve</span></span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>RocCurveDisplay.from_estimator(gs_logreg, X_test, y_test)</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ROC Curve'</span>)</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate statistical report with p-values using statsmodels</span></span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>X_resampled_with_const <span class="op">=</span> sm.add_constant(X_resampled)  <span class="co"># Add constant for intercept</span></span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>logit_model_resampled <span class="op">=</span> sm.Logit(y_resampled, X_resampled_with_const)</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>result_resampled <span class="op">=</span> logit_model_resampled.fit_regularized()</span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the summary of the logistic regression model</span></span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>summary_resampled <span class="op">=</span> result_resampled.summary()</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary_resampled)</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the maximum number of rows and columns to display</span></span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_rows'</span>, <span class="va">None</span>)</span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_columns'</span>, <span class="va">None</span>)</span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Print coefficients with p-values from the statsmodels summary</span></span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a>coef_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: [<span class="st">'Intercept'</span>] <span class="op">+</span> <span class="bu">list</span>(X.columns),</span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coefficient'</span>: result_resampled.params,</span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a>    <span class="st">'P-Value'</span>: result_resampled.pvalues</span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-2592243296.png" class="img-fluid"></p>
<p><img src="images/clipboard-3249462092.png" class="img-fluid" width="387"></p>
<p><img src="images/clipboard-96420571.png" class="img-fluid" width="362"></p>
<p><img src="images/clipboard-1055715652.png" class="img-fluid" width="545"></p>
<p><img src="images/clipboard-2022614774.png" class="img-fluid" width="546"></p>
<div class="notebox lightbulb">
<p><strong>Discussion on Results</strong> - <em>Pseudo R-squared (0.5986):</em> Indicates that the model explains approximately 60% of the variability in the dependent variable, which suggests a good fit.</p>
<ul>
<li><p><em>Log-Likelihood (-47051):</em> Measures how well the model fits the data. A higher (less negative) value would indicate a better fit.</p></li>
<li><p><em>Coefficients :</em></p>
<ul>
<li><p><em>age_no_transform (1.3001):</em> For each unit increase in age, the log-odds of the event occurring increase by 1.3001. This translates to an increased probability of the event with age. Converting this to odds: an increase in age by one unit multiplies the odds of the event by exp(1.3001) ≈ 3.68. Hence, older individuals have significantly higher odds of the event occurring.</p></li>
<li><p><em>gender_male (0.4632):</em> Being male increases the log-odds of the event by 0.4632. In terms of odds: exp(0.4632) ≈ 1.588. Thus, being male increases the odds of the event occurring by approximately 58.8%.</p></li>
</ul></li>
<li><p><em>Significance (P&gt;|z|):</em> Most coefficients have p-values of 0.000, indicating that these predictors are statistically significant. Coefficients with higher p-values (e.g., agecategory_30-49 (0.091)) are less significant, meaning they may not be as impactful in predicting the outcome.</p></li>
</ul>
</div>
</section>
<section id="machine-learning-individual-models" class="level4">
<h4 class="anchored" data-anchor-id="machine-learning-individual-models">Machine Learning (Individual Models)</h4>
<p>not needed here, we will proceed straight to AutoML with the models</p>
</section>
</section>
<section id="comparison-and-evaluation-automate-the-evaluation-process" class="level3">
<h3 class="anchored" data-anchor-id="comparison-and-evaluation-automate-the-evaluation-process">5. Comparison and Evaluation: Automate the evaluation process</h3>
<p>Automate the model training and evaluation process, and generate comprehensive results and key evaluation reports to assess the validity and effectiveness of the chosen model.</p>
<div id="3b18edf6" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BaseModel:</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, cleaned_df, target_column, balance<span class="op">=</span><span class="st">'imbalanced'</span>, n_splits<span class="op">=</span><span class="dv">5</span>, n_repeats<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">123</span>):</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> cleaned_df</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.target_column <span class="op">=</span> target_column</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.balance <span class="op">=</span> balance</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_splits <span class="op">=</span> n_splits</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_repeats <span class="op">=</span> n_repeats</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.random_state <span class="op">=</span> random_state</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prepare features and target variable</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> <span class="va">self</span>.df.drop(columns<span class="op">=</span>[<span class="va">self</span>.target_column])</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> <span class="va">self</span>.df[<span class="va">self</span>.target_column]</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Label encode the target variable</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>        label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> label_encoder.fit_transform(<span class="va">self</span>.y)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Split the data into training and test sets</span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_train, <span class="va">self</span>.X_test, <span class="va">self</span>.y_train, <span class="va">self</span>.y_test <span class="op">=</span> train_test_split(</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X, <span class="va">self</span>.y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="va">self</span>.random_state</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize SMOTEENN if balance is set to 'imbalanced'</span></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.balance <span class="op">==</span> <span class="st">'imbalanced'</span>:</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.smoteenn <span class="op">=</span> SMOTEENN(sampling_strategy<span class="op">=</span><span class="st">'auto'</span>, random_state<span class="op">=</span><span class="va">self</span>.random_state)</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.smoteenn <span class="op">=</span> <span class="va">None</span></span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> apply_smoteenn(<span class="va">self</span>):</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.smoteenn:</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.smoteenn.fit_resample(<span class="va">self</span>.X_train, <span class="va">self</span>.y_train)</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.X_train, <span class="va">self</span>.y_train</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> show_matrix(<span class="va">self</span>, matrix, title<span class="op">=</span><span class="st">'Confusion Matrix'</span>):</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plotting the confusion matrix</span></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>        sns.heatmap(matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">"d"</span>, cmap<span class="op">=</span><span class="st">"Blues"</span>, xticklabels<span class="op">=</span><span class="va">True</span>, yticklabels<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>        plt.title(title)</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Actual Class'</span>)</span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'Predicted Class'</span>)</span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> plot_roc_auc(<span class="va">self</span>, y_true, y_pred, title):</span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>        fpr, tpr, _ <span class="op">=</span> roc_curve(y_true, y_pred)</span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>        roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a>        plt.figure()</span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a>        plt.plot(fpr, tpr, color<span class="op">=</span><span class="st">'darkorange'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'ROC curve (area = </span><span class="sc">%0.2f</span><span class="st">)'</span> <span class="op">%</span> roc_auc)</span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a>        plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'navy'</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a>        plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a>        plt.ylim([<span class="fl">0.0</span>, <span class="fl">1.05</span>])</span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a>        plt.title(title)</span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a>        plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb28-59"><a href="#cb28-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-60"><a href="#cb28-60" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DT(BaseModel):</span>
<span id="cb28-61"><a href="#cb28-61" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb28-62"><a href="#cb28-62" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb28-63"><a href="#cb28-63" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> DecisionTreeClassifier()</span>
<span id="cb28-64"><a href="#cb28-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-65"><a href="#cb28-65" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_bayesian_search(<span class="va">self</span>):</span>
<span id="cb28-66"><a href="#cb28-66" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running Bayesian Search for Decision Tree..."</span>)</span>
<span id="cb28-67"><a href="#cb28-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the parameter space</span></span>
<span id="cb28-68"><a href="#cb28-68" aria-hidden="true" tabindex="-1"></a>        search_spaces <span class="op">=</span> {</span>
<span id="cb28-69"><a href="#cb28-69" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_features'</span>: Categorical([<span class="st">'sqrt'</span>, <span class="st">'log2'</span>]),</span>
<span id="cb28-70"><a href="#cb28-70" aria-hidden="true" tabindex="-1"></a>            <span class="st">'ccp_alpha'</span>: Real(<span class="fl">0.001</span>, <span class="fl">0.1</span>, prior<span class="op">=</span><span class="st">'log-uniform'</span>),</span>
<span id="cb28-71"><a href="#cb28-71" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_depth'</span>: Integer(<span class="dv">20</span>, <span class="dv">30</span>),</span>
<span id="cb28-72"><a href="#cb28-72" aria-hidden="true" tabindex="-1"></a>            <span class="st">'criterion'</span>: Categorical([<span class="st">'gini'</span>, <span class="st">'entropy'</span>]),</span>
<span id="cb28-73"><a href="#cb28-73" aria-hidden="true" tabindex="-1"></a>            <span class="st">'min_samples_split'</span>: Integer(<span class="dv">2</span>, <span class="dv">4</span>),</span>
<span id="cb28-74"><a href="#cb28-74" aria-hidden="true" tabindex="-1"></a>            <span class="st">'min_samples_leaf'</span>: Integer(<span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb28-75"><a href="#cb28-75" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb28-76"><a href="#cb28-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-77"><a href="#cb28-77" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize BayesSearchCV</span></span>
<span id="cb28-78"><a href="#cb28-78" aria-hidden="true" tabindex="-1"></a>        cv <span class="op">=</span> RepeatedStratifiedKFold(n_splits<span class="op">=</span><span class="va">self</span>.n_splits, n_repeats<span class="op">=</span><span class="va">self</span>.n_repeats, random_state<span class="op">=</span><span class="va">self</span>.random_state)</span>
<span id="cb28-79"><a href="#cb28-79" aria-hidden="true" tabindex="-1"></a>        bayes_search <span class="op">=</span> BayesSearchCV(estimator<span class="op">=</span><span class="va">self</span>.clf, search_spaces<span class="op">=</span>search_spaces, cv<span class="op">=</span>cv, n_iter<span class="op">=</span><span class="dv">10</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>, random_state<span class="op">=</span><span class="va">self</span>.random_state, verbose<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb28-80"><a href="#cb28-80" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-81"><a href="#cb28-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply SMOTEENN to the training data if balance is 'imbalanced'</span></span>
<span id="cb28-82"><a href="#cb28-82" aria-hidden="true" tabindex="-1"></a>        X_resampled, y_resampled <span class="op">=</span> <span class="va">self</span>.apply_smoteenn()</span>
<span id="cb28-83"><a href="#cb28-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-84"><a href="#cb28-84" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit BayesSearchCV with the resampled data</span></span>
<span id="cb28-85"><a href="#cb28-85" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.time()</span>
<span id="cb28-86"><a href="#cb28-86" aria-hidden="true" tabindex="-1"></a>        bayes_result <span class="op">=</span> bayes_search.fit(X_resampled, y_resampled)</span>
<span id="cb28-87"><a href="#cb28-87" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Time taken = </span><span class="sc">{</span><span class="bu">round</span>(time.time() <span class="op">-</span> t0, <span class="dv">2</span>)<span class="sc">}</span><span class="ss"> sec'</span>)</span>
<span id="cb28-88"><a href="#cb28-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-89"><a href="#cb28-89" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print best score and parameters</span></span>
<span id="cb28-90"><a href="#cb28-90" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Best score = </span><span class="sc">{</span><span class="bu">round</span>(bayes_result.best_score_, <span class="dv">3</span>)<span class="sc">}</span><span class="ss"> using params: </span><span class="sc">{</span>bayes_result<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-91"><a href="#cb28-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-92"><a href="#cb28-92" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate on test data</span></span>
<span id="cb28-93"><a href="#cb28-93" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> bayes_result.best_estimator_.predict(<span class="va">self</span>.X_test)</span>
<span id="cb28-94"><a href="#cb28-94" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb28-95"><a href="#cb28-95" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Test accuracy = </span><span class="sc">{</span><span class="bu">round</span>(accuracy, <span class="dv">3</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-96"><a href="#cb28-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-97"><a href="#cb28-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> bayes_result, y_pred</span>
<span id="cb28-98"><a href="#cb28-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-99"><a href="#cb28-99" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RandomForest(BaseModel):</span>
<span id="cb28-100"><a href="#cb28-100" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb28-101"><a href="#cb28-101" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb28-102"><a href="#cb28-102" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> RandomForestClassifier()</span>
<span id="cb28-103"><a href="#cb28-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-104"><a href="#cb28-104" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_bayesian_search(<span class="va">self</span>):</span>
<span id="cb28-105"><a href="#cb28-105" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running Bayesian Search for Random Forest..."</span>)</span>
<span id="cb28-106"><a href="#cb28-106" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the parameter space</span></span>
<span id="cb28-107"><a href="#cb28-107" aria-hidden="true" tabindex="-1"></a>        search_spaces <span class="op">=</span> {</span>
<span id="cb28-108"><a href="#cb28-108" aria-hidden="true" tabindex="-1"></a>            <span class="st">'n_estimators'</span>: Integer(<span class="dv">80</span>, <span class="dv">150</span>),</span>
<span id="cb28-109"><a href="#cb28-109" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_features'</span>: Categorical([<span class="st">'sqrt'</span>, <span class="st">'log2'</span>]),</span>
<span id="cb28-110"><a href="#cb28-110" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_depth'</span>: Integer(<span class="dv">20</span>, <span class="dv">30</span>),</span>
<span id="cb28-111"><a href="#cb28-111" aria-hidden="true" tabindex="-1"></a>            <span class="st">'criterion'</span>: Categorical([<span class="st">'gini'</span>, <span class="st">'entropy'</span>]),</span>
<span id="cb28-112"><a href="#cb28-112" aria-hidden="true" tabindex="-1"></a>            <span class="st">'min_samples_split'</span>: Integer(<span class="dv">2</span>, <span class="dv">4</span>),</span>
<span id="cb28-113"><a href="#cb28-113" aria-hidden="true" tabindex="-1"></a>            <span class="st">'min_samples_leaf'</span>: Integer(<span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb28-114"><a href="#cb28-114" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb28-115"><a href="#cb28-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-116"><a href="#cb28-116" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize BayesSearchCV</span></span>
<span id="cb28-117"><a href="#cb28-117" aria-hidden="true" tabindex="-1"></a>        cv <span class="op">=</span> RepeatedStratifiedKFold(n_splits<span class="op">=</span><span class="va">self</span>.n_splits, n_repeats<span class="op">=</span><span class="va">self</span>.n_repeats, random_state<span class="op">=</span><span class="va">self</span>.random_state)</span>
<span id="cb28-118"><a href="#cb28-118" aria-hidden="true" tabindex="-1"></a>        bayes_search <span class="op">=</span> BayesSearchCV(estimator<span class="op">=</span><span class="va">self</span>.clf, search_spaces<span class="op">=</span>search_spaces, cv<span class="op">=</span>cv, n_iter<span class="op">=</span><span class="dv">10</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>, random_state<span class="op">=</span><span class="va">self</span>.random_state, verbose<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb28-119"><a href="#cb28-119" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-120"><a href="#cb28-120" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply SMOTEENN to the training data if balance is 'imbalanced'</span></span>
<span id="cb28-121"><a href="#cb28-121" aria-hidden="true" tabindex="-1"></a>        X_resampled, y_resampled <span class="op">=</span> <span class="va">self</span>.apply_smoteenn()</span>
<span id="cb28-122"><a href="#cb28-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-123"><a href="#cb28-123" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit BayesSearchCV with the resampled data</span></span>
<span id="cb28-124"><a href="#cb28-124" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.time()</span>
<span id="cb28-125"><a href="#cb28-125" aria-hidden="true" tabindex="-1"></a>        bayes_result <span class="op">=</span> bayes_search.fit(X_resampled, y_resampled)</span>
<span id="cb28-126"><a href="#cb28-126" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Time taken = </span><span class="sc">{</span><span class="bu">round</span>(time.time() <span class="op">-</span> t0, <span class="dv">2</span>)<span class="sc">}</span><span class="ss"> sec'</span>)</span>
<span id="cb28-127"><a href="#cb28-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-128"><a href="#cb28-128" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print best score and parameters</span></span>
<span id="cb28-129"><a href="#cb28-129" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Best score = </span><span class="sc">{</span><span class="bu">round</span>(bayes_result.best_score_, <span class="dv">3</span>)<span class="sc">}</span><span class="ss"> using params: </span><span class="sc">{</span>bayes_result<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-130"><a href="#cb28-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-131"><a href="#cb28-131" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate on test data</span></span>
<span id="cb28-132"><a href="#cb28-132" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> bayes_result.best_estimator_.predict(<span class="va">self</span>.X_test)</span>
<span id="cb28-133"><a href="#cb28-133" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb28-134"><a href="#cb28-134" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Test accuracy = </span><span class="sc">{</span><span class="bu">round</span>(accuracy, <span class="dv">3</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-135"><a href="#cb28-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-136"><a href="#cb28-136" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> bayes_result, y_pred</span>
<span id="cb28-137"><a href="#cb28-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-138"><a href="#cb28-138" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> XGBoost(BaseModel):</span>
<span id="cb28-139"><a href="#cb28-139" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb28-140"><a href="#cb28-140" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb28-141"><a href="#cb28-141" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> xgb.XGBClassifier(use_label_encoder<span class="op">=</span><span class="va">False</span>, eval_metric<span class="op">=</span><span class="st">'logloss'</span>)</span>
<span id="cb28-142"><a href="#cb28-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-143"><a href="#cb28-143" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_bayesian_search(<span class="va">self</span>):</span>
<span id="cb28-144"><a href="#cb28-144" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running Bayesian Search for XGBoost..."</span>)</span>
<span id="cb28-145"><a href="#cb28-145" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the parameter space</span></span>
<span id="cb28-146"><a href="#cb28-146" aria-hidden="true" tabindex="-1"></a>        search_spaces <span class="op">=</span> {</span>
<span id="cb28-147"><a href="#cb28-147" aria-hidden="true" tabindex="-1"></a>            <span class="st">'n_estimators'</span>: Integer(<span class="dv">80</span>, <span class="dv">150</span>),</span>
<span id="cb28-148"><a href="#cb28-148" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_depth'</span>: Integer(<span class="dv">20</span>, <span class="dv">30</span>),</span>
<span id="cb28-149"><a href="#cb28-149" aria-hidden="true" tabindex="-1"></a>            <span class="st">'learning_rate'</span>: Real(<span class="fl">0.01</span>, <span class="fl">0.2</span>, prior<span class="op">=</span><span class="st">'log-uniform'</span>),</span>
<span id="cb28-150"><a href="#cb28-150" aria-hidden="true" tabindex="-1"></a>            <span class="st">'subsample'</span>: Real(<span class="fl">0.5</span>, <span class="fl">1.0</span>),</span>
<span id="cb28-151"><a href="#cb28-151" aria-hidden="true" tabindex="-1"></a>            <span class="st">'colsample_bytree'</span>: Real(<span class="fl">0.5</span>, <span class="fl">1.0</span>)</span>
<span id="cb28-152"><a href="#cb28-152" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb28-153"><a href="#cb28-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-154"><a href="#cb28-154" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize BayesSearchCV</span></span>
<span id="cb28-155"><a href="#cb28-155" aria-hidden="true" tabindex="-1"></a>        cv <span class="op">=</span> RepeatedStratifiedKFold(n_splits<span class="op">=</span><span class="va">self</span>.n_splits, n_repeats<span class="op">=</span><span class="va">self</span>.n_repeats, random_state<span class="op">=</span><span class="va">self</span>.random_state)</span>
<span id="cb28-156"><a href="#cb28-156" aria-hidden="true" tabindex="-1"></a>        bayes_search <span class="op">=</span> BayesSearchCV(estimator<span class="op">=</span><span class="va">self</span>.clf, search_spaces<span class="op">=</span>search_spaces, cv<span class="op">=</span>cv, n_iter<span class="op">=</span><span class="dv">10</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>, random_state<span class="op">=</span><span class="va">self</span>.random_state, verbose<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb28-157"><a href="#cb28-157" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-158"><a href="#cb28-158" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply SMOTEENN to the training data if balance is 'imbalanced'</span></span>
<span id="cb28-159"><a href="#cb28-159" aria-hidden="true" tabindex="-1"></a>        X_resampled, y_resampled <span class="op">=</span> <span class="va">self</span>.apply_smoteenn()</span>
<span id="cb28-160"><a href="#cb28-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-161"><a href="#cb28-161" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit BayesSearchCV with the resampled data</span></span>
<span id="cb28-162"><a href="#cb28-162" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.time()</span>
<span id="cb28-163"><a href="#cb28-163" aria-hidden="true" tabindex="-1"></a>        bayes_result <span class="op">=</span> bayes_search.fit(X_resampled, y_resampled)</span>
<span id="cb28-164"><a href="#cb28-164" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Time taken = </span><span class="sc">{</span><span class="bu">round</span>(time.time() <span class="op">-</span> t0, <span class="dv">2</span>)<span class="sc">}</span><span class="ss"> sec'</span>)</span>
<span id="cb28-165"><a href="#cb28-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-166"><a href="#cb28-166" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print best score and parameters</span></span>
<span id="cb28-167"><a href="#cb28-167" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Best score = </span><span class="sc">{</span><span class="bu">round</span>(bayes_result.best_score_, <span class="dv">3</span>)<span class="sc">}</span><span class="ss"> using params: </span><span class="sc">{</span>bayes_result<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-168"><a href="#cb28-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-169"><a href="#cb28-169" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate on test data</span></span>
<span id="cb28-170"><a href="#cb28-170" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> bayes_result.best_estimator_.predict(<span class="va">self</span>.X_test)</span>
<span id="cb28-171"><a href="#cb28-171" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb28-172"><a href="#cb28-172" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Test accuracy = </span><span class="sc">{</span><span class="bu">round</span>(accuracy, <span class="dv">3</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-173"><a href="#cb28-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-174"><a href="#cb28-174" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> bayes_result, y_pred</span>
<span id="cb28-175"><a href="#cb28-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-176"><a href="#cb28-176" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LightGBM(BaseModel):</span>
<span id="cb28-177"><a href="#cb28-177" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb28-178"><a href="#cb28-178" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb28-179"><a href="#cb28-179" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> LGBMClassifier()</span>
<span id="cb28-180"><a href="#cb28-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-181"><a href="#cb28-181" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_bayesian_search(<span class="va">self</span>):</span>
<span id="cb28-182"><a href="#cb28-182" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running Bayesian Search for LightGBM..."</span>)</span>
<span id="cb28-183"><a href="#cb28-183" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the parameter space</span></span>
<span id="cb28-184"><a href="#cb28-184" aria-hidden="true" tabindex="-1"></a>        search_spaces <span class="op">=</span> {</span>
<span id="cb28-185"><a href="#cb28-185" aria-hidden="true" tabindex="-1"></a>            <span class="st">'n_estimators'</span>: Integer(<span class="dv">80</span>, <span class="dv">150</span>),</span>
<span id="cb28-186"><a href="#cb28-186" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_depth'</span>: Integer(<span class="dv">20</span>, <span class="dv">30</span>),</span>
<span id="cb28-187"><a href="#cb28-187" aria-hidden="true" tabindex="-1"></a>            <span class="st">'learning_rate'</span>: Real(<span class="fl">0.01</span>, <span class="fl">0.2</span>, prior<span class="op">=</span><span class="st">'log-uniform'</span>),</span>
<span id="cb28-188"><a href="#cb28-188" aria-hidden="true" tabindex="-1"></a>            <span class="st">'subsample'</span>: Real(<span class="fl">0.5</span>, <span class="fl">1.0</span>),</span>
<span id="cb28-189"><a href="#cb28-189" aria-hidden="true" tabindex="-1"></a>            <span class="st">'colsample_bytree'</span>: Real(<span class="fl">0.5</span>, <span class="fl">1.0</span>)</span>
<span id="cb28-190"><a href="#cb28-190" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb28-191"><a href="#cb28-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-192"><a href="#cb28-192" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize BayesSearchCV</span></span>
<span id="cb28-193"><a href="#cb28-193" aria-hidden="true" tabindex="-1"></a>        cv <span class="op">=</span> RepeatedStratifiedKFold(n_splits<span class="op">=</span><span class="va">self</span>.n_splits, n_repeats<span class="op">=</span><span class="va">self</span>.n_repeats, random_state<span class="op">=</span><span class="va">self</span>.random_state)</span>
<span id="cb28-194"><a href="#cb28-194" aria-hidden="true" tabindex="-1"></a>        bayes_search <span class="op">=</span> BayesSearchCV(estimator<span class="op">=</span><span class="va">self</span>.clf, search_spaces<span class="op">=</span>search_spaces, cv<span class="op">=</span>cv, n_iter<span class="op">=</span><span class="dv">10</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>, random_state<span class="op">=</span><span class="va">self</span>.random_state, verbose<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb28-195"><a href="#cb28-195" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-196"><a href="#cb28-196" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply SMOTEENN to the training data if balance is 'imbalanced'</span></span>
<span id="cb28-197"><a href="#cb28-197" aria-hidden="true" tabindex="-1"></a>        X_resampled, y_resampled <span class="op">=</span> <span class="va">self</span>.apply_smoteenn()</span>
<span id="cb28-198"><a href="#cb28-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-199"><a href="#cb28-199" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit BayesSearchCV with the resampled data</span></span>
<span id="cb28-200"><a href="#cb28-200" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.time()</span>
<span id="cb28-201"><a href="#cb28-201" aria-hidden="true" tabindex="-1"></a>        bayes_result <span class="op">=</span> bayes_search.fit(X_resampled, y_resampled)</span>
<span id="cb28-202"><a href="#cb28-202" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Time taken = </span><span class="sc">{</span><span class="bu">round</span>(time.time() <span class="op">-</span> t0, <span class="dv">2</span>)<span class="sc">}</span><span class="ss"> sec'</span>)</span>
<span id="cb28-203"><a href="#cb28-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-204"><a href="#cb28-204" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print best score and parameters</span></span>
<span id="cb28-205"><a href="#cb28-205" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Best score = </span><span class="sc">{</span><span class="bu">round</span>(bayes_result.best_score_, <span class="dv">3</span>)<span class="sc">}</span><span class="ss"> using params: </span><span class="sc">{</span>bayes_result<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-206"><a href="#cb28-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-207"><a href="#cb28-207" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate on test data</span></span>
<span id="cb28-208"><a href="#cb28-208" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> bayes_result.best_estimator_.predict(<span class="va">self</span>.X_test)</span>
<span id="cb28-209"><a href="#cb28-209" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb28-210"><a href="#cb28-210" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Test accuracy = </span><span class="sc">{</span><span class="bu">round</span>(accuracy, <span class="dv">3</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-211"><a href="#cb28-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-212"><a href="#cb28-212" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> bayes_result, y_pred</span>
<span id="cb28-213"><a href="#cb28-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-214"><a href="#cb28-214" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AutoML:</span>
<span id="cb28-215"><a href="#cb28-215" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, cleaned_df, target_column, balance<span class="op">=</span><span class="st">'imbalanced'</span>, n_splits<span class="op">=</span><span class="dv">5</span>, n_repeats<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">123</span>, secondary_metric<span class="op">=</span><span class="st">'precision'</span>):</span>
<span id="cb28-216"><a href="#cb28-216" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cleaned_df <span class="op">=</span> cleaned_df</span>
<span id="cb28-217"><a href="#cb28-217" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.target_column <span class="op">=</span> target_column</span>
<span id="cb28-218"><a href="#cb28-218" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.balance <span class="op">=</span> balance</span>
<span id="cb28-219"><a href="#cb28-219" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_splits <span class="op">=</span> n_splits</span>
<span id="cb28-220"><a href="#cb28-220" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_repeats <span class="op">=</span> n_repeats</span>
<span id="cb28-221"><a href="#cb28-221" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.random_state <span class="op">=</span> random_state</span>
<span id="cb28-222"><a href="#cb28-222" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.secondary_metric <span class="op">=</span> secondary_metric</span>
<span id="cb28-223"><a href="#cb28-223" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-224"><a href="#cb28-224" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize model classes</span></span>
<span id="cb28-225"><a href="#cb28-225" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models <span class="op">=</span> {</span>
<span id="cb28-226"><a href="#cb28-226" aria-hidden="true" tabindex="-1"></a>            <span class="st">'DecisionTree'</span>: DT(cleaned_df, target_column, balance, n_splits, n_repeats, random_state),</span>
<span id="cb28-227"><a href="#cb28-227" aria-hidden="true" tabindex="-1"></a>            <span class="st">'RandomForest'</span>: RandomForest(cleaned_df, target_column, balance, n_splits, n_repeats, random_state),</span>
<span id="cb28-228"><a href="#cb28-228" aria-hidden="true" tabindex="-1"></a>            <span class="st">'XGBoost'</span>: XGBoost(cleaned_df, target_column, balance, n_splits, n_repeats, random_state),</span>
<span id="cb28-229"><a href="#cb28-229" aria-hidden="true" tabindex="-1"></a>            <span class="st">'LightGBM'</span>: LightGBM(cleaned_df, target_column, balance, n_splits, n_repeats, random_state)</span>
<span id="cb28-230"><a href="#cb28-230" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb28-231"><a href="#cb28-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-232"><a href="#cb28-232" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> evaluate_models(<span class="va">self</span>):</span>
<span id="cb28-233"><a href="#cb28-233" aria-hidden="true" tabindex="-1"></a>        results <span class="op">=</span> {}</span>
<span id="cb28-234"><a href="#cb28-234" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, model <span class="kw">in</span> <span class="va">self</span>.models.items():</span>
<span id="cb28-235"><a href="#cb28-235" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Evaluating </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">...'</span>)</span>
<span id="cb28-236"><a href="#cb28-236" aria-hidden="true" tabindex="-1"></a>            best_model, y_pred <span class="op">=</span> model.run_bayesian_search()</span>
<span id="cb28-237"><a href="#cb28-237" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb28-238"><a href="#cb28-238" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute metrics</span></span>
<span id="cb28-239"><a href="#cb28-239" aria-hidden="true" tabindex="-1"></a>            accuracy <span class="op">=</span> accuracy_score(model.y_test, y_pred)</span>
<span id="cb28-240"><a href="#cb28-240" aria-hidden="true" tabindex="-1"></a>            precision <span class="op">=</span> precision_score(model.y_test, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb28-241"><a href="#cb28-241" aria-hidden="true" tabindex="-1"></a>            recall <span class="op">=</span> recall_score(model.y_test, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb28-242"><a href="#cb28-242" aria-hidden="true" tabindex="-1"></a>            f1 <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (precision <span class="op">*</span> recall) <span class="op">/</span> (precision <span class="op">+</span> recall)</span>
<span id="cb28-243"><a href="#cb28-243" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb28-244"><a href="#cb28-244" aria-hidden="true" tabindex="-1"></a>            results[name] <span class="op">=</span> {</span>
<span id="cb28-245"><a href="#cb28-245" aria-hidden="true" tabindex="-1"></a>                <span class="st">'accuracy'</span>: accuracy,</span>
<span id="cb28-246"><a href="#cb28-246" aria-hidden="true" tabindex="-1"></a>                <span class="st">'precision'</span>: precision,</span>
<span id="cb28-247"><a href="#cb28-247" aria-hidden="true" tabindex="-1"></a>                <span class="st">'recall'</span>: recall,</span>
<span id="cb28-248"><a href="#cb28-248" aria-hidden="true" tabindex="-1"></a>                <span class="st">'f1'</span>: f1,</span>
<span id="cb28-249"><a href="#cb28-249" aria-hidden="true" tabindex="-1"></a>                <span class="st">'classification_report'</span>: classification_report(model.y_test, y_pred),</span>
<span id="cb28-250"><a href="#cb28-250" aria-hidden="true" tabindex="-1"></a>                <span class="st">'confusion_matrix'</span>: model.show_matrix(confusion_matrix(model.y_test, y_pred))</span>
<span id="cb28-251"><a href="#cb28-251" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb28-252"><a href="#cb28-252" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb28-253"><a href="#cb28-253" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Print Classification Report and Confusion Matrix</span></span>
<span id="cb28-254"><a href="#cb28-254" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'Classification Report for </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">:</span><span class="ch">\n</span><span class="sc">{</span>results[name][<span class="st">"classification_report"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-255"><a href="#cb28-255" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb28-256"><a href="#cb28-256" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ROC and AUC</span></span>
<span id="cb28-257"><a href="#cb28-257" aria-hidden="true" tabindex="-1"></a>            y_test_binarized <span class="op">=</span> label_binarize(model.y_test, classes<span class="op">=</span>np.unique(model.y_test))</span>
<span id="cb28-258"><a href="#cb28-258" aria-hidden="true" tabindex="-1"></a>            y_pred_binarized <span class="op">=</span> label_binarize(y_pred, classes<span class="op">=</span>np.unique(model.y_test))</span>
<span id="cb28-259"><a href="#cb28-259" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> y_test_binarized.shape[<span class="dv">1</span>] <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb28-260"><a href="#cb28-260" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_binarized.shape[<span class="dv">1</span>]):</span>
<span id="cb28-261"><a href="#cb28-261" aria-hidden="true" tabindex="-1"></a>                    model.plot_roc_auc(y_test_binarized[:, i], y_pred_binarized[:, i], <span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> ROC Curve for Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-262"><a href="#cb28-262" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb28-263"><a href="#cb28-263" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Determine the best model</span></span>
<span id="cb28-264"><a href="#cb28-264" aria-hidden="true" tabindex="-1"></a>        sorted_results <span class="op">=</span> <span class="bu">sorted</span>(results.items(), key<span class="op">=</span><span class="kw">lambda</span> x: (x[<span class="dv">1</span>][<span class="st">'accuracy'</span>], x[<span class="dv">1</span>][<span class="va">self</span>.secondary_metric]), reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-265"><a href="#cb28-265" aria-hidden="true" tabindex="-1"></a>        best_model_name, best_model_metrics <span class="op">=</span> sorted_results[<span class="dv">0</span>]</span>
<span id="cb28-266"><a href="#cb28-266" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Best Model: </span><span class="sc">{</span>best_model_name<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-267"><a href="#cb28-267" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Accuracy: </span><span class="sc">{</span>best_model_metrics[<span class="st">"accuracy"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-268"><a href="#cb28-268" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>secondary_metric<span class="sc">.</span>capitalize()<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>best_model_metrics[<span class="va">self</span>.secondary_metric]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-269"><a href="#cb28-269" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-270"><a href="#cb28-270" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> best_model_name, best_model_metrics</span>
<span id="cb28-271"><a href="#cb28-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-272"><a href="#cb28-272" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb28-273"><a href="#cb28-273" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming `transformed_df` is your DataFrame and 'thirtydaymortality' is your target column</span></span>
<span id="cb28-274"><a href="#cb28-274" aria-hidden="true" tabindex="-1"></a>auto_ml <span class="op">=</span> AutoML(reduced_df, target_column<span class="op">=</span><span class="st">'thirtydaymortality'</span>, balance<span class="op">=</span><span class="st">'imbalanced'</span>, secondary_metric<span class="op">=</span><span class="st">'recall'</span>)</span>
<span id="cb28-275"><a href="#cb28-275" aria-hidden="true" tabindex="-1"></a>best_model_name, best_model_metrics <span class="op">=</span> auto_ml.evaluate_models()</span>
<span id="cb28-276"><a href="#cb28-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-277"><a href="#cb28-277" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Best Model: </span><span class="sc">{</span>best_model_name<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-278"><a href="#cb28-278" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Accuracy: </span><span class="sc">{</span>best_model_metrics[<span class="st">"accuracy"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-279"><a href="#cb28-279" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Precision: </span><span class="sc">{</span>best_model_metrics[<span class="st">"precision"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-280"><a href="#cb28-280" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Recall: </span><span class="sc">{</span>best_model_metrics[<span class="st">"recall"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-281"><a href="#cb28-281" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'F1 Score: </span><span class="sc">{</span>best_model_metrics[<span class="st">"f1"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-282"><a href="#cb28-282" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Confusion Matrix:</span><span class="ch">\n</span><span class="sc">{</span>best_model_metrics[<span class="st">"confusion_matrix"</span>]<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Evaluating DecisionTree…</p>
<p>Time taken = 38.33 sec</p>
<p>Best score = 0.882 using params: OrderedDict([(‘ccp_alpha’, 0.001131086677421503), (‘criterion’, ‘entropy’), (‘max_depth’, 24), (‘max_features’, ‘log2’), (‘min_samples_leaf’, 3), (‘min_samples_split’, 3)])<br>
<strong>Test accuracy = <u>0.85</u></strong></p>
<p><img src="images/clipboard-59382711.png" class="img-fluid"></p>
<p><img src="images/clipboard-3531112163.png" class="img-fluid"></p>
<p>Evaluating RandomForest…</p>
<p>Time taken = 891.38 sec Best score = 0.97 using params: OrderedDict([(‘criterion’, ‘entropy’), (‘max_depth’, 27), (‘max_features’, ‘sqrt’), (‘min_samples_leaf’, 2), (‘min_samples_split’, 3), (‘n_estimators’, 82)]) <strong>Test accuracy = <u>0.956</u></strong></p>
<p><img src="images/clipboard-2689837012.png" class="img-fluid"></p>
<p><img src="images/clipboard-925563829.png" class="img-fluid"></p>
<p>Evaluating XGBoost</p>
<p>Time taken = 487.2 sec Best score = 0.973 using params: OrderedDict([(‘colsample_bytree’, 0.8636816590466002), (‘learning_rate’, 0.0645354435221669), (‘max_depth’, 29), (‘n_estimators’, 108), (‘subsample’, 0.9220560088509978)]) <strong>Test accuracy = 0.952</strong></p>
<p><img src="images/clipboard-388346725.png" class="img-fluid"></p>
<p><img src="images/clipboard-1451616604.png" class="img-fluid"></p>
<p>Evaluating LightGBM…</p>
<p>Time taken = 230.12 sec Best score = 0.958 using params: OrderedDict([(‘colsample_bytree’, 0.5133739717626367), (‘learning_rate’, 0.1941545477346783), (‘max_depth’, 24), (‘n_estimators’, 131), (‘subsample’, 0.8487299825534435)]) <strong>Test accuracy = 0.941</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/clipboard-2732899064.png" class="img-fluid figure-img"></p>
<figcaption><img src="images/clipboard-433414607.png" class="img-fluid figure-img"></figcaption>
</figure>
</div>
<p><u><strong>Best Model: RandomForest</strong></u></p>
<p>Accuracy: 0.9561266060795989</p>
<p>Recall: 0.9561266060795989</p>
<p><u><strong>Best Model: RandomForest</strong></u></p>
<p>Accuracy: 0.9561266060795989</p>
<p>Precision: 0.9905793259715808</p>
<p>Recall: 0.9561266060795989</p>
<p>F1 Score: 0.9730480946301695</p>
</section>
<section id="tuning-model-to-industry-and-domain-knowledge-avoiding-false-negatives" class="level3">
<h3 class="anchored" data-anchor-id="tuning-model-to-industry-and-domain-knowledge-avoiding-false-negatives">6. Tuning Model to industry and domain knowledge: avoiding false negatives</h3>
<p>In cancer diagnostics, <strong>avoiding false negatives is particularly crucial</strong>. Missing a cancer diagnosis can lead to delayed treatment, disease progression, and reduced survival rates, which are far more serious than the consequences of false positives, such as psychological distress, additional testing, or unnecessary treatment. Consequently, cancer screening programs tend to prioritize AUC/sensitivity to minimize the number of missed cases, even if it results in a higher rate of false positives.</p>
<p>In this context, we fit and test the models similarly to the previous approach, but we specifically evaluate and <strong>select the best model based on sensitivity</strong>.</p>
<div id="a550a0c4" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BaseModel:</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, cleaned_df, target_column, balance<span class="op">=</span><span class="st">'imbalanced'</span>, n_splits<span class="op">=</span><span class="dv">5</span>, n_repeats<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">123</span>, evaluation_metric<span class="op">=</span><span class="st">'recall'</span>):</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> cleaned_df</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.target_column <span class="op">=</span> target_column</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.balance <span class="op">=</span> balance</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_splits <span class="op">=</span> n_splits</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_repeats <span class="op">=</span> n_repeats</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.random_state <span class="op">=</span> random_state</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.evaluation_metric <span class="op">=</span> evaluation_metric</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prepare features and target variable</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> <span class="va">self</span>.df.drop(columns<span class="op">=</span>[<span class="va">self</span>.target_column])</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> <span class="va">self</span>.df[<span class="va">self</span>.target_column]</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Label encode the target variable</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>        label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> label_encoder.fit_transform(<span class="va">self</span>.y)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Split the data into training and test sets</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_train, <span class="va">self</span>.X_test, <span class="va">self</span>.y_train, <span class="va">self</span>.y_test <span class="op">=</span> train_test_split(</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X, <span class="va">self</span>.y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="va">self</span>.random_state</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize SMOTEENN if balance is set to 'imbalanced'</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.balance <span class="op">==</span> <span class="st">'imbalanced'</span>:</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.smoteenn <span class="op">=</span> SMOTEENN(sampling_strategy<span class="op">=</span><span class="st">'auto'</span>, random_state<span class="op">=</span><span class="va">self</span>.random_state)</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.smoteenn <span class="op">=</span> <span class="va">None</span></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> apply_smoteenn(<span class="va">self</span>):</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.smoteenn:</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.smoteenn.fit_resample(<span class="va">self</span>.X_train, <span class="va">self</span>.y_train)</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.X_train, <span class="va">self</span>.y_train</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> show_matrix(<span class="va">self</span>, matrix, title<span class="op">=</span><span class="st">'Confusion Matrix'</span>):</span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plotting the confusion matrix</span></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>        sns.heatmap(matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">"d"</span>, cmap<span class="op">=</span><span class="st">"Blues"</span>, xticklabels<span class="op">=</span><span class="va">True</span>, yticklabels<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>        plt.title(title)</span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Actual Class'</span>)</span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'Predicted Class'</span>)</span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> plot_roc_auc(<span class="va">self</span>, y_true, y_pred, title):</span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a>        fpr, tpr, _ <span class="op">=</span> roc_curve(y_true, y_pred)</span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a>        roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a>        plt.figure()</span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a>        plt.plot(fpr, tpr, color<span class="op">=</span><span class="st">'darkorange'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'ROC curve (area = </span><span class="sc">%0.2f</span><span class="st">)'</span> <span class="op">%</span> roc_auc)</span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a>        plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'navy'</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a>        plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a>        plt.ylim([<span class="fl">0.0</span>, <span class="fl">1.05</span>])</span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a>        plt.title(title)</span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a>        plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb29-57"><a href="#cb29-57" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb29-58"><a href="#cb29-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> roc_auc</span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-61"><a href="#cb29-61" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> print_feature_importance(<span class="va">self</span>, model_name):</span>
<span id="cb29-62"><a href="#cb29-62" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> <span class="bu">hasattr</span>(<span class="va">self</span>.clf, <span class="st">'feature_importances_'</span>):</span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a>        importance <span class="op">=</span> <span class="va">self</span>.clf.feature_importances_</span>
<span id="cb29-64"><a href="#cb29-64" aria-hidden="true" tabindex="-1"></a>        feature_names <span class="op">=</span> <span class="va">self</span>.X.columns</span>
<span id="cb29-65"><a href="#cb29-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a DataFrame for feature importances and sort it</span></span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a>        feature_importance_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Feature'</span>: feature_names,</span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a>            <span class="st">'Importance'</span>: importance</span>
<span id="cb29-70"><a href="#cb29-70" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb29-71"><a href="#cb29-71" aria-hidden="true" tabindex="-1"></a>        feature_importance_df <span class="op">=</span> feature_importance_df.sort_values(by<span class="op">=</span><span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb29-72"><a href="#cb29-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-73"><a href="#cb29-73" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plot feature importances</span></span>
<span id="cb29-74"><a href="#cb29-74" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb29-75"><a href="#cb29-75" aria-hidden="true" tabindex="-1"></a>        plt.barh(feature_importance_df[<span class="st">'Feature'</span>], feature_importance_df[<span class="st">'Importance'</span>])</span>
<span id="cb29-76"><a href="#cb29-76" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'Feature Importance Score'</span>)</span>
<span id="cb29-77"><a href="#cb29-77" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="ss">f'Feature Importance for </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-78"><a href="#cb29-78" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb29-79"><a href="#cb29-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-80"><a href="#cb29-80" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> print_tree_structure(<span class="va">self</span>):</span>
<span id="cb29-81"><a href="#cb29-81" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> <span class="bu">isinstance</span>(<span class="va">self</span>.clf, tree.DecisionTreeClassifier):</span>
<span id="cb29-82"><a href="#cb29-82" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Plot the tree structure</span></span>
<span id="cb29-83"><a href="#cb29-83" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb29-84"><a href="#cb29-84" aria-hidden="true" tabindex="-1"></a>        plot_tree(<span class="va">self</span>.clf, feature_names<span class="op">=</span><span class="va">self</span>.X.columns, filled<span class="op">=</span><span class="va">True</span>, rounded<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb29-85"><a href="#cb29-85" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">"Decision Tree Visualization"</span>)</span>
<span id="cb29-86"><a href="#cb29-86" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb29-87"><a href="#cb29-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-88"><a href="#cb29-88" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DT(BaseModel):</span>
<span id="cb29-89"><a href="#cb29-89" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb29-90"><a href="#cb29-90" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb29-91"><a href="#cb29-91" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> tree.DecisionTreeClassifier(class_weight<span class="op">=</span><span class="st">'balanced'</span>)</span>
<span id="cb29-92"><a href="#cb29-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-93"><a href="#cb29-93" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_bayesian_search(<span class="va">self</span>):</span>
<span id="cb29-94"><a href="#cb29-94" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running Bayesian Search for Decision Tree..."</span>)</span>
<span id="cb29-95"><a href="#cb29-95" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the parameter space</span></span>
<span id="cb29-96"><a href="#cb29-96" aria-hidden="true" tabindex="-1"></a>        search_spaces <span class="op">=</span> {</span>
<span id="cb29-97"><a href="#cb29-97" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_features'</span>: Categorical([<span class="st">'sqrt'</span>, <span class="st">'log2'</span>]),</span>
<span id="cb29-98"><a href="#cb29-98" aria-hidden="true" tabindex="-1"></a>            <span class="st">'ccp_alpha'</span>: Real(<span class="fl">0.001</span>, <span class="fl">0.1</span>, prior<span class="op">=</span><span class="st">'log-uniform'</span>),</span>
<span id="cb29-99"><a href="#cb29-99" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_depth'</span>: Integer(<span class="dv">20</span>, <span class="dv">30</span>),</span>
<span id="cb29-100"><a href="#cb29-100" aria-hidden="true" tabindex="-1"></a>            <span class="st">'criterion'</span>: Categorical([<span class="st">'gini'</span>, <span class="st">'entropy'</span>]),</span>
<span id="cb29-101"><a href="#cb29-101" aria-hidden="true" tabindex="-1"></a>            <span class="st">'min_samples_split'</span>: Integer(<span class="dv">2</span>, <span class="dv">4</span>),</span>
<span id="cb29-102"><a href="#cb29-102" aria-hidden="true" tabindex="-1"></a>            <span class="st">'min_samples_leaf'</span>: Integer(<span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb29-103"><a href="#cb29-103" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb29-104"><a href="#cb29-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-105"><a href="#cb29-105" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize BayesSearchCV</span></span>
<span id="cb29-106"><a href="#cb29-106" aria-hidden="true" tabindex="-1"></a>        cv <span class="op">=</span> RepeatedStratifiedKFold(n_splits<span class="op">=</span><span class="va">self</span>.n_splits, n_repeats<span class="op">=</span><span class="va">self</span>.n_repeats, random_state<span class="op">=</span><span class="va">self</span>.random_state)</span>
<span id="cb29-107"><a href="#cb29-107" aria-hidden="true" tabindex="-1"></a>        bayes_search <span class="op">=</span> BayesSearchCV(estimator<span class="op">=</span><span class="va">self</span>.clf, search_spaces<span class="op">=</span>search_spaces, cv<span class="op">=</span>cv, n_iter<span class="op">=</span><span class="dv">10</span>, scoring<span class="op">=</span><span class="va">self</span>.evaluation_metric, random_state<span class="op">=</span><span class="va">self</span>.random_state, verbose<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb29-108"><a href="#cb29-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-109"><a href="#cb29-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply SMOTEENN to the training data if balance is 'imbalanced'</span></span>
<span id="cb29-110"><a href="#cb29-110" aria-hidden="true" tabindex="-1"></a>        X_resampled, y_resampled <span class="op">=</span> <span class="va">self</span>.apply_smoteenn()</span>
<span id="cb29-111"><a href="#cb29-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-112"><a href="#cb29-112" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit BayesSearchCV with the resampled data</span></span>
<span id="cb29-113"><a href="#cb29-113" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.time()</span>
<span id="cb29-114"><a href="#cb29-114" aria-hidden="true" tabindex="-1"></a>        bayes_result <span class="op">=</span> bayes_search.fit(X_resampled, y_resampled)</span>
<span id="cb29-115"><a href="#cb29-115" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Time taken = </span><span class="sc">{</span><span class="bu">round</span>(time.time() <span class="op">-</span> t0, <span class="dv">2</span>)<span class="sc">}</span><span class="ss"> sec'</span>)</span>
<span id="cb29-116"><a href="#cb29-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-117"><a href="#cb29-117" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update self.clf with the best estimator</span></span>
<span id="cb29-118"><a href="#cb29-118" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> bayes_result.best_estimator_</span>
<span id="cb29-119"><a href="#cb29-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-120"><a href="#cb29-120" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print best score and parameters</span></span>
<span id="cb29-121"><a href="#cb29-121" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Best score = </span><span class="sc">{</span><span class="bu">round</span>(bayes_result.best_score_, <span class="dv">3</span>)<span class="sc">}</span><span class="ss"> using params: </span><span class="sc">{</span>bayes_result<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-122"><a href="#cb29-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-123"><a href="#cb29-123" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate on test data</span></span>
<span id="cb29-124"><a href="#cb29-124" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> bayes_result.best_estimator_.predict(<span class="va">self</span>.X_test)</span>
<span id="cb29-125"><a href="#cb29-125" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb29-126"><a href="#cb29-126" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Test accuracy = </span><span class="sc">{</span><span class="bu">round</span>(accuracy, <span class="dv">3</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-127"><a href="#cb29-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-128"><a href="#cb29-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-129"><a href="#cb29-129" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Ensure the model is fitted before calling methods</span></span>
<span id="cb29-130"><a href="#cb29-130" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(<span class="va">self</span>.clf, <span class="st">'feature_importances_'</span>) <span class="kw">or</span> <span class="bu">isinstance</span>(<span class="va">self</span>.clf, tree.DecisionTreeClassifier):</span>
<span id="cb29-131"><a href="#cb29-131" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.print_tree_structure()</span>
<span id="cb29-132"><a href="#cb29-132" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.print_feature_importance(<span class="st">"Decision Tree"</span>)</span>
<span id="cb29-133"><a href="#cb29-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-134"><a href="#cb29-134" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> bayes_result, y_pred</span>
<span id="cb29-135"><a href="#cb29-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-136"><a href="#cb29-136" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RandomForest(BaseModel):</span>
<span id="cb29-137"><a href="#cb29-137" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb29-138"><a href="#cb29-138" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb29-139"><a href="#cb29-139" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> RandomForestClassifier(class_weight<span class="op">=</span><span class="st">'balanced'</span>)</span>
<span id="cb29-140"><a href="#cb29-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-141"><a href="#cb29-141" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_bayesian_search(<span class="va">self</span>):</span>
<span id="cb29-142"><a href="#cb29-142" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running Bayesian Search for Random Forest..."</span>)</span>
<span id="cb29-143"><a href="#cb29-143" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the parameter space</span></span>
<span id="cb29-144"><a href="#cb29-144" aria-hidden="true" tabindex="-1"></a>        search_spaces <span class="op">=</span> {</span>
<span id="cb29-145"><a href="#cb29-145" aria-hidden="true" tabindex="-1"></a>            <span class="st">'n_estimators'</span>: Integer(<span class="dv">80</span>, <span class="dv">150</span>),</span>
<span id="cb29-146"><a href="#cb29-146" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_features'</span>: Categorical([<span class="st">'sqrt'</span>, <span class="st">'log2'</span>]),</span>
<span id="cb29-147"><a href="#cb29-147" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_depth'</span>: Integer(<span class="dv">20</span>, <span class="dv">30</span>),</span>
<span id="cb29-148"><a href="#cb29-148" aria-hidden="true" tabindex="-1"></a>            <span class="st">'criterion'</span>: Categorical([<span class="st">'gini'</span>, <span class="st">'entropy'</span>]),</span>
<span id="cb29-149"><a href="#cb29-149" aria-hidden="true" tabindex="-1"></a>            <span class="st">'min_samples_split'</span>: Integer(<span class="dv">2</span>, <span class="dv">4</span>),</span>
<span id="cb29-150"><a href="#cb29-150" aria-hidden="true" tabindex="-1"></a>            <span class="st">'min_samples_leaf'</span>: Integer(<span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb29-151"><a href="#cb29-151" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb29-152"><a href="#cb29-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-153"><a href="#cb29-153" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize BayesSearchCV</span></span>
<span id="cb29-154"><a href="#cb29-154" aria-hidden="true" tabindex="-1"></a>        cv <span class="op">=</span> RepeatedStratifiedKFold(n_splits<span class="op">=</span><span class="va">self</span>.n_splits, n_repeats<span class="op">=</span><span class="va">self</span>.n_repeats, random_state<span class="op">=</span><span class="va">self</span>.random_state)</span>
<span id="cb29-155"><a href="#cb29-155" aria-hidden="true" tabindex="-1"></a>        bayes_search <span class="op">=</span> BayesSearchCV(estimator<span class="op">=</span><span class="va">self</span>.clf, search_spaces<span class="op">=</span>search_spaces, cv<span class="op">=</span>cv, n_iter<span class="op">=</span><span class="dv">10</span>, scoring<span class="op">=</span><span class="va">self</span>.evaluation_metric, random_state<span class="op">=</span><span class="va">self</span>.random_state, verbose<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb29-156"><a href="#cb29-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-157"><a href="#cb29-157" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply SMOTEENN to the training data if balance is 'imbalanced'</span></span>
<span id="cb29-158"><a href="#cb29-158" aria-hidden="true" tabindex="-1"></a>        X_resampled, y_resampled <span class="op">=</span> <span class="va">self</span>.apply_smoteenn()</span>
<span id="cb29-159"><a href="#cb29-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-160"><a href="#cb29-160" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit BayesSearchCV with the resampled data</span></span>
<span id="cb29-161"><a href="#cb29-161" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.time()</span>
<span id="cb29-162"><a href="#cb29-162" aria-hidden="true" tabindex="-1"></a>        bayes_result <span class="op">=</span> bayes_search.fit(X_resampled, y_resampled)</span>
<span id="cb29-163"><a href="#cb29-163" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Time taken = </span><span class="sc">{</span><span class="bu">round</span>(time.time() <span class="op">-</span> t0, <span class="dv">2</span>)<span class="sc">}</span><span class="ss"> sec'</span>)</span>
<span id="cb29-164"><a href="#cb29-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-165"><a href="#cb29-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-166"><a href="#cb29-166" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update self.clf with the best estimator</span></span>
<span id="cb29-167"><a href="#cb29-167" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> bayes_result.best_estimator_</span>
<span id="cb29-168"><a href="#cb29-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-169"><a href="#cb29-169" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print best score and parameters</span></span>
<span id="cb29-170"><a href="#cb29-170" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Best score = </span><span class="sc">{</span><span class="bu">round</span>(bayes_result.best_score_, <span class="dv">3</span>)<span class="sc">}</span><span class="ss"> using params: </span><span class="sc">{</span>bayes_result<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-171"><a href="#cb29-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-172"><a href="#cb29-172" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate on test data</span></span>
<span id="cb29-173"><a href="#cb29-173" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> bayes_result.best_estimator_.predict(<span class="va">self</span>.X_test)</span>
<span id="cb29-174"><a href="#cb29-174" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb29-175"><a href="#cb29-175" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Test accuracy = </span><span class="sc">{</span><span class="bu">round</span>(accuracy, <span class="dv">3</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-176"><a href="#cb29-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-177"><a href="#cb29-177" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.print_feature_importance(<span class="st">"Random Forest"</span>)</span>
<span id="cb29-178"><a href="#cb29-178" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> bayes_result, y_pred</span>
<span id="cb29-179"><a href="#cb29-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-180"><a href="#cb29-180" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> XGBoost(BaseModel):</span>
<span id="cb29-181"><a href="#cb29-181" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb29-182"><a href="#cb29-182" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb29-183"><a href="#cb29-183" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.scale_pos_weight <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.y_train[<span class="va">self</span>.y_train <span class="op">==</span> <span class="dv">0</span>]) <span class="op">/</span> <span class="bu">len</span>(<span class="va">self</span>.y_train[<span class="va">self</span>.y_train <span class="op">==</span> <span class="dv">1</span>])</span>
<span id="cb29-184"><a href="#cb29-184" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> xgb.XGBClassifier(</span>
<span id="cb29-185"><a href="#cb29-185" aria-hidden="true" tabindex="-1"></a>            use_label_encoder<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb29-186"><a href="#cb29-186" aria-hidden="true" tabindex="-1"></a>            eval_metric<span class="op">=</span><span class="st">'logloss'</span>,</span>
<span id="cb29-187"><a href="#cb29-187" aria-hidden="true" tabindex="-1"></a>            scale_pos_weight<span class="op">=</span><span class="va">self</span>.scale_pos_weight</span>
<span id="cb29-188"><a href="#cb29-188" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb29-189"><a href="#cb29-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-190"><a href="#cb29-190" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_bayesian_search(<span class="va">self</span>):</span>
<span id="cb29-191"><a href="#cb29-191" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running Bayesian Search for XGBoost..."</span>)</span>
<span id="cb29-192"><a href="#cb29-192" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the parameter space</span></span>
<span id="cb29-193"><a href="#cb29-193" aria-hidden="true" tabindex="-1"></a>        search_spaces <span class="op">=</span> {</span>
<span id="cb29-194"><a href="#cb29-194" aria-hidden="true" tabindex="-1"></a>            <span class="st">'n_estimators'</span>: Integer(<span class="dv">80</span>, <span class="dv">150</span>),</span>
<span id="cb29-195"><a href="#cb29-195" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_depth'</span>: Integer(<span class="dv">20</span>, <span class="dv">30</span>),</span>
<span id="cb29-196"><a href="#cb29-196" aria-hidden="true" tabindex="-1"></a>            <span class="st">'learning_rate'</span>: Real(<span class="fl">0.01</span>, <span class="fl">0.2</span>, prior<span class="op">=</span><span class="st">'log-uniform'</span>),</span>
<span id="cb29-197"><a href="#cb29-197" aria-hidden="true" tabindex="-1"></a>            <span class="st">'subsample'</span>: Real(<span class="fl">0.5</span>, <span class="fl">1.0</span>),</span>
<span id="cb29-198"><a href="#cb29-198" aria-hidden="true" tabindex="-1"></a>            <span class="st">'colsample_bytree'</span>: Real(<span class="fl">0.5</span>, <span class="fl">1.0</span>)</span>
<span id="cb29-199"><a href="#cb29-199" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb29-200"><a href="#cb29-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-201"><a href="#cb29-201" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize BayesSearchCV</span></span>
<span id="cb29-202"><a href="#cb29-202" aria-hidden="true" tabindex="-1"></a>        cv <span class="op">=</span> RepeatedStratifiedKFold(n_splits<span class="op">=</span><span class="va">self</span>.n_splits, n_repeats<span class="op">=</span><span class="va">self</span>.n_repeats, random_state<span class="op">=</span><span class="va">self</span>.random_state)</span>
<span id="cb29-203"><a href="#cb29-203" aria-hidden="true" tabindex="-1"></a>        bayes_search <span class="op">=</span> BayesSearchCV(estimator<span class="op">=</span><span class="va">self</span>.clf, search_spaces<span class="op">=</span>search_spaces, cv<span class="op">=</span>cv, n_iter<span class="op">=</span><span class="dv">10</span>, scoring<span class="op">=</span><span class="va">self</span>.evaluation_metric, random_state<span class="op">=</span><span class="va">self</span>.random_state, verbose<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb29-204"><a href="#cb29-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-205"><a href="#cb29-205" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply SMOTEENN to the training data if balance is 'imbalanced'</span></span>
<span id="cb29-206"><a href="#cb29-206" aria-hidden="true" tabindex="-1"></a>        X_resampled, y_resampled <span class="op">=</span> <span class="va">self</span>.apply_smoteenn()</span>
<span id="cb29-207"><a href="#cb29-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-208"><a href="#cb29-208" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit BayesSearchCV with the resampled data</span></span>
<span id="cb29-209"><a href="#cb29-209" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.time()</span>
<span id="cb29-210"><a href="#cb29-210" aria-hidden="true" tabindex="-1"></a>        bayes_result <span class="op">=</span> bayes_search.fit(X_resampled, y_resampled)</span>
<span id="cb29-211"><a href="#cb29-211" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Time taken = </span><span class="sc">{</span><span class="bu">round</span>(time.time() <span class="op">-</span> t0, <span class="dv">2</span>)<span class="sc">}</span><span class="ss"> sec'</span>)</span>
<span id="cb29-212"><a href="#cb29-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-213"><a href="#cb29-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-214"><a href="#cb29-214" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update self.clf with the best estimator</span></span>
<span id="cb29-215"><a href="#cb29-215" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> bayes_result.best_estimator_</span>
<span id="cb29-216"><a href="#cb29-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-217"><a href="#cb29-217" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print best score and parameters</span></span>
<span id="cb29-218"><a href="#cb29-218" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Best score = </span><span class="sc">{</span><span class="bu">round</span>(bayes_result.best_score_, <span class="dv">3</span>)<span class="sc">}</span><span class="ss"> using params: </span><span class="sc">{</span>bayes_result<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-219"><a href="#cb29-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-220"><a href="#cb29-220" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate on test data</span></span>
<span id="cb29-221"><a href="#cb29-221" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> bayes_result.best_estimator_.predict(<span class="va">self</span>.X_test)</span>
<span id="cb29-222"><a href="#cb29-222" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb29-223"><a href="#cb29-223" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Test accuracy = </span><span class="sc">{</span><span class="bu">round</span>(accuracy, <span class="dv">3</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-224"><a href="#cb29-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-225"><a href="#cb29-225" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.print_feature_importance(<span class="st">"XGBoost"</span>)</span>
<span id="cb29-226"><a href="#cb29-226" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> bayes_result, y_pred</span>
<span id="cb29-227"><a href="#cb29-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-228"><a href="#cb29-228" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LightGBM(BaseModel):</span>
<span id="cb29-229"><a href="#cb29-229" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb29-230"><a href="#cb29-230" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb29-231"><a href="#cb29-231" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.scale_pos_weight <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.y_train[<span class="va">self</span>.y_train <span class="op">==</span> <span class="dv">0</span>]) <span class="op">/</span> <span class="bu">len</span>(<span class="va">self</span>.y_train[<span class="va">self</span>.y_train <span class="op">==</span> <span class="dv">1</span>])</span>
<span id="cb29-232"><a href="#cb29-232" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.class_weight <span class="op">=</span> {<span class="dv">0</span>: <span class="dv">1</span>, <span class="dv">1</span>: <span class="va">self</span>.scale_pos_weight}</span>
<span id="cb29-233"><a href="#cb29-233" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> LGBMClassifier(class_weight<span class="op">=</span><span class="va">self</span>.class_weight)</span>
<span id="cb29-234"><a href="#cb29-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-235"><a href="#cb29-235" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_bayesian_search(<span class="va">self</span>):</span>
<span id="cb29-236"><a href="#cb29-236" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Running Bayesian Search for LightGBM..."</span>)</span>
<span id="cb29-237"><a href="#cb29-237" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the parameter space</span></span>
<span id="cb29-238"><a href="#cb29-238" aria-hidden="true" tabindex="-1"></a>        search_spaces <span class="op">=</span> {</span>
<span id="cb29-239"><a href="#cb29-239" aria-hidden="true" tabindex="-1"></a>            <span class="st">'n_estimators'</span>: Integer(<span class="dv">80</span>, <span class="dv">150</span>),</span>
<span id="cb29-240"><a href="#cb29-240" aria-hidden="true" tabindex="-1"></a>            <span class="st">'max_depth'</span>: Integer(<span class="dv">20</span>, <span class="dv">30</span>),</span>
<span id="cb29-241"><a href="#cb29-241" aria-hidden="true" tabindex="-1"></a>            <span class="st">'learning_rate'</span>: Real(<span class="fl">0.01</span>, <span class="fl">0.2</span>, prior<span class="op">=</span><span class="st">'log-uniform'</span>),</span>
<span id="cb29-242"><a href="#cb29-242" aria-hidden="true" tabindex="-1"></a>            <span class="st">'subsample'</span>: Real(<span class="fl">0.5</span>, <span class="fl">1.0</span>),</span>
<span id="cb29-243"><a href="#cb29-243" aria-hidden="true" tabindex="-1"></a>            <span class="st">'colsample_bytree'</span>: Real(<span class="fl">0.5</span>, <span class="fl">1.0</span>)</span>
<span id="cb29-244"><a href="#cb29-244" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb29-245"><a href="#cb29-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-246"><a href="#cb29-246" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize BayesSearchCV</span></span>
<span id="cb29-247"><a href="#cb29-247" aria-hidden="true" tabindex="-1"></a>        cv <span class="op">=</span> RepeatedStratifiedKFold(n_splits<span class="op">=</span><span class="va">self</span>.n_splits, n_repeats<span class="op">=</span><span class="va">self</span>.n_repeats, random_state<span class="op">=</span><span class="va">self</span>.random_state)</span>
<span id="cb29-248"><a href="#cb29-248" aria-hidden="true" tabindex="-1"></a>        bayes_search <span class="op">=</span> BayesSearchCV(estimator<span class="op">=</span><span class="va">self</span>.clf, search_spaces<span class="op">=</span>search_spaces, cv<span class="op">=</span>cv, n_iter<span class="op">=</span><span class="dv">10</span>, scoring<span class="op">=</span><span class="va">self</span>.evaluation_metric, random_state<span class="op">=</span><span class="va">self</span>.random_state, verbose<span class="op">=</span><span class="dv">1</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb29-249"><a href="#cb29-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-250"><a href="#cb29-250" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply SMOTEENN to the training data if balance is 'imbalanced'</span></span>
<span id="cb29-251"><a href="#cb29-251" aria-hidden="true" tabindex="-1"></a>        X_resampled, y_resampled <span class="op">=</span> <span class="va">self</span>.apply_smoteenn()</span>
<span id="cb29-252"><a href="#cb29-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-253"><a href="#cb29-253" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fit BayesSearchCV with the resampled data</span></span>
<span id="cb29-254"><a href="#cb29-254" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.time()</span>
<span id="cb29-255"><a href="#cb29-255" aria-hidden="true" tabindex="-1"></a>        bayes_result <span class="op">=</span> bayes_search.fit(X_resampled, y_resampled)</span>
<span id="cb29-256"><a href="#cb29-256" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Time taken = </span><span class="sc">{</span><span class="bu">round</span>(time.time() <span class="op">-</span> t0, <span class="dv">2</span>)<span class="sc">}</span><span class="ss"> sec'</span>)</span>
<span id="cb29-257"><a href="#cb29-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-258"><a href="#cb29-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-259"><a href="#cb29-259" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update self.clf with the best estimator</span></span>
<span id="cb29-260"><a href="#cb29-260" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.clf <span class="op">=</span> bayes_result.best_estimator_</span>
<span id="cb29-261"><a href="#cb29-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-262"><a href="#cb29-262" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print best score and parameters</span></span>
<span id="cb29-263"><a href="#cb29-263" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Best score = </span><span class="sc">{</span><span class="bu">round</span>(bayes_result.best_score_, <span class="dv">3</span>)<span class="sc">}</span><span class="ss"> using params: </span><span class="sc">{</span>bayes_result<span class="sc">.</span>best_params_<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-264"><a href="#cb29-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-265"><a href="#cb29-265" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate on test data</span></span>
<span id="cb29-266"><a href="#cb29-266" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> bayes_result.best_estimator_.predict(<span class="va">self</span>.X_test)</span>
<span id="cb29-267"><a href="#cb29-267" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(<span class="va">self</span>.y_test, y_pred)</span>
<span id="cb29-268"><a href="#cb29-268" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Test accuracy = </span><span class="sc">{</span><span class="bu">round</span>(accuracy, <span class="dv">3</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-269"><a href="#cb29-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-270"><a href="#cb29-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-271"><a href="#cb29-271" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.print_feature_importance(<span class="st">"LightGBM"</span>)</span>
<span id="cb29-272"><a href="#cb29-272" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> bayes_result, y_pred</span>
<span id="cb29-273"><a href="#cb29-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-274"><a href="#cb29-274" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AutoML:</span>
<span id="cb29-275"><a href="#cb29-275" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, cleaned_df, target_column, balance<span class="op">=</span><span class="st">'imbalanced'</span>, n_splits<span class="op">=</span><span class="dv">5</span>, n_repeats<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">123</span>, evaluation_metric<span class="op">=</span><span class="st">'recall'</span>):</span>
<span id="cb29-276"><a href="#cb29-276" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cleaned_df <span class="op">=</span> cleaned_df</span>
<span id="cb29-277"><a href="#cb29-277" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.target_column <span class="op">=</span> target_column</span>
<span id="cb29-278"><a href="#cb29-278" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.balance <span class="op">=</span> balance</span>
<span id="cb29-279"><a href="#cb29-279" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_splits <span class="op">=</span> n_splits</span>
<span id="cb29-280"><a href="#cb29-280" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_repeats <span class="op">=</span> n_repeats</span>
<span id="cb29-281"><a href="#cb29-281" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.random_state <span class="op">=</span> random_state</span>
<span id="cb29-282"><a href="#cb29-282" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.evaluation_metric <span class="op">=</span> evaluation_metric</span>
<span id="cb29-283"><a href="#cb29-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-284"><a href="#cb29-284" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize model classes</span></span>
<span id="cb29-285"><a href="#cb29-285" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.models <span class="op">=</span> {</span>
<span id="cb29-286"><a href="#cb29-286" aria-hidden="true" tabindex="-1"></a>            <span class="st">'DecisionTree'</span>: DT(cleaned_df, target_column, balance, n_splits, n_repeats, random_state),</span>
<span id="cb29-287"><a href="#cb29-287" aria-hidden="true" tabindex="-1"></a>            <span class="st">'RandomForest'</span>: RandomForest(cleaned_df, target_column, balance, n_splits, n_repeats, random_state),</span>
<span id="cb29-288"><a href="#cb29-288" aria-hidden="true" tabindex="-1"></a>            <span class="st">'XGBoost'</span>: XGBoost(cleaned_df, target_column, balance, n_splits, n_repeats, random_state),</span>
<span id="cb29-289"><a href="#cb29-289" aria-hidden="true" tabindex="-1"></a>            <span class="st">'LightGBM'</span>: LightGBM(cleaned_df, target_column, balance, n_splits, n_repeats, random_state)</span>
<span id="cb29-290"><a href="#cb29-290" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb29-291"><a href="#cb29-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-292"><a href="#cb29-292" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> evaluate_models(<span class="va">self</span>):</span>
<span id="cb29-293"><a href="#cb29-293" aria-hidden="true" tabindex="-1"></a>        results <span class="op">=</span> {}</span>
<span id="cb29-294"><a href="#cb29-294" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, model <span class="kw">in</span> <span class="va">self</span>.models.items():</span>
<span id="cb29-295"><a href="#cb29-295" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Evaluating </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">...'</span>)</span>
<span id="cb29-296"><a href="#cb29-296" aria-hidden="true" tabindex="-1"></a>            best_model, y_pred <span class="op">=</span> model.run_bayesian_search()</span>
<span id="cb29-297"><a href="#cb29-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-298"><a href="#cb29-298" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute metrics</span></span>
<span id="cb29-299"><a href="#cb29-299" aria-hidden="true" tabindex="-1"></a>            accuracy <span class="op">=</span> accuracy_score(model.y_test, y_pred)</span>
<span id="cb29-300"><a href="#cb29-300" aria-hidden="true" tabindex="-1"></a>            precision <span class="op">=</span> precision_score(model.y_test, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb29-301"><a href="#cb29-301" aria-hidden="true" tabindex="-1"></a>            recall <span class="op">=</span> recall_score(model.y_test, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb29-302"><a href="#cb29-302" aria-hidden="true" tabindex="-1"></a>            f1 <span class="op">=</span> f1_score(model.y_test, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb29-303"><a href="#cb29-303" aria-hidden="true" tabindex="-1"></a>            cm <span class="op">=</span> confusion_matrix(model.y_test, y_pred)</span>
<span id="cb29-304"><a href="#cb29-304" aria-hidden="true" tabindex="-1"></a>            tn, fp, fn, tp <span class="op">=</span> cm.ravel()</span>
<span id="cb29-305"><a href="#cb29-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-306"><a href="#cb29-306" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate sensitivity (recall for positive class)</span></span>
<span id="cb29-307"><a href="#cb29-307" aria-hidden="true" tabindex="-1"></a>            sensitivity <span class="op">=</span> recall_score(model.y_test, y_pred, pos_label<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb29-308"><a href="#cb29-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-309"><a href="#cb29-309" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate specificity</span></span>
<span id="cb29-310"><a href="#cb29-310" aria-hidden="true" tabindex="-1"></a>            specificity <span class="op">=</span> tn <span class="op">/</span> (tn <span class="op">+</span> fp) <span class="cf">if</span> (tn <span class="op">+</span> fp) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb29-311"><a href="#cb29-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-312"><a href="#cb29-312" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Determine false negatives</span></span>
<span id="cb29-313"><a href="#cb29-313" aria-hidden="true" tabindex="-1"></a>            false_negatives <span class="op">=</span> fn</span>
<span id="cb29-314"><a href="#cb29-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-315"><a href="#cb29-315" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Determine false positives</span></span>
<span id="cb29-316"><a href="#cb29-316" aria-hidden="true" tabindex="-1"></a>            false_positives <span class="op">=</span> fp</span>
<span id="cb29-317"><a href="#cb29-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-318"><a href="#cb29-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-319"><a href="#cb29-319" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ROC and AUC</span></span>
<span id="cb29-320"><a href="#cb29-320" aria-hidden="true" tabindex="-1"></a>            y_test_binarized <span class="op">=</span> label_binarize(model.y_test, classes<span class="op">=</span>np.unique(model.y_test))</span>
<span id="cb29-321"><a href="#cb29-321" aria-hidden="true" tabindex="-1"></a>            y_pred_binarized <span class="op">=</span> label_binarize(y_pred, classes<span class="op">=</span>np.unique(model.y_test))</span>
<span id="cb29-322"><a href="#cb29-322" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> y_test_binarized.shape[<span class="dv">1</span>] <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb29-323"><a href="#cb29-323" aria-hidden="true" tabindex="-1"></a>                auc_scores <span class="op">=</span> []</span>
<span id="cb29-324"><a href="#cb29-324" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_binarized.shape[<span class="dv">1</span>]):</span>
<span id="cb29-325"><a href="#cb29-325" aria-hidden="true" tabindex="-1"></a>                    auc <span class="op">=</span> model.plot_roc_auc(y_test_binarized[:, i], y_pred_binarized[:, i], <span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> ROC Curve for Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-326"><a href="#cb29-326" aria-hidden="true" tabindex="-1"></a>                    auc_scores.append(auc)</span>
<span id="cb29-327"><a href="#cb29-327" aria-hidden="true" tabindex="-1"></a>                mean_auc <span class="op">=</span> np.mean(auc_scores)</span>
<span id="cb29-328"><a href="#cb29-328" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb29-329"><a href="#cb29-329" aria-hidden="true" tabindex="-1"></a>                auc <span class="op">=</span> model.plot_roc_auc(model.y_test, y_pred, <span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> ROC Curve'</span>)</span>
<span id="cb29-330"><a href="#cb29-330" aria-hidden="true" tabindex="-1"></a>                mean_auc <span class="op">=</span> auc</span>
<span id="cb29-331"><a href="#cb29-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-332"><a href="#cb29-332" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Store results</span></span>
<span id="cb29-333"><a href="#cb29-333" aria-hidden="true" tabindex="-1"></a>            results[name] <span class="op">=</span> {</span>
<span id="cb29-334"><a href="#cb29-334" aria-hidden="true" tabindex="-1"></a>                <span class="st">'accuracy'</span>: accuracy,</span>
<span id="cb29-335"><a href="#cb29-335" aria-hidden="true" tabindex="-1"></a>                <span class="st">'precision'</span>: precision,</span>
<span id="cb29-336"><a href="#cb29-336" aria-hidden="true" tabindex="-1"></a>                <span class="st">'recall'</span>: recall,</span>
<span id="cb29-337"><a href="#cb29-337" aria-hidden="true" tabindex="-1"></a>                <span class="st">'f1'</span>: f1,</span>
<span id="cb29-338"><a href="#cb29-338" aria-hidden="true" tabindex="-1"></a>                <span class="st">'false_negatives'</span>: false_negatives,</span>
<span id="cb29-339"><a href="#cb29-339" aria-hidden="true" tabindex="-1"></a>                <span class="st">'false_positives'</span>: false_positives,</span>
<span id="cb29-340"><a href="#cb29-340" aria-hidden="true" tabindex="-1"></a>                <span class="st">'sensitivity'</span>: sensitivity,</span>
<span id="cb29-341"><a href="#cb29-341" aria-hidden="true" tabindex="-1"></a>                <span class="st">'specificity'</span>: specificity,</span>
<span id="cb29-342"><a href="#cb29-342" aria-hidden="true" tabindex="-1"></a>                <span class="st">'classification_report'</span>: classification_report(model.y_test, y_pred),</span>
<span id="cb29-343"><a href="#cb29-343" aria-hidden="true" tabindex="-1"></a>                <span class="st">'confusion_matrix'</span>: model.show_matrix(cm),</span>
<span id="cb29-344"><a href="#cb29-344" aria-hidden="true" tabindex="-1"></a>                <span class="st">'auc'</span>: mean_auc</span>
<span id="cb29-345"><a href="#cb29-345" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb29-346"><a href="#cb29-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-347"><a href="#cb29-347" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Print Classification Report, Confusion Matrix, and AUC</span></span>
<span id="cb29-348"><a href="#cb29-348" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'Classification Report for </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">:</span><span class="ch">\n</span><span class="sc">{</span>results[name][<span class="st">"classification_report"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-349"><a href="#cb29-349" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'AUC Score for </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>results[name][<span class="st">"auc"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-350"><a href="#cb29-350" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'Sensitivity for </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>results[name][<span class="st">"sensitivity"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-351"><a href="#cb29-351" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'Specificity for </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>results[name][<span class="st">"specificity"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-352"><a href="#cb29-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-353"><a href="#cb29-353" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Determine the best model</span></span>
<span id="cb29-354"><a href="#cb29-354" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.evaluation_metric <span class="kw">in</span> [<span class="st">'false_negatives'</span>, <span class="st">'false_positives'</span>]:</span>
<span id="cb29-355"><a href="#cb29-355" aria-hidden="true" tabindex="-1"></a>            sorted_results <span class="op">=</span> <span class="bu">sorted</span>(results.items(), key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>][<span class="va">self</span>.evaluation_metric])</span>
<span id="cb29-356"><a href="#cb29-356" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb29-357"><a href="#cb29-357" aria-hidden="true" tabindex="-1"></a>            sorted_results <span class="op">=</span> <span class="bu">sorted</span>(results.items(), key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>][<span class="va">self</span>.evaluation_metric], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb29-358"><a href="#cb29-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-359"><a href="#cb29-359" aria-hidden="true" tabindex="-1"></a>        best_model_name, best_model_metrics <span class="op">=</span> sorted_results[<span class="dv">0</span>]</span>
<span id="cb29-360"><a href="#cb29-360" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Best Model: </span><span class="sc">{</span>best_model_name<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-361"><a href="#cb29-361" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Accuracy: </span><span class="sc">{</span>best_model_metrics[<span class="st">"accuracy"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-362"><a href="#cb29-362" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Precision: </span><span class="sc">{</span>best_model_metrics[<span class="st">"precision"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-363"><a href="#cb29-363" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Recall: </span><span class="sc">{</span>best_model_metrics[<span class="st">"recall"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-364"><a href="#cb29-364" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'F1 Score: </span><span class="sc">{</span>best_model_metrics[<span class="st">"f1"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-365"><a href="#cb29-365" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'False Negatives: </span><span class="sc">{</span>best_model_metrics[<span class="st">"false_negatives"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-366"><a href="#cb29-366" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'False Positives: </span><span class="sc">{</span>best_model_metrics[<span class="st">"false_positives"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-367"><a href="#cb29-367" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'AUC Score: </span><span class="sc">{</span>best_model_metrics[<span class="st">"auc"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-368"><a href="#cb29-368" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Confusion Matrix:</span><span class="ch">\n</span><span class="sc">{</span>best_model_metrics[<span class="st">"confusion_matrix"</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb29-369"><a href="#cb29-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-370"><a href="#cb29-370" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> best_model_name, best_model_metrics</span>
<span id="cb29-371"><a href="#cb29-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-372"><a href="#cb29-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-373"><a href="#cb29-373" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage</span></span>
<span id="cb29-374"><a href="#cb29-374" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming `reduced_df` is your DataFrame and 'thirtydaymortality' is your target column</span></span>
<span id="cb29-375"><a href="#cb29-375" aria-hidden="true" tabindex="-1"></a>auto_ml <span class="op">=</span> AutoML(reduced_df, target_column<span class="op">=</span><span class="st">'thirtydaymortality'</span>, balance<span class="op">=</span><span class="st">'imbalanced'</span>, evaluation_metric<span class="op">=</span><span class="st">'auc'</span>)</span>
<span id="cb29-376"><a href="#cb29-376" aria-hidden="true" tabindex="-1"></a>best_model_name, best_model_metrics <span class="op">=</span> auto_ml.evaluate_models()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Evaluating DecisionTree…</p>
<p>Time taken = 43.36 sec</p>
<p>Best score = 0.921 using params: OrderedDict([(‘ccp_alpha’, 0.001131086677421503), (‘criterion’, ‘entropy’), (‘max_depth’, 24), (‘max_features’, ‘log2’), (‘min_samples_leaf’, 3), (‘min_samples_split’, 3)])</p>
<p><strong>Test accuracy = 0.853</strong></p>
<p><img src="images/clipboard-2144372909.png" class="img-fluid" width="553"></p>
<p><img src="images/clipboard-3271840178.png" class="img-fluid" width="424"></p>
<p><img src="images/clipboard-3492499816.png" class="img-fluid" width="419"></p>
<p><img src="images/clipboard-759995167.png" class="img-fluid" width="410"></p>
<p>Evaluating RandomForest…</p>
<p>Time taken = 1131.54 sec Best score = 0.99 using params: OrderedDict([(‘criterion’, ‘entropy’), (‘max_depth’, 27), (‘max_features’, ‘sqrt’), (‘min_samples_leaf’, 2), (‘min_samples_split’, 3), (‘n_estimators’, 82)])</p>
<p><strong>Test accuracy = 0.975</strong></p>
<p><img src="images/clipboard-472869976.png" class="img-fluid" width="581"></p>
<p><img src="images/clipboard-3293245603.png" class="img-fluid" width="427"></p>
<p><img src="images/clipboard-3815466419.png" class="img-fluid" width="412"></p>
<p><img src="images/clipboard-1034884692.png" class="img-fluid" width="416"></p>
<p>Evaluating XGBoost…</p>
<p>Time taken = 569.31 sec Best score = 0.999 using params: OrderedDict([(‘colsample_bytree’, 0.6654338738457878), (‘learning_rate’, 0.038882847597077025), (‘max_depth’, 21), (‘n_estimators’, 127), (‘subsample’, 0.7398225001914931)])</p>
<p><strong>Test accuracy = 0.91</strong></p>
<p><img src="images/clipboard-1553979538.png" class="img-fluid" width="560"></p>
<p><img src="images/clipboard-1898839044.png" class="img-fluid" width="440"></p>
<p><img src="images/clipboard-414980368.png" class="img-fluid" width="447"></p>
<p><img src="images/clipboard-2446320798.png" class="img-fluid" width="446"></p>
<p>Evaluating LightGBM…</p>
<p>Time taken = 259.26 sec Best score = 1.0 using params: OrderedDict([(‘colsample_bytree’, 0.8840100626990215), (‘learning_rate’, 0.017347709137475083), (‘max_depth’, 20), (‘n_estimators’, 132), (‘subsample’, 0.9722507666816909)])</p>
<p><strong>Test accuracy = 0.67</strong></p>
<p><img src="images/clipboard-2294252204.png" class="img-fluid" width="554"></p>
<p><img src="images/clipboard-3824491189.png" class="img-fluid" width="432"></p>
<p><img src="images/clipboard-4063952050.png" class="img-fluid" width="447"></p>
<p><img src="images/clipboard-1205127027.png" class="img-fluid" width="447"></p>
</section>
<section id="model-evaluation-summary" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation-summary">7. Model Evaluation Summary</h3>
<section id="decision-tree" class="level4">
<h4 class="anchored" data-anchor-id="decision-tree">1. Decision Tree</h4>
<p><strong>Best Parameters:</strong> - <code>ccp_alpha</code>: 0.0011 - <code>criterion</code>: ‘entropy’ - <code>max_depth</code>: 24 - <code>max_features</code>: ‘log2’ - <code>min_samples_leaf</code>: 3 - <code>min_samples_split</code>: 3</p>
<p><strong>Test Accuracy:</strong> 0.853</p>
<p><strong>Classification Report:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Metric</th>
<th>Class 0</th>
<th>Class 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Precision</td>
<td>1.00</td>
<td>0.03</td>
</tr>
<tr class="even">
<td>Recall</td>
<td>0.85</td>
<td>0.76</td>
</tr>
<tr class="odd">
<td>F1-Score</td>
<td>0.92</td>
<td>0.06</td>
</tr>
<tr class="even">
<td>Macro Avg</td>
<td>0.51</td>
<td>0.81</td>
</tr>
<tr class="odd">
<td>Weighted Avg</td>
<td>0.99</td>
<td>0.85</td>
</tr>
</tbody>
</table>
<p><strong>AUC Score:</strong> 0.808</p>
<p><strong>Sensitivity:</strong> 0.764<br>
<strong>Specificity:</strong> 0.853</p>
<p><strong>Discussion:</strong></p>
<ul>
<li><strong>Strengths:</strong> The Decision Tree model has high accuracy (0.853) and relatively good recall for the majority class (0.76 for class 1). The AUC score of 0.808 indicates decent performance in distinguishing between classes.</li>
<li><strong>Weaknesses:</strong> Precision for the minority class is very low (0.03), and the F1-Score is also very low (0.06), reflecting poor performance in correctly identifying the positive class (class 1). The model struggles with class imbalance.</li>
</ul>
</section>
<section id="random-forest" class="level4">
<h4 class="anchored" data-anchor-id="random-forest">2. Random Forest</h4>
<p><strong>Best Parameters:</strong> - <code>criterion</code>: ‘entropy’ - <code>max_depth</code>: 27 - <code>max_features</code>: ‘sqrt’ - <code>min_samples_leaf</code>: 2 - <code>min_samples_split</code>: 3 - <code>n_estimators</code>: 82</p>
<p><strong>Test Accuracy:</strong> 0.975</p>
<p><strong>Classification Report:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Metric</th>
<th>Class 0</th>
<th>Class 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Precision</td>
<td>1.00</td>
<td>0.09</td>
</tr>
<tr class="even">
<td>Recall</td>
<td>0.98</td>
<td>0.35</td>
</tr>
<tr class="odd">
<td>F1-Score</td>
<td>0.99</td>
<td>0.14</td>
</tr>
<tr class="even">
<td>Macro Avg</td>
<td>0.54</td>
<td>0.66</td>
</tr>
<tr class="odd">
<td>Weighted Avg</td>
<td>0.99</td>
<td>0.97</td>
</tr>
</tbody>
</table>
<p><strong>AUC Score:</strong> 0.665</p>
<p><strong>Sensitivity:</strong> 0.351<br>
<strong>Specificity:</strong> 0.978</p>
<p><strong>Discussion:</strong></p>
<ul>
<li><strong>Strengths:</strong> High accuracy (0.975) and good recall for the majority class (0.35 for class 1). The Random Forest model shows strong performance for the majority class.</li>
<li><strong>Weaknesses:</strong> Precision for the minority class is extremely low (0.09), indicating poor performance in identifying the positive class. The AUC score of 0.665 suggests weaker discriminatory performance compared to other models.</li>
</ul>
</section>
<section id="xgboost" class="level4">
<h4 class="anchored" data-anchor-id="xgboost">3. XGBoost</h4>
<p><strong>Best Parameters:</strong> - <code>colsample_bytree</code>: 0.665 - <code>learning_rate</code>: 0.039 - <code>max_depth</code>: 21 - <code>n_estimators</code>: 127 - <code>subsample</code>: 0.740</p>
<p><strong>Test Accuracy:</strong> 0.910</p>
<p><strong>Classification Report:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Metric</th>
<th>Class 0</th>
<th>Class 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Precision</td>
<td>1.00</td>
<td>0.03</td>
</tr>
<tr class="even">
<td>Recall</td>
<td>0.91</td>
<td>0.53</td>
</tr>
<tr class="odd">
<td>F1-Score</td>
<td>0.95</td>
<td>0.06</td>
</tr>
<tr class="even">
<td>Macro Avg</td>
<td>0.52</td>
<td>0.72</td>
</tr>
<tr class="odd">
<td>Weighted Avg</td>
<td>0.99</td>
<td>0.91</td>
</tr>
</tbody>
</table>
<p><strong>AUC Score:</strong> 0.723</p>
<p><strong>Sensitivity:</strong> 0.534<br>
<strong>Specificity:</strong> 0.913</p>
<p><strong>Discussion:</strong></p>
<ul>
<li><strong>Strengths:</strong> High accuracy (0.910) and good recall for the majority class (0.53 for class 1).</li>
<li><strong>Weaknesses:</strong> The XGBoost model has low precision (0.03) and F1-Score (0.06) for the minority class. The AUC score of 0.723 shows limited effectiveness in distinguishing between classes.</li>
</ul>
</section>
<section id="lightgbm" class="level4">
<h4 class="anchored" data-anchor-id="lightgbm">4. LightGBM</h4>
<p><strong>Best Parameters:</strong> - <code>colsample_bytree</code>: 0.884 - <code>learning_rate</code>: 0.017 - <code>max_depth</code>: 20 - <code>n_estimators</code>: 132 - <code>subsample</code>: 0.972</p>
<p><strong>Test Accuracy:</strong> 0.670</p>
<p><strong>Classification Report:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Metric</th>
<th>Class 0</th>
<th>Class 1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Precision</td>
<td>1.00</td>
<td>0.01</td>
</tr>
<tr class="even">
<td>Recall</td>
<td>0.67</td>
<td>0.84</td>
</tr>
<tr class="odd">
<td>F1-Score</td>
<td>0.80</td>
<td>0.03</td>
</tr>
<tr class="even">
<td>Macro Avg</td>
<td>0.51</td>
<td>0.76</td>
</tr>
<tr class="odd">
<td>Weighted Avg</td>
<td>0.99</td>
<td>0.67</td>
</tr>
</tbody>
</table>
<p><strong>AUC Score:</strong> 0.757</p>
<p><strong>Sensitivity:</strong> 0.845<br>
<strong>Specificity:</strong> 0.669</p>
<p><strong>Discussion:</strong></p>
<ul>
<li><strong>Strengths:</strong> High recall for the minority class (0.84). The model achieves a good balance between precision and recall for the majority class.</li>
<li><strong>Weaknesses:</strong> Low precision (0.01) and F1-Score (0.03) for the minority class. The AUC score of 0.757 indicates limited ability to discriminate between the classes.</li>
</ul>
</section>
<section id="best-model-auc-decision-tree" class="level4">
<h4 class="anchored" data-anchor-id="best-model-auc-decision-tree">Best Model (AUC): Decision Tree</h4>
<p><strong>Accuracy:</strong> 0.853<br>
<strong>Precision:</strong> 0.993 (for class 0), 0.03 (for class 1)<br>
<strong>Recall:</strong> 0.85 (for class 0), 0.76 (for class 1)<br>
<strong>F1 Score:</strong> 0.92 (for class 0), 0.06 (for class 1)<br>
<strong>False Negatives:</strong> 35<br>
<strong>AUC Score:</strong> 0.808</p>
<p><strong>Discussion:</strong></p>
<ul>
<li><strong>Strengths:</strong> The Decision Tree model has the highest recall for the minority class among the models evaluated, with an AUC score of 0.808, indicating better performance in distinguishing between classes compared to other models.</li>
<li><strong>Weaknesses:</strong> Precision for the minority class remains low, which is a common issue in imbalanced datasets. The F1-Score for the minority class is also low, indicating that while the recall is better, precision is lacking.</li>
</ul>
</section>
<section id="overall-recommendations" class="level4">
<h4 class="anchored" data-anchor-id="overall-recommendations">Overall Recommendations</h4>
<p>To improve performance, consider the following strategies:</p>
<ul>
<li><strong>Resampling:</strong> Experiment with more methods to deal with imbalance.</li>
<li><strong>Class Weights:</strong> Adjust class weights in the model to give more importance to the minority class.</li>
<li><strong>Ensemble Methods:</strong> Combine predictions from multiple models to improve performance on the minority class.</li>
<li><strong>SVMs:</strong> Consider using SVMs with dimensionality reduction techniques instead of dropping potentially critical variables.</li>
</ul>
</section>
<section id="performance-metrics-comparison" class="level4">
<h4 class="anchored" data-anchor-id="performance-metrics-comparison">Performance Metrics Comparison</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall (Sensitivity)</th>
<th>Specificity</th>
<th>AUC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Decision Tree</td>
<td>0.853</td>
<td>0.993</td>
<td>0.764</td>
<td>0.853</td>
<td>0.808</td>
</tr>
<tr class="even">
<td>Random Forest</td>
<td>0.975</td>
<td>0.990</td>
<td>0.351</td>
<td>0.978</td>
<td>0.665</td>
</tr>
<tr class="odd">
<td>XGBoost</td>
<td>0.910</td>
<td>0.999</td>
<td>0.534</td>
<td>0.913</td>
<td>0.723</td>
</tr>
<tr class="even">
<td>LightGBM</td>
<td>0.670</td>
<td>1.000</td>
<td>0.845</td>
<td>0.669</td>
<td>0.757</td>
</tr>
</tbody>
</table>
<div class="notebox lightbulb">
<p><strong>Upon fine-tuning to context: Minimising False Negatives</strong></p>
<p>The <strong>Decision Tree</strong> model performs best in terms of recall for the minority class and AUC score among the models evaluated.</p>
<p>HOWEVER, sensitivity score (0.845) is higher for <strong>LightGBM</strong> instead even though it has less AUC score (0.757). <strong>LightGBM</strong> is the ideal model for our scenario.</p>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://quarto.org/">
<p>Published with Quarto |</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://www.netlify.com/">
<p>Hosted by Netlify</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>