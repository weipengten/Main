<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.555">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ten Wei Peng">
<meta name="dcterms.date" content="2024-07-20">
<meta name="description" content="Deep Learning with CIFAR-10">

<title>Wei Peng’s Analytics Journey - Image Learning on CIFAR-10</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Wei Peng’s Analytics Journey</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-rstudio" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">RStudio</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-rstudio">    
        <li>
    <a class="dropdown-item" href="../RStudio/Geospatial_Analytics/Analyzing_Bus_Traffic_Flows/Analyzing_Bus_Traffic_Flows.html">
 <span class="dropdown-text">Analyzing Bus Traffic Flows in Singapore</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../RStudio/Visual_Analytics/Creating_Better_Visualisations/Creating_Better_Visualisations.html">
 <span class="dropdown-text">Creating Better Visualisations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../RStudio/Geospatial_Analytics/Unveiling_spatio_temporal_mobility_patterns/Unveiling_spatio_temporal_mobility_patterns.html">
 <span class="dropdown-text">Unveiling spatial and spatio-temporal mobility patterns</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-tableau" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Tableau</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-tableau">    
        <li>
    <a class="dropdown-item" href="../Tableau/Quarterly_Private_Residential_Property_Watcher.html">
 <span class="dropdown-text">Quarterly Private Residential Property Watcher</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Tableau/Mapping_In_Tableau.html">
 <span class="dropdown-text">Mapping In Tableau</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../Tableau/Bullet_Graph_and_Sparkline.html">
 <span class="dropdown-text">Bullet Graph and Sparkline</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-python" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Python</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-python">    
        <li>
    <a class="dropdown-item" href="../Python/ImageLearningCifar10.html">
 <span class="dropdown-text">Image Learning on CIFAR-10</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/weipengten"> <i class="bi bi-linkedin" role="img" aria-label="Linkedin">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/weipengten"> <i class="bi bi-github" role="img" aria-label="Github">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="3">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#importing-libraries" id="toc-importing-libraries" class="nav-link" data-scroll-target="#importing-libraries">Importing Libraries</a></li>
  <li><a href="#exploring-the-dataset" id="toc-exploring-the-dataset" class="nav-link" data-scroll-target="#exploring-the-dataset">Exploring the dataset</a></li>
  <li><a href="#implementing-a-multi-layer-perceptron-for-cifar-10-classification" id="toc-implementing-a-multi-layer-perceptron-for-cifar-10-classification" class="nav-link" data-scroll-target="#implementing-a-multi-layer-perceptron-for-cifar-10-classification">1. Implementing a Multi-Layer Perceptron for CIFAR-10 Classification</a></li>
  <li><a href="#implementing-a-convolutional-neural-network-cnn-for-cifar-10-classification" id="toc-implementing-a-convolutional-neural-network-cnn-for-cifar-10-classification" class="nav-link" data-scroll-target="#implementing-a-convolutional-neural-network-cnn-for-cifar-10-classification">2. Implementing a Convolutional Neural Network (CNN) for CIFAR-10 Classification</a>
  <ul class="collapse">
  <li><a href="#building-a-convolutional-neural-network-for-cifar-10" id="toc-building-a-convolutional-neural-network-for-cifar-10" class="nav-link" data-scroll-target="#building-a-convolutional-neural-network-for-cifar-10">Building a Convolutional Neural Network for CIFAR-10!</a></li>
  </ul></li>
  <li><a href="#leveraging-a-pretrained-model-for-cifar-10" id="toc-leveraging-a-pretrained-model-for-cifar-10" class="nav-link" data-scroll-target="#leveraging-a-pretrained-model-for-cifar-10">3. Leveraging a Pretrained Model for CIFAR-10</a>
  <ul class="collapse">
  <li><a href="#to-be-continued.." id="toc-to-be-continued.." class="nav-link" data-scroll-target="#to-be-continued..">To be Continued…..</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Image Learning on CIFAR-10</h1>
</div>

<div>
  <div class="description">
    Deep Learning with CIFAR-10
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ten Wei Peng </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 20, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p><img src="images/clipboard-4123856362.png" class="img-fluid" width="475"></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Hello everyone, this post is intended to provide an in-depth comparison and discussion of various methods for image learning. I will add more detailed explanations as soon as I have the time.</p>
<p><code>Changelog:</code></p>
<p><code>\[1.0.0\] - 2024-07-20 - Initial deployment after consolidating course work and initial refinement.</code></p>
<p>This page demonstrates how to perform an image classification task using:</p>
<ul>
<li><p><strong>Multi-Layer Perceptron (MLP)</strong></p></li>
<li><p><strong>Convolutional Neural Network (CNN)</strong></p></li>
<li><p><strong>Transfer Learning using Resnet50</strong> <em>(in-progress)</em></p></li>
</ul>
<p>for the CIFAR-10 dataset as a demonstration</p>
</section>
<section id="importing-libraries" class="level2">
<h2 class="anchored" data-anchor-id="importing-libraries">Importing Libraries</h2>
<div id="c453cf85" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Importing necessary libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedKFold</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils.class_weight <span class="im">import</span> compute_class_weight</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">#Data preprocessing and modeling related functions</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.utils <span class="im">import</span> to_categorical</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder, OneHotEncoder</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.preprocessing.image <span class="im">import</span> ImageDataGenerator</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">#Cross-validation and evaluation related functions</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">#Datamodeling related functions</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential, Model</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.optimizers <span class="im">import</span> SGD</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> model_selection, preprocessing, metrics</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.applications <span class="im">import</span> VGG16, ResNet50, InceptionV3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="exploring-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="exploring-the-dataset">Exploring the dataset</h2>
<p>This Python code snippet uses TensorFlow’s Keras API to load the CIFAR-10 dataset and print the shapes of the training and test sets. The CIFAR-10 dataset is a popular dataset used for training machine learning and computer vision algorithms. It consists of 60,000 32x32 color images in 10 different classes, with 6,000 images per class.</p>
<div id="36afae91" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the CIFAR-10 dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>cifar10 <span class="op">=</span> tf.keras.datasets.cifar10</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> cifar10.load_data()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training set shape:"</span>, x_train.shape)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test set shape:"</span>, x_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-929340846.png" class="img-fluid"></p>
<div class="notebox lightbulb">
<ul>
<li><p>The x_train.shape returns <strong>(50000, 32, 32, 3)</strong>, indicating that there are 50,000 training images, each of size 32x32 pixels with 3 color channels (RGB).</p></li>
<li><p>The x_test.shape returns <strong>(10000, 32, 32, 3)</strong>, indicating that there are 10,000 test images, each of size 32x32 pixels with 3 color channels (RGB).</p></li>
</ul>
</div>
<p><strong>This code will display the first 10 images from the CIFAR-10 training set with their respective classes.</strong></p>
<div id="f53d73c8" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="dv">10</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> <span class="bu">list</span>(np.unique(y_train))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">10</span>))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> images:</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">1</span> <span class="op">+</span> i).set_title(classes[y_train[i][<span class="dv">0</span>]])</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        plt.imshow(x_train[i])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-1174994514.png" class="img-fluid"></p>
<p><strong>Next, let’s reshape the arrays to have only 2 dimensions</strong></p>
<div id="a3719b72" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> x_train.reshape(<span class="dv">50000</span>, <span class="dv">32</span> <span class="op">*</span> <span class="dv">32</span> <span class="op">*</span> <span class="dv">3</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>x_test  <span class="op">=</span> x_test.reshape (<span class="dv">10000</span>, <span class="dv">32</span> <span class="op">*</span> <span class="dv">32</span> <span class="op">*</span> <span class="dv">3</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training set shape:"</span>, x_train.shape)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test set shape:"</span>, x_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-149929291.png" class="img-fluid"></p>
<div class="notebox lightbulb">
<p>By reshaping the images into <strong>(50000, 3072)</strong> and <strong>(10000, 3072)</strong>, each image is now represented as a 1-dimensional array (vector) of length 3072. This reshaping is commonly done to prepare the data for certain machine learning algorithms that expect input as 1-dimensional arrays rather than 3-dimensional images.</p>
</div>
<p><strong>Next we perform the necessary pre-processing steps:</strong></p>
<p><strong>Splitting the Training Dataset:</strong> The training dataset is split into a new training set and a validation set using an 80/20 split to evaluate the model during training. The train_test_split function is used with test_size=0.2 and random_state=42 for reproducibility.</p>
<p><strong>Data Type Conversion:</strong> The feature arrays are converted to float32 data type to ensure compatibility with TensorFlow</p>
<div id="b4d52ebf" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Splitting "training" dataset further into train,validation datasets</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>x_train, x_valid, y_train, y_valid <span class="op">=</span> train_test_split(x_train, y_train, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> x_train.astype(<span class="st">'float32'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>x_valid <span class="op">=</span> x_valid.astype(<span class="st">'float32'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> x_test.astype(<span class="st">'float32'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Min-Max Scaling:</strong> . A Min-Max scaling function normalizes the pixel values of the images to the range [0, 1], which helps in faster and more stable training of the model.</p>
<div id="d914bb73" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Transform method: MinMax - is preferred when working with TensorFlow</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> min_max_scaler(x_train, x_valid, x_test):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  x_train_ms<span class="op">=</span> x_train<span class="op">/</span><span class="dv">255</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  x_valid_ms<span class="op">=</span> x_valid<span class="op">/</span><span class="dv">255</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  x_test_ms <span class="op">=</span> x_test<span class="op">/</span><span class="dv">255</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> x_train_ms,x_valid_ms,x_test_ms</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>x_train_ms, x_valid_ms, x_test_ms <span class="op">=</span> min_max_scaler(x_train, x_valid, x_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>One-Hot Encoding the Labels:</strong> The class labels are converted to one-hot encoded vectors using to_categorical, which transforms the integer labels into binary vectors. This format is required for categorical classification tasks where the neural network’s output layer expects binary vectors.</p>
<div id="e89b4e33" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># By converting the target variables to one-hot format, we can ensure that they are compatible with the output layer of the MLP model, which expects the target variables to be represented as a vector of binary values.</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>y_train_1hot <span class="op">=</span> to_categorical(y_train, <span class="dv">10</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>y_valid_1hot <span class="op">=</span> to_categorical(y_valid, <span class="dv">10</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>y_test_1hot  <span class="op">=</span> to_categorical(y_test , <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="implementing-a-multi-layer-perceptron-for-cifar-10-classification" class="level2">
<h2 class="anchored" data-anchor-id="implementing-a-multi-layer-perceptron-for-cifar-10-classification">1. Implementing a Multi-Layer Perceptron for CIFAR-10 Classification</h2>
<p><strong>MLP with one hidden layer consisting of 256 neurons,sgd</strong></p>
<ul>
<li><p><strong>Optimizer</strong>: SGD</p></li>
<li><p><strong>Loss</strong>: Cross Entropy</p></li>
<li><p><strong>Hidden Layers</strong>: 1 with 256 neurons</p></li>
<li><p><strong>Activation Layer</strong>: (ReLU, softmax)</p></li>
</ul>
<div id="270831b9" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the model architecture</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> keras.Sequential([</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Input Layer</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    keras.layers.Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>(<span class="dv">32</span><span class="op">*</span><span class="dv">32</span><span class="op">*</span><span class="dv">3</span>,)),</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hidden Layers</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    keras.layers.Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    keras.layers.Dropout(<span class="fl">0.2</span>),</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Output Layer</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile the model</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'SGD'</span>,</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>              loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>,</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model using mini-batch learning</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">40</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>patience <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>best_acc <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(x_train_ms), batch_size):</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        batch_x, batch_y <span class="op">=</span> x_train_ms[i:i<span class="op">+</span>batch_size], y_train_1hot[i:i<span class="op">+</span>batch_size]</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        model.train_on_batch(batch_x, batch_y)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluate the model on the validation set after each epoch</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    val_loss, val_acc <span class="op">=</span> model.evaluate(x_valid_ms, y_valid_1hot)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Epoch </span><span class="sc">%d</span><span class="st">: validation accuracy=</span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> (epoch<span class="op">+</span><span class="dv">1</span>, val_acc))</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if the validation accuracy has improved</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val_acc <span class="op">&gt;</span> best_acc:</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>        best_acc <span class="op">=</span> val_acc</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>        patience <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>        patience <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"patience ="</span>,patience)</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stop training if the validation accuracy does not improve after a certain number of epochs</span></span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> patience <span class="op">==</span> <span class="dv">5</span>:</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate final model on test set</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>test_pred <span class="op">=</span> model.predict(x_test_ms)</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="op">=</span> accuracy_score(np.argmax(y_test_1hot, axis<span class="op">=</span><span class="dv">1</span>), np.argmax(test_pred, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test Accuracy of MLP, 1 Hidden Layer with 256 neurons, SGD, ReLu = "</span>,<span class="bu">round</span>(test_accuracy,<span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-3703383034.png" class="img-fluid"></p>
<p><img src="images/clipboard-2107656334.png" class="img-fluid"></p>
</section>
<section id="implementing-a-convolutional-neural-network-cnn-for-cifar-10-classification" class="level2">
<h2 class="anchored" data-anchor-id="implementing-a-convolutional-neural-network-cnn-for-cifar-10-classification">2. Implementing a Convolutional Neural Network (CNN) for CIFAR-10 Classification</h2>
<p><strong>Preprocessing</strong></p>
<p>First off, let’s reproduce some of the preprocessing steps we did earlier:</p>
<div id="bb1c6f7c" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Data and Split into Train, Test dataset</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> cifar10.load_data()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Onehot Encoding</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> to_categorical(y_train, <span class="dv">10</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>y_test  <span class="op">=</span> to_categorical(y_test , <span class="dv">10</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to float datatype</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> x_train.astype(<span class="st">'float32'</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>x_test  <span class="op">=</span> x_test.astype(<span class="st">'float32'</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Minmax Scaling</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>x_train  <span class="op">/=</span> <span class="dv">255</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>x_test   <span class="op">/=</span> <span class="dv">255</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Data Augmentation, Manual Splitting and Batch Processing</strong></p>
<p>Next, this set of additional steps are required for preprocessing for CNN</p>
<div id="eeaf4f9f" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data Augmentation</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>transform_train <span class="op">=</span> ImageDataGenerator(</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        width_shift_range<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># randomly shift images horizontally (fraction of total width)</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        height_shift_range<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># randomly shift images vertically (fraction of total height)</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        rotation_range <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        horizontal_flip<span class="op">=</span><span class="va">True</span>)   <span class="co"># flip images horizontally</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>validation_train <span class="op">=</span> ImageDataGenerator()</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Split Train dataset to get Validation dataset</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>validation_train <span class="op">=</span> ImageDataGenerator()</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>train_set <span class="op">=</span> transform_train.flow(x_train[:<span class="dv">40000</span>], y_train[:<span class="dv">40000</span>], batch_size<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>validation_set <span class="op">=</span> validation_train.flow(x_train[<span class="dv">40000</span>:], y_train[<span class="dv">40000</span>:], batch_size<span class="op">=</span><span class="dv">32</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="notebox lightbulb">
<p><strong>Why do we need additional preprocessing steps for CNN?</strong></p>
<p>Convolutional Neural Networks (CNNs) are specifically designed to work with image data. To enhance their performance, particularly when working with relatively small datasets like CIFAR-10, additional preprocessing steps are often employed. These steps help improve the model’s ability to generalize to unseen data and mitigate overfitting.</p>
<ul>
<li><p><strong>Data Augmentation:</strong> Increases the diversity of the training dataset by applying random transformations such as shifts, rotations, and flips. This helps the CNN model generalize better by training on a wider variety of image presentations. This is different from MLP earlier as MLPs typically work with flattened input data and do not benefit as much from spatial data augmentation</p></li>
<li><p><strong>Manual Splitting and Batch Processing:</strong> The <code>ImageDataGenerator</code> in TensorFlow/Keras handles data augmentation and requires the data to be in a specific format (i.e., batches). Hence, the split is done manually to apply augmentation on the training set while keeping the validation set unchanged. CNNs typically require batch processing for efficient training. The flow method from <code>ImageDataGenerator</code>creates an iterator that generates batches of augmented data on-the-fly. This is especially useful when working with large datasets or when applying data augmentation. Manual splitting allows for better control over how data is augmented and fed into the model. By explicitly defining the training and validation datasets, we ensure that augmentation is applied only to the training data, not the validation data.</p></li>
</ul>
</div>
<section id="building-a-convolutional-neural-network-for-cifar-10" class="level3">
<h3 class="anchored" data-anchor-id="building-a-convolutional-neural-network-for-cifar-10">Building a Convolutional Neural Network for CIFAR-10!</h3>
<ul>
<li><p>Batch Size: 64</p></li>
<li><p>Epochs: 50</p></li>
<li><p>Padding: Same</p></li>
<li><p>Kernel: 3*3</p></li>
<li><p>(Convolution-BatchNormalisation-Relu-MaxPooling) x 2</p></li>
<li><p>Loss Function: Categorical Crossentropy</p></li>
<li><p>Dropout: 0.25,0.25,0.5</p></li>
</ul>
<section id="padding-same-this-means-that-the-output-spatial-dimensions-will-be-the-same-as-the-input-spatial-dimensions-after-applying-the-convolution-operation.-this-is-achieved-by-adding-zeros-around-the-borders-of-the-input-tensor-so-that-the-output-spatial-dimensions-match-the-input-spatial-dimensions." class="level5">
<h5 class="anchored" data-anchor-id="padding-same-this-means-that-the-output-spatial-dimensions-will-be-the-same-as-the-input-spatial-dimensions-after-applying-the-convolution-operation.-this-is-achieved-by-adding-zeros-around-the-borders-of-the-input-tensor-so-that-the-output-spatial-dimensions-match-the-input-spatial-dimensions."><code>Padding: Same:</code> This means that the output spatial dimensions will be the same as the input spatial dimensions after applying the convolution operation. This is achieved by adding zeros around the borders of the input tensor so that the output spatial dimensions match the input spatial dimensions.</h5>
</section>
<section id="kernel-3x3-a-kernel-size-of-3x3-is-a-standard-choice-for-convolutional-neural-networks-because-it-provides-a-good-balance-between-capturing-local-patterns-and-not-overfitting-to-the-training-data.-larger-kernel-sizes-can-capture-more-complex-patterns-but-may-lead-to-overfitting-while-smaller-kernel-sizes-may-not-capture-enough-information." class="level5">
<h5 class="anchored" data-anchor-id="kernel-3x3-a-kernel-size-of-3x3-is-a-standard-choice-for-convolutional-neural-networks-because-it-provides-a-good-balance-between-capturing-local-patterns-and-not-overfitting-to-the-training-data.-larger-kernel-sizes-can-capture-more-complex-patterns-but-may-lead-to-overfitting-while-smaller-kernel-sizes-may-not-capture-enough-information."><code>Kernel: 3x3:</code> A kernel size of 3x3 is a standard choice for convolutional neural networks because it provides a good balance between capturing local patterns and not overfitting to the training data. Larger kernel sizes can capture more complex patterns but may lead to overfitting, while smaller kernel sizes may not capture enough information.</h5>
</section>
<section id="convolution-batchnormalisation-relu-maxpooling-x-2-this-sequence-of-layers-is-commonly-used-in-convolutional-neural-networks-because-it-allows-the-model-to-learn-increasingly-complex-features-while-reducing-overfitting." class="level5">
<h5 class="anchored" data-anchor-id="convolution-batchnormalisation-relu-maxpooling-x-2-this-sequence-of-layers-is-commonly-used-in-convolutional-neural-networks-because-it-allows-the-model-to-learn-increasingly-complex-features-while-reducing-overfitting."><code>(Convolution-BatchNormalisation-Relu-MaxPooling) x 2</code>: This sequence of layers is commonly used in convolutional neural networks because it allows the model to learn increasingly complex features while reducing overfitting.</h5>
</section>
<section id="batch-normalization-normalize-the-activations-to-improve-generalization" class="level5">
<h5 class="anchored" data-anchor-id="batch-normalization-normalize-the-activations-to-improve-generalization"><code>Batch normalization</code> normalize the activations to improve generalization</h5>
</section>
<section id="relu-activation-functions-introduce-non-linearity-to-the-model" class="level5">
<h5 class="anchored" data-anchor-id="relu-activation-functions-introduce-non-linearity-to-the-model"><code>ReLU activation functions</code> introduce non-linearity to the model</h5>
</section>
<section id="max-pooling-layers-downsample-the-spatial-dimensions-to-reduce-computational-complexity-and-help-the-model-learn-spatial-hierarchies." class="level5">
<h5 class="anchored" data-anchor-id="max-pooling-layers-downsample-the-spatial-dimensions-to-reduce-computational-complexity-and-help-the-model-learn-spatial-hierarchies."><code>Max pooling</code> layers downsample the spatial dimensions to reduce computational complexity and help the model learn spatial hierarchies.</h5>
</section>
<section id="loss-function-categorical-crossentropy-this-loss-function-is-commonly-used-for-multi-class-classification-problems-like-image-classification.-it-measures-the-difference-between-the-predicted-probabilities-and-the-true-labels-by-calculating-the-negative-log-likelihood-of-the-true-class.-this-encourages-the-model-to-output-high-probabilities-for-the-correct-classes-and-low-probabilities-for-the-incorrect-classe" class="level5">
<h5 class="anchored" data-anchor-id="loss-function-categorical-crossentropy-this-loss-function-is-commonly-used-for-multi-class-classification-problems-like-image-classification.-it-measures-the-difference-between-the-predicted-probabilities-and-the-true-labels-by-calculating-the-negative-log-likelihood-of-the-true-class.-this-encourages-the-model-to-output-high-probabilities-for-the-correct-classes-and-low-probabilities-for-the-incorrect-classe"><code>Loss Function: Categorical Crossentropy:</code> This loss function is commonly used for multi-class classification problems like image classification. It measures the difference between the predicted probabilities and the true labels by calculating the negative log likelihood of the true class. This encourages the model to output high probabilities for the correct classes and low probabilities for the incorrect classe</h5>
</section>
<section id="dropout-is-a-regularization-technique-that-helps-prevent-overfitting-by-randomly-setting-some-of-the-neurons-to-zero-during-training.-by-using-a-high-dropout-rate-0.25-and-0.5-it-is-likely-to-reduce-overfitting-and-contribute-to-better-performance." class="level5">
<h5 class="anchored" data-anchor-id="dropout-is-a-regularization-technique-that-helps-prevent-overfitting-by-randomly-setting-some-of-the-neurons-to-zero-during-training.-by-using-a-high-dropout-rate-0.25-and-0.5-it-is-likely-to-reduce-overfitting-and-contribute-to-better-performance."><code>Dropout</code> is a regularization technique that helps prevent overfitting by randomly setting some of the neurons to zero during training. By using a high dropout rate (0.25) and (0.5), it is likely to reduce overfitting and contribute to better performance.</h5>
<div id="b3a99509" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">## CNN Archeticure</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> CNN():</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential()</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), padding<span class="op">=</span><span class="st">'same'</span>, input_shape<span class="op">=</span>x_train.shape[<span class="dv">1</span>:]) )</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    model.add(Activation(<span class="st">'relu'</span>))</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    model.add(Conv2D(<span class="dv">32</span>,(<span class="dv">3</span>, <span class="dv">3</span>)))</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    model.add(BatchNormalization())</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    model.add(Activation(<span class="st">'relu'</span>))</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    model.add(MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    model.add(Dropout(<span class="fl">0.25</span>))</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    model.add(Conv2D(<span class="dv">32</span>,(<span class="dv">3</span>, <span class="dv">3</span>)))</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    model.add(BatchNormalization())</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    model.add(Activation(<span class="st">'relu'</span>))</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    model.add(MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    model.add(Dropout(<span class="fl">0.25</span>))</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    model.add(Flatten())</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">512</span>))</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    model.add(BatchNormalization())</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    model.add(Activation(<span class="st">'relu'</span>))</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    model.add(Dropout(<span class="fl">0.5</span>))</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    model.add(Dense(<span class="dv">10</span>))</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    model.add(Activation(<span class="st">'softmax'</span>))</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Train model</span></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>cnn <span class="op">=</span> CNN()</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>cnn.fit(train_set,</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>        epochs<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>        validation_data<span class="op">=</span>validation_set, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>loss, acc <span class="op">=</span> cnn.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Test loss:'</span>, loss)</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Test acc:'</span>, acc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-3449070481.png" class="img-fluid"></p>
</section>
</section>
</section>
<section id="leveraging-a-pretrained-model-for-cifar-10" class="level2">
<h2 class="anchored" data-anchor-id="leveraging-a-pretrained-model-for-cifar-10">3. Leveraging a Pretrained Model for CIFAR-10</h2>
<p><strong>ResNet50</strong> is known for its high accuracy and relatively efficient parameter count among pretrained models. We should adjust its input dimensions to fit the CIFAR-10 dataset rather than using its default settings. See <a href="https://paperswithcode.com/sota/image-classification-on-imagenet" class="uri">https://paperswithcode.com/sota/image-classification-on-imagenet</a> to see list of pretrained models and their performance, using ImageNet dataset as benchmark.</p>
<p>First, let’s illustrate a method that is <strong>conceptually sound but inefficient</strong> for using pretrained models.</p>
<ul>
<li><p><strong>Resizing layer</strong> is added to adjust the image dimensions from the original 32x32 pixels to 224x224 pixels. This step is crucial because ResNet50 was originally trained on the ImageNet dataset, where images have a resolution of <em>224x224</em> pixels. By resizing our images to match this resolution, we align them with the input format the model was designed for, ensuring that the features learned from ImageNet are effectively utilized. This alignment helps maintain the integrity of the pretrained model’s architecture and improves its performance on our specific dataset.</p></li>
<li><p><strong>Early Stopping</strong> is employed to enhance training efficiency by halting the training process when the model’s performance ceases to improve on the validation dataset. This prevents unnecessary computations and helps avoid overfitting.</p></li>
<li><p><strong>ModelCheckpoint callback</strong> is used to save the model’s weights at specific points during training, ensuring that the best-performing model (according to validation metrics) is preserved. This way, if the training process is interrupted or if we need to revert to a previous state, we can load the saved weights and continue from the best checkpoint. Together, these techniques help optimize both the training time and the final performance of the model.</p></li>
</ul>
<div id="3bb43d14" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>pretrained_model <span class="op">=</span> ResNet50(input_shape<span class="op">=</span>(<span class="dv">224</span>, <span class="dv">224</span>, <span class="dv">3</span>),</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>                    include_top<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>pretrained_model.trainable <span class="op">=</span> <span class="va">True</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>          Resizing(<span class="dv">224</span>, <span class="dv">224</span>),  <span class="co"># Resize images to 224x224</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>            pretrained_model,</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>            BatchNormalization(),</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>            GlobalAveragePooling2D(),</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>            Dense(<span class="dv">1024</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>            Dropout(<span class="fl">0.4</span>),</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>            Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>, dtype<span class="op">=</span><span class="st">'float32'</span>),</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile the model with the same optimizer and loss function</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>,loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>,metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Define early stopping parameters</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>early_stopping_patience <span class="op">=</span> <span class="dv">5</span> <span class="co"># Stop training if no improvement after 5 epochs</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>early_stopping_min_delta <span class="op">=</span> <span class="fl">0.01</span> <span class="co"># Stop training if improvement is less than 0.01%</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Create EarlyStopping callback object</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>early_stopping <span class="op">=</span> EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span>early_stopping_patience, min_delta<span class="op">=</span>early_stopping_min_delta)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Define where to save the best model based on validation accuracy</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>best_model_path <span class="op">=</span> <span class="st">'best_model.h5'</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Create ModelCheckpoint callback object</span></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>model_checkpoint <span class="op">=</span> ModelCheckpoint(best_model_path <span class="op">+</span> <span class="st">'.keras'</span>, monitor<span class="op">=</span><span class="st">'val_accuracy'</span>, mode<span class="op">=</span><span class="st">'max'</span>, verbose<span class="op">=</span><span class="dv">1</span>, save_best_only<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Continue training from the last saved model</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>model.fit(train_set,</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>        epochs<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>        validation_data<span class="op">=</span>validation_set, shuffle<span class="op">=</span><span class="va">True</span>,callbacks<span class="op">=</span>[early_stopping, model_checkpoint])</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate final model on test set</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>loss, acc <span class="op">=</span> best_model.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Test loss:'</span>, loss)</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Test acc:'</span>, acc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="images/clipboard-3999430006.png" class="img-fluid"></p>
<p><img src="images/clipboard-239623973.png" class="img-fluid"></p>
<div class="notebox lightbulb">
<p><strong>We achieved a high test score of 0.898, but the question remains: is this the best way to use transfer learning?</strong></p>
<p>To determine if our approach to transfer learning is correct, we first need to understand the principles behind it. Transfer learning is designed to enhance efficiency and reduce computational costs by leveraging pretrained models. Instead of retraining a model from scratch, we use an existing model that has already been trained on a large dataset. This typically involves “freezing” the earlier layers of the model, which means keeping their weights unchanged, and only training the final layers on our specific dataset. This strategy allows us to build on the learned features of the pretrained model, thus saving time and computational resources while potentially achieving better performance with less data.</p>
<p>In the case above, we had set <code>pretrained_model.trainable = True</code> which we should have set to <code>False</code> to fully leverage the full benefits of a pretrained model.</p>
</div>
<p><strong>A Better way to utilise a pretrained model:</strong> Firstly, instead of incorporating a resizing layer within the model, we should resize our images to 224x224 pixels during the preprocessing step.</p>
<div class="notebox lightbulb">
<p><strong>Can you think of the rationale for this?</strong></p>
</div>
<section id="to-be-continued.." class="level3">
<h3 class="anchored" data-anchor-id="to-be-continued..">To be Continued…..</h3>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://quarto.org/">
<p>Published with Quarto |</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://www.netlify.com/">
<p>Hosted by Netlify</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>