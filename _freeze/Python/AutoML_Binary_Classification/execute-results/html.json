{
  "hash": "099db40ad5c40f58e3de066e42969320",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"AutoML for Binary Classification\"\nauthor: \"Ten Wei Peng\"\ndescription: \"Automated Machine Learning (In-Progress)\"\nexecute: \n  eval: false\n  echo: true\n  warning: false\n  freeze: true\ndate: \"2024-08-02\"\nformat: html\n---\n\n![](images/clipboard-2913337989.png)\n\n## Introduction\n\nHello everyone, this post is intended to demonstrate how it is possible to automate some of the evaluation process in deciding which machine learning models to utilise to achieve the best desired results, which is commonly know as **AutoML.**\n\nI was intrigued that such a thing was possible and couldn't wait to try it, here's an attempt on my version of AutoML for a Binary Classification Model. Going forward, i would like to automate more of the common decision-making processes like pre-processing that is in tune with domain knowledge.\n\n`Changelog:`\n\n`\\[1.0.0\\] - 2024-08-02 - Initial deployment after consolidating course work and initial refinement. Looking to tune model to avoid false negatives, for the case of cancer diagnostics.`In the context of cancer diagnostics, **false negatives are generally more critical to avoid** because the consequences of missing a cancer diagnosis (delayed treatment, progression of the disease, reduced survival rates) are often more severe than the consequences of false positives (psychological impact, additional testing, unnecessary treatment). Therefore, cancer screening programs typically prioritize sensitivity to ensure that as few cases as possible are missed, even at the expense of higher false positive rates.\n\n## Importing Libraries\n\n::: {#eba3bcf6 .cell execution_count=1}\n``` {.python .cell-code}\n#Importing necessary libraries\nimport time\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom pandas.api.types import CategoricalDtype\n\nfrom sklearn.impute import SimpleImputerfrom scipy.stats import skew\nfrom sklearn.preprocessing import PowerTransformer, QuantileTransformer,StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split,RepeatedStratifiedKFold\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import label_binarize,LabelEncoder\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix, roc_curve, auc\n\n\nfrom imblearn.combine import SMOTEENN\nfrom skopt import BayesSearchCV\nfrom skopt.space import Real, Categorical, Integer\nimport xgboost as xgb\nfrom lightgbm import LGBMClassifier\n \n \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools.tools import add_constant\n\nwarnings.filterwarnings('ignore')\n```\n:::\n\n\n## Load the Dataset\n\nThis Python code snippet uses TensorFlow's Keras API to load the CIFAR-10 dataset and print the shapes of the training and test sets. The CIFAR-10 dataset is a popular dataset used for training machine learning and computer vision algorithms. It consists of 60,000 32x32 color images in 10 different classes, with 6,000 images per class.\n\n::: {#d0b02333 .cell execution_count=2}\n``` {.python .cell-code}\nurl = 'https://raw.githubusercontent.com/weipengten/ISSS623GroupProject--Applied-Healthcare-/main/CARES_data.xlsx'\ndf = pd.read_excel(url, index_col='Indexno')\n\nprint(df.shape)\ndf.head()\n```\n:::\n\n\n![](images/clipboard-2209450693.png)\n\n## Data Cleaning\n\n-   Replace missing values with nan\n\n-   String formatting\n\n-   Create bins for age as age_bins\n\n-   Create bins for rcri_score as rcri_bin\n\n-   Drop rows with at least 10 missing values in columns, 93.73% remaining\n\n-   NUMERICAL columns (remaining columns except for DaysbetweenDeathandoperation): impute missing values with median\n\n-   CATEGORICAL columns (remaining columns except for \\['mortality', 'daysbetweendeathandoperation', '\\@30daymortality', 'thirtydaymortality'\\]): impute missing values with 'None'\n\n### Replace missing values with nan\n\n::: {#70f3e6ef .cell execution_count=3}\n``` {.python .cell-code}\n# replace missing values with pd.NA\nnull_values = ['#NULL!', 'BLANK', 'none', 'NA', '<NA>', 'None']\ndf.replace(null_values, np.nan, inplace=True)\n\n# check data types and missing values\ndf.info()\n```\n:::\n\n\n![](images/clipboard-4006132243.png)\n\n::: {#412bdc59 .cell execution_count=4}\n``` {.python .cell-code}\n# statistical summary\ndf.describe()\n```\n:::\n\n\n![](images/clipboard-62069690.png)\n\n### String formatting\n\n::: {#34e40dec .cell execution_count=5}\n``` {.python .cell-code}\n# replace all column names with lowercase and replace spaces with underscores\ndf.columns = df.columns.str.lower().str.replace(' ', '_')\n\n# replace all string values in the DataFrame with lowercase\ndf = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n```\n:::\n\n\n### Replace missing values with nan\n\n::: {#9cbb72d2 .cell execution_count=6}\n``` {.python .cell-code}\n# replace missing values with pd.NA\nnull_values = ['#NULL!', 'BLANK', 'none', 'NA', '<NA>', 'None']\ndf.replace(null_values, np.nan, inplace=True)\n\n# check data types and missing values\ndf.info()\n```\n:::\n\n\n![](images/clipboard-263768488.png)\n\n#### Check potential duplicates\n\n::: {#8a4e54a6 .cell execution_count=7}\n``` {.python .cell-code}\n# check potential duplicates\ndf.duplicated().sum()\n\n# We will not drop duplicates in this dataste as\n# they represent multiple legitimate entries representing different patients\n```\n:::\n\n\n![](images/clipboard-1862191658.png)\n\n#### Find all unique values for categorical features\n\n::: {#422dcff5 .cell execution_count=8}\n``` {.python .cell-code}\n# find all unique values for categorical features\nfor column in df.select_dtypes(include=['object']).columns:\n    print(f'{column}: {df[column].unique()}')\n```\n:::\n\n\n![](images/clipboard-3989827221.png)\n\n### Create bins for age as age_bins\n\n::: {#c1f2f4c2 .cell execution_count=9}\n``` {.python .cell-code}\n# bin the age column\nage_bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110]\nage_labels = ['0-10', '11-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100', '101-110']\ndf['age_binned'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, right=False)\n\n# summarize frequency counts\nage_binned_counts = df['age_binned'].value_counts().sort_index()\nprint(age_binned_counts, '\\n')\nplt.figure(figsize=(6, 4))\nsns.barplot(x=age_binned_counts.index, y=age_binned_counts.values, palette=\"viridis\")\nplt.xlabel('Age Bins')\nplt.ylabel('Frequency')\nplt.title('Frequency of Age Bins')\nplt.xticks(rotation=45)\nplt.show()\n\ndf['age_binned'] = df['age_binned'].astype('object')\n```\n:::\n\n\n![](images/clipboard-3669474606.png)\n\n### Create bins for rcri_score as rcri_bin\n\n::: {#7912f5ab .cell execution_count=10}\n``` {.python .cell-code}\n# Function to bin 'RCRI score' into distinct ordinal categories\ndef smart_binning(df, column_name, bin_column_name):\n    # Create a copy of the DataFrame to avoid modifying the original\n    _df = df.copy()\n\n    # Create a mapping for the bins, including a label for NaN values\n    bin_labels = {1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6'}\n    _df[bin_column_name] = _df[column_name].map(bin_labels)\n\n    # Handle NaN values by assigning them to a specific category\n    _df[bin_column_name] = _df[bin_column_name].fillna('No_RCRI')\n\n    # Define the categorical type with ordered categories, including 'No_RCRI'\n    cat_type = CategoricalDtype(categories=['1', '2', '3', '4', '5', '6', 'No_RCRI'], ordered=True)\n\n    # Convert the new bin column to categorical type\n    _df[bin_column_name] = _df[bin_column_name].astype(cat_type)\n\n    return _df\n\n# Apply the smart binning function\ndf = smart_binning(df, 'rcri_score', 'rcri_bin')\n\n# Check if the rcri_bin column is ordinal\nif isinstance(df['rcri_bin'].dtype, CategoricalDtype) and df['rcri_bin'].dtype.ordered:\n    print(\"rcri_bin is ordinal.\")\nelse:\n    print(\"rcri_bin is not ordinal.\")\nprint('\\n')\n\n# Print the categories and their order\nprint(\"Categories and order:\", df['rcri_bin'].dtype.categories)\nprint('\\n')\n\n# Print the distribution of data in 'rcri_bin'\nprint(f\"The distribution of data in 'rcri_bin' is as follows:\\n{df['rcri_bin'].value_counts()}\")\nprint('\\n')\n\n\ndf['rcri_bin'] = df['rcri_bin'].astype('object')\n```\n:::\n\n\n![](images/clipboard-393517675.png)\n\n#### Visualize correlation for numerical column\n\n::: {#bffc78f4 .cell execution_count=11}\n``` {.python .cell-code}\ncorrelation_matrix = df.select_dtypes(include=['number']).corr()\nfontsize=8\nplt.figure(figsize=(6,6))\nsns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', vmin=-1, vmax=1, cbar=True, annot_kws={'size': 8})\nplt.title('Correlation Matrix for Numerical Columns', fontsize=10)\nplt.xticks(fontsize=fontsize)\nplt.yticks(fontsize=fontsize)\nplt.show()\n```\n:::\n\n\n![](images/clipboard-2942571460.png)\n\n### Drop rows with at least 10 missing values in columns, 93.73% remaining\n\n::: {#626a945c .cell execution_count=12}\n``` {.python .cell-code}\n# define the threshold for missing values\nthreshold = 10\nmissing_counts = df.isna().sum(axis=1)\n\n# Calculate the percentage of rows to keep\npercentage_remaining = round((df[missing_counts < threshold].shape[0] / df.shape[0]) * 100, 2)\nprint(f\"Percentage of rows with fewer than {threshold} missing values: {percentage_remaining}%\")\n\n# Drop rows with at least the specified number of missing values\ndf = df[missing_counts < threshold]\ndf.head()\n```\n:::\n\n\n![](images/clipboard-2865351042.png)\n\n#### Data Validation\n\n::: {#80c56509 .cell execution_count=13}\n``` {.python .cell-code}\n# Check the condition\ncondition_check = df[df['thirtydaymortality'] == True]['mortality'] == True\n\n# Verify if all values meet the condition\nif condition_check.all():\n    print('----------------------------------------')\n    print(\"All instances where 'thirtydaymortality' is True, 'mortality' is also True.\")\n    print(\"Data validation step 1, there's no logical errors found for mortality and thirtydaymortality\")\n    print('----------------------------------------')\nelse:\n    print(\"There are instances where 'thirtydaymortality' is True but 'mortality' is not True.\")\n    # Data validation:\n\nif 'mortality' in df.columns and 'daysbetweendeathandoperation' in df.columns:\n    # Check the conditions\n    condition_1 = df.loc[df['mortality'] == True, 'daysbetweendeathandoperation'].notnull().all()\n    condition_2 = df.loc[df['mortality'] == False, 'daysbetweendeathandoperation'].isnull().all()\n\n    # Print the results\n    print('----------------------------------------')\n    print(\"Condition 1 met:\", condition_1)\n    print(\"Condition 2 met:\", condition_2)\n    print(\"Data validation step 2, there's no logical errors found for mortality and daysbetweendeathandoperation\")\n    print('----------------------------------------')\nelse:\n    print(\"The DataFrame does not contain the required columns.\")\n```\n:::\n\n\n![](images/clipboard-2261022608.png)\n\n#### Outlier detection for numerical features\n\n::: {#9fb7fff5 .cell execution_count=14}\n``` {.python .cell-code}\nnumerical_columns = df.select_dtypes(include=['number']).columns\nprint(\"Numerical columns:\", numerical_columns)\n\nplt.figure(figsize=(16, 10))\nfor i, column in enumerate(numerical_columns, 1):\n    plt.subplot(2, 4, i)\n    sns.boxplot(y=df[column])\n    plt.title(column)\n\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n[ ](images/clipboard-884694652.png)\n\n### NUMERICAL columns (remaining columns except for DaysbetweenDeathandoperation): impute missing values with median)\n\n::: {#5205b4c6 .cell execution_count=15}\n``` {.python .cell-code}\n# Initialize SimpleImputer to fill missing values with the median\nimp = SimpleImputer(missing_values=np.nan, strategy='median')\n\n# List all numeric columns in the DataFrame\nnumeric_columns = df.select_dtypes(include=['number']).columns\nprint(\"Numeric columns:\", list(numeric_columns))  # we have also checked that all the numerical columns are correct, no binary variables are mistakenly treated as numeric variables.\n\n# Define specific numeric columns for imputation\nnumeric_cols = [col for col in numeric_columns if col != 'daysbetweendeathandoperation']\nprint(\"Numeric columns:\", list(numeric_cols))\n\n# Fit the imputer on the specified numeric columns\nimp.fit(df[numeric_cols])\n\n# Transform the specified numeric columns by imputing missing values with the median\ndf[numeric_cols] = imp.transform(df[numeric_cols])\n\n# Ensure the columns are of float32 type\ndf[numeric_cols] = df[numeric_cols].astype(np.float32)\n\n# Print the DataFrame with imputed data to verify the changes\nprint(\"DataFrame with imputed numeric columns:\")\nprint(df[numeric_cols])\n```\n:::\n\n\n![](images/clipboard-3764274460.png)\n\n### CATEGORICAL columns (remaining columns except for ['mortality', 'daysbetweendeathandoperation', ' @30daymortality', 'thirtydaymortality']): impute missing values with 'None'\n\n::: {#184c98e0 .cell execution_count=16}\n``` {.python .cell-code}\n# Initialize SimpleImputer for categorical columns to fill missing values with 'None'\ncat_imp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='None')\n\n# List all categorical columns in the DataFrame\ncategorical_columns  = df.select_dtypes(include=['object']).columns\nprint(\"Categorical columns:\", list(categorical_columns))\n\n# Columns to exclude\nexclude_columns = ['mortality', 'daysbetweendeathandoperation', '@30daymortality', 'thirtydaymortality']\n\n# Filter out the excluded columns from the list of categorical columns\ncategorical_columns = [col for col in categorical_columns if col not in exclude_columns]\n\n# Fit the imputer on the categorical columns\ncat_imp.fit(df[categorical_columns])\n\n# Transform the categorical columns by imputing missing values with 'None'\ndf[categorical_columns] = cat_imp.transform(df[categorical_columns])\n\n# find all unique values for categorical features\nfor column in df.select_dtypes(include=['object']).columns:\n    print(f'{column}: {df[column].unique()}')\n\n```\n:::\n\n\n[ ](images/clipboard-692645940.png)Outcome 1: Mortality within 30 days (thirtydaymortality)\n\n### 1. Frame the Problem\n\n-   Target variable: thirtydaymortality\n\n-   Type: Classification Problem\n\n-   Binary Outcome: (No,Yes)\n\n### 2. Data sensing, preprocessing:\n\n-   `Feature Selection:` Exclusion of variables that deomonstrates high redundancy or Multicollinearity with thirtydaymortality:\n\n    -   \\@30daymortality\n\n    -   mortality\n\n    -   daysbetweendeathandoperation\n\n::: {#57df2811 .cell execution_count=17}\n``` {.python .cell-code}\n# Feature Selection:\n# drop unecessary columns, features that occur only after the target result should be excluded\nfeatures_to_exclude = ['mortality', 'daysbetweendeathandoperation', '@30daymortality']\ndf = df.drop(columns=features_to_exclude)\n```\n:::\n\n\n### 3. Data Wrangling, Transformation:\n\nNumerical features Transformation:\n\n-   Test for normality of numeric columns: ALL are not normally distributed\n\n-   DIstribution transfomation for columns\n\n-   Distribution normalisation and standardisation for columns\n\nCateogorical features Transformation:\n\n-   One-hot encoding to ensure smooth usage by tree learning algorithms\n\n#### Numerical features Transformation\n\n##### Test for Normality\n\n::: {#3d1b0553 .cell execution_count=18}\n``` {.python .cell-code}\n# Test for normality of numeric columns: ALL are not normally distributed\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n# Define specific numeric columns for imputation\nnumeric_cols = [col for col in numeric_columns if col != 'daysbetweendeathandoperation']\nprint(\"Numeric columns:\", list(numeric_cols))\n\n# Function to test for normal distribution\ndef test_normal_distribution(data, alpha=0.05):\n    \"\"\"\n    Test if the data follows a normal distribution.\n    \"\"\"\n    shapiro_stat, shapiro_p = stats.shapiro(data)\n    ks_stat, ks_p = stats.kstest(data, 'norm', args=(np.mean(data), np.std(data, ddof=0)))\n\n    print(f\"Shapiro-Wilk: Statistic={shapiro_stat:.3f}, p-value={shapiro_p:.3f}\")\n    print(f\"Kolmogorov-Smirnov: Statistic={ks_stat:.3f}, p-value={ks_p:.3f}\")\n    print(\"Normally distributed:\" if shapiro_p > alpha and ks_p > alpha else \"Not normally distributed.\")\n    print()\n\n# Test normal distribution\nprint(\"Testing Normal Distribution:\")\nfor col in numeric_cols:\n    print(f\"{col}:\")\n    test_normal_distribution(df[col])\n\ndef create_qq_plots(columns):\n    # Number of columns to plot\n    num_cols = len(columns)\n\n    # Determine grid size for subplots\n    n_cols = 3  # Number of columns in the subplot grid\n    n_rows = (num_cols + n_cols - 1) // n_cols  # Calculate number of rows needed\n\n    # Create subplots\n    plt.figure(figsize=(15, 5 * n_rows))  # Adjust figure size as needed\n\n    for i, col in enumerate(columns, 1):\n        plt.subplot(n_rows, n_cols, i)\n        stats.probplot(df[col].dropna(), dist=\"norm\", plot=plt)\n        plt.title(f'Q-Q Plot of {col}')\n        plt.xlabel('Theoretical Quantiles')\n        plt.ylabel('Sample Quantiles')\n\n    plt.tight_layout()\n    plt.show()\n\n# Create Q-Q plots for numeric columns\ncreate_qq_plots(numeric_cols)\n```\n:::\n\n\n![](images/clipboard-1338966806.png)\n\n![](images/clipboard-1362939341.png)\n\n##### Distribution of numeric columns\n\n::: {#73a77346 .cell execution_count=19}\n``` {.python .cell-code}\ndef create_histograms(df,columns):\n    # Number of columns to plot\n    num_cols = len(columns)\n\n    # Determine grid size for subplots\n    n_cols = 3  # Number of columns in the subplot grid\n    n_rows = (num_cols + n_cols - 1) // n_cols  # Calculate number of rows needed\n\n    # Create subplots\n    plt.figure(figsize=(15, 5 * n_rows))  # Adjust figure size as needed\n\n    for i, col in enumerate(columns, 1):\n        plt.subplot(n_rows, n_cols, i)\n        sns.histplot(df[col].dropna(), kde=True, bins=30)  # Adjust bins as needed\n        plt.title(f'Distribution of {col}')\n        plt.xlabel(col)\n        plt.ylabel('Frequency')\n\n    plt.tight_layout()\n    plt.show()\n\n\n# Create histograms for numeric columns\ncreate_histograms(df,numeric_cols)\n```\n:::\n\n\n![](images/clipboard-4289095336.png)\n\n##### Automation of transforming numeric columns based on skewness\n\n::: {#45285570 .cell execution_count=20}\n``` {.python .cell-code}\ndef calculate_skewness(df,columns):\n    # Dictionary to store skewness values\n    skewness_dict = {}\n\n    for col in columns:\n        # Drop NaN values for skewness calculation, there shouldn't be any left\n        data = df[col].dropna()\n\n        # Calculate skewness\n        skew_value = skew(data, nan_policy='omit')  # nan_policy='omit' ignores NaN values\n        skewness_dict[col] = skew_value\n\n    # Convert skewness dictionary to DataFrame for better readability\n    skewness_df = pd.DataFrame(list(skewness_dict.items()), columns=['Column', 'Skewness'])\n    return skewness_df\n\n\n# Calculate skewness for numeric columns\nskewness_df = calculate_skewness(df,numeric_cols)\n\n# Print skewness values\nprint(\"Skewness of Numeric Columns:\")\nprint(skewness_df)\n\n\n\ndef transform_based_on_skewness(df, columns):\n    transformed_df = df.copy()\n    new_columns_numeric = []\n    column_mapping = {}\n\n    for col in columns:\n        # Calculate skewness\n        skewness = skew(df[col].dropna(), nan_policy='omit')\n\n        # Initialize new_col to None\n        new_col = None\n\n        # Print the skewness for debugging\n        print(f\"Skewness for column {col}: {skewness}\")\n\n        # Choose transformation based on skewness\n        if skewness > 1:\n            # Highly positively skewed\n            if (transformed_df[col] > 0).all():  # Check if all values are positive\n                new_col = col + '_log'\n                transformed_df[new_col] = np.log1p(df[col])\n                print(f\"Applied log transformation on column {col}\")\n            else:\n                # Use Yeo-Johnson if data contains zero or negative values\n                new_col = col + '_yeojohnson'\n                pt = PowerTransformer(method='yeo-johnson')\n                transformed_df[new_col] = pt.fit_transform(df[[col]])\n                print(f\"Applied Yeo-Johnson transformation on column {col}\")\n\n        elif skewness > 0.5:\n            # Moderately positively skewed\n            new_col = col + '_sqrt'\n            transformed_df[new_col] = np.sqrt(df[col] + 1)  # Adding 1 to handle zero values\n            print(f\"Applied square root transformation on column {col}\")\n\n        elif skewness < -1:\n            # Highly negatively skewed\n            new_col = col + '_inv'\n            transformed_df[new_col] = 1 / (df[col] + 1)  # Adding 1 to avoid division by zero\n            print(f\"Applied inverse transformation on column {col}\")\n\n        elif skewness < -0.5:\n            # Moderately negatively skewed\n            new_col = col + '_inv_sqrt'\n            transformed_df[new_col] = 1 / np.sqrt(df[col] + 1)  # Adding 1 to handle zero values\n            print(f\"Applied inverse square root transformation on column {col}\")\n\n        else:\n            # Data is close to normal, no transformation needed\n            new_col = col + '_no_transform'\n            transformed_df[new_col] = df[col]\n\n       \n        if new_col:\n            new_columns_numeric.append(new_col)\n            column_mapping[col] = new_col\n\n    return transformed_df, new_columns_numeric, column_mapping\n\n# Example usage\n# Assuming df is your DataFrame\nnumeric_cols = ['age', 'rcri_score', 'preopegfrmdrd', 'preoptransfusionwithin30days',\n                'intraop', 'postopwithin30days', 'transfusionintraandpostop']\n\n# Apply transformations based on skewness\ntransformed_df, new_columns_numeric, column_mapping = transform_based_on_skewness(df, numeric_cols)\n\n\n# Print the first few rows of the transformed DataFrame to verify\nprint(transformed_df.head())\n# Print the list of newly transformed columns\nprint(new_columns_numeric)\n\n# Verify the columns are indeed in the DataFrame\nfor col in new_columns_numeric:\n    if col in transformed_df.columns:\n        print(f\"Column {col} exists in the DataFrame.\")\n    else:\n        print(f\"Column {col} does NOT exist in the DataFrame.\")\n\n\n\n# Create histograms for newly transformed columns\ncreate_histograms(transformed_df,new_columns_numeric)\n\n```\n:::\n\n\n![](images/clipboard-1165382113.png)\n\n![](images/clipboard-2447623812.png)\n\n![](images/clipboard-917996487.png)\n\n##### Comparison of newly transformed variables as compared to orignal in terms of skewness\n\n::: {#eb910469 .cell execution_count=21}\n``` {.python .cell-code}\n# Calculate skewness for original columns\nskewness_original = calculate_skewness(df,numeric_cols).set_index('Column')['Skewness'].to_dict()\n\n# Calculate skewness for transformed columns\nskewness_transformed = calculate_skewness(transformed_df,new_columns_numeric).set_index('Column')['Skewness'].to_dict()\n\n# Print column mapping\nprint(\"Column Mapping:\")\nprint(column_mapping)\n\n\n# Print skewness values\nprint(\"Skewness of Numeric Columns:\")\nprint(skewness_df)\nprint(skewness_transformed)\n\n# Print column mapping\nprint (column_mapping)\n\n# Create a comparison DataFrame\ncomparison_df = pd.DataFrame({\n    'Original Column': numeric_cols,\n    'Original Skewness': [skewness_original[col] for col in numeric_cols],\n    'Transformed Column': [column_mapping[col] if col in column_mapping else col + '_no_transform' for col in numeric_cols],\n    'Transformed Skewness': [skewness_transformed[column_mapping[col]] if col in column_mapping else skewness_original[col] for col in numeric_cols]\n})\n\n# Add a column to indicate if skewness has decreased\ncomparison_df['Skewness Decreased'] = abs(comparison_df['Original Skewness']) > abs(comparison_df['Transformed Skewness'])\n\nprint(\"Skewness Comparison:\")\ncomparison_df\n```\n:::\n\n\n![](images/clipboard-2181277663.png)\n\n##### Standardize all newly transformed columns\n\n::: {#274413dd .cell execution_count=22}\n``` {.python .cell-code}\nstd_scaler = StandardScaler()\ntransformed_df[new_columns_numeric] = std_scaler.fit_transform(transformed_df[new_columns_numeric])\n```\n:::\n\n\n#### Categorical features processing: One- hot encoding all features\n\n::: {#77ba537c .cell execution_count=23}\n``` {.python .cell-code}\n# List all categorical columns in the DataFrame\ncategorical_columns  = transformed_df.select_dtypes(include=['object']).columns\n\n# Columns to exclude (make sure names match exactly)\nexclude_columns = ['mortality', 'daysbetweendeathandoperation', '@30daymortality', 'thirtydaymortality']\n\n# Filter out the excluded columns from the list of categorical columns\ncategorical_columns = [col for col in categorical_columns if col not in exclude_columns]\n\n# One-hot encode categorical columns\none_hot_ed = pd.get_dummies(transformed_df[categorical_columns],drop_first=True)\n\n# Concatenate the one-hot encoded columns with the original DataFrame\ntransformed_df = pd.concat([transformed_df, one_hot_ed], axis=1)\n```\n:::\n\n\n#### Final Cleaning and Consolidation of Processed Numerical and Categorical columns\n\n::: {#4d5c7541 .cell execution_count=24}\n``` {.python .cell-code}\n# Drop the original categorical columns\ntransformed_df.drop(categorical_columns, axis=1, inplace=True)\n# Drop the original numeric columns\ntransformed_df.drop(numeric_cols, axis=1, inplace=True)\n```\n:::\n\n\n::: {#4780a879 .cell execution_count=25}\n``` {.python .cell-code}\ntransformed_df.info()\n```\n:::\n\n\n![](images/clipboard-3862374559.png)![](images/clipboard-3784664671.png)\n\n### 4. In-depth analysis: Satistical modelling / Machine Learning\n\n#### Multivariate Analysis\n\n::: {#3b705ef4 .cell execution_count=26}\n``` {.python .cell-code}\nclass MultivariateAnalysis:\n    def __init__(self, transformed_df, target_variable, vif_threshold=10, corr_threshold=0.8):\n        self.df = transformed_df\n        self.target_variable = target_variable\n        self.vif_threshold = vif_threshold\n        self.corr_threshold = corr_threshold\n        \n        # Drop target variable for analysis\n        self.features_df = self.df.drop(columns=[self.target_variable])\n\n    def preprocess_data(self):\n        # Convert Boolean columns to numeric\n        bool_cols = self.features_df.select_dtypes(include=['bool']).columns\n        self.features_df[bool_cols] = self.features_df[bool_cols].astype(int)\n\n    def plot_correlation_heatmap(self, high_corr_vars):\n        plt.figure(figsize=(20, 20))\n        corr = self.features_df[high_corr_vars].corr()\n        ax = sns.heatmap(corr, annot=True, fmt='.2g', vmin=-1, vmax=1, center=0,\n                         cmap='coolwarm_r', linecolor='black', linewidth=1, annot_kws={\"size\": 12})\n        ax.set_ylim(len(corr), 0)\n        plt.xticks(rotation=45, ha='right')\n        plt.title('Correlation Heatmap of High Correlation Variables')\n        plt.show()\n\n    def calculate_vif(self, df):\n        # Ensure only numeric columns are used\n        numeric_df = df.select_dtypes(include=['float64', 'int64'])\n        if numeric_df.empty:\n            raise ValueError(\"DataFrame contains no numeric columns.\")\n        \n        # Add constant to the feature set for VIF calculation\n        numeric_df_with_const = add_constant(numeric_df, has_constant='add')\n        vif_data = pd.DataFrame()\n        vif_data[\"Variable\"] = numeric_df_with_const.columns\n        vif_data[\"VIF\"] = [variance_inflation_factor(numeric_df_with_const.values, i) \n                           for i in range(numeric_df_with_const.shape[1])]\n        return vif_data\n\n    def plot_vif(self, vif_data):\n        plt.figure(figsize=(10, 6))\n        sns.barplot(x=\"VIF\", y=\"Variable\", data=vif_data.sort_values(\"VIF\", ascending=False))\n        plt.title('Variance Inflation Factor (VIF)')\n        plt.show()\n\n    def identify_high_corr_pairs(self):\n        corr_matrix = self.features_df.corr().abs()\n        high_corr_pairs = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n                           .stack()\n                           .reset_index()\n                           .rename(columns={0: 'correlation', 'level_0': 'feature1', 'level_1': 'feature2'}))\n        high_corr_pairs = high_corr_pairs[high_corr_pairs['correlation'] > self.corr_threshold]\n        return high_corr_pairs\n\n    def drop_high_corr_vars(self, high_corr_pairs):\n        to_drop = set()\n        for _, row in high_corr_pairs.iterrows():\n            if row['feature1'] in to_drop or row['feature2'] in to_drop:\n                continue\n            feature1_corr_sum = self.features_df.corr()[row['feature1']].abs().sum()\n            feature2_corr_sum = self.features_df.corr()[row['feature2']].abs().sum()\n            if feature1_corr_sum > feature2_corr_sum:\n                to_drop.add(row['feature1'])\n            else:\n                to_drop.add(row['feature2'])\n        self.features_df.drop(columns=to_drop, inplace=True)\n        return to_drop\n\n    def run_analysis(self):\n        # Preprocess data to include Boolean columns as numeric\n        self.preprocess_data()\n        \n        # Identify and drop high correlation variables\n        high_corr_pairs = self.identify_high_corr_pairs()\n        dropped_corr_vars = self.drop_high_corr_vars(high_corr_pairs)\n        \n        # Plot correlation heatmap for remaining variables\n        if not high_corr_pairs.empty:\n            high_corr_vars = list(set(high_corr_pairs['feature1']).union(set(high_corr_pairs['feature2'])))\n            high_corr_vars = [var for var in high_corr_vars if var in self.features_df.columns]\n            self.plot_correlation_heatmap(high_corr_vars)\n        \n        # Calculate and plot VIF\n        vif_data = self.calculate_vif(self.features_df)\n        print(\"Original VIF Data:\")\n        print(vif_data)\n        \n        # Variables to keep for VIF reporting\n        high_vif_vars = vif_data[vif_data[\"VIF\"] > self.vif_threshold]\n        \n        # Print table for high VIF variables\n        if not high_vif_vars.empty:\n            print(\"\\nVariables with high VIF:\")\n            print(high_vif_vars)\n        else:\n            print(\"\\nNo variables exceed the VIF threshold.\")\n\n        # Drop variables with high VIF\n        reduced_df = self.features_df.drop(columns=high_vif_vars['Variable'], errors='ignore')\n        \n        # Recalculate VIF on reduced dataset\n        reduced_vif_data = self.calculate_vif(reduced_df)\n        print(\"\\nNew VIF Data after dropping high VIF variables:\")\n        print(reduced_vif_data)\n        \n        # Plot new VIF\n        self.plot_vif(reduced_vif_data)\n        \n        # Add target variable back to reduced_df\n        reduced_df[self.target_variable] = self.df[self.target_variable]\n        \n        return reduced_df, dropped_corr_vars, high_vif_vars, reduced_vif_data\n\n# Example usage\n# transformed_df is your DataFrame and 'target' is your target variable\nma = MultivariateAnalysis(transformed_df, target_variable='thirtydaymortality', corr_threshold=0.6)\nreduced_df, dropped_corr_vars, high_vif_vars, new_vif = ma.run_analysis()\n```\n:::\n\n\n![](images/clipboard-3373007464.png)\n\n![](images/clipboard-1693251949.png)\n\n![](images/clipboard-1846959993.png)\n\n![](images/clipboard-2809728910.png)\n\n#### Machine Learning (Individual Models)\n\nnot needed here, we will proceed straight to AutoML with the models\n\n### 5. Comparison and Evaluation: Automate the evaluation process\n\nAutomate the model training and evaluation process, and generate comprehensive results and key evaluation reports to assess the validity and effectiveness of the chosen model.\n\n::: {#54af5a7d .cell execution_count=27}\n``` {.python .cell-code}\nclass BaseModel:\n    def __init__(self, cleaned_df, target_column, balance='imbalanced', n_splits=5, n_repeats=3, random_state=123):\n        self.df = cleaned_df\n        self.target_column = target_column\n        self.balance = balance\n        self.n_splits = n_splits\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n\n        # Prepare features and target variable\n        self.X = self.df.drop(columns=[self.target_column])\n        self.y = self.df[self.target_column]\n\n        \n        # Label encode the target variable\n        label_encoder = LabelEncoder()\n        self.y = label_encoder.fit_transform(self.y)\n\n\n        # Split the data into training and test sets\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n            self.X, self.y, test_size=0.3, random_state=self.random_state\n        )\n\n        # Initialize SMOTEENN if balance is set to 'imbalanced'\n        if self.balance == 'imbalanced':\n            self.smoteenn = SMOTEENN(sampling_strategy='auto', random_state=self.random_state)\n        else:\n            self.smoteenn = None\n\n    def apply_smoteenn(self):\n        if self.smoteenn:\n            return self.smoteenn.fit_resample(self.X_train, self.y_train)\n        else:\n            return self.X_train, self.y_train\n\n    def show_matrix(self, matrix, title='Confusion Matrix'):\n        # Plotting the confusion matrix\n        plt.figure(figsize=(6, 5))\n        sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=True, yticklabels=True)\n        plt.title(title)\n        plt.ylabel('Actual Class')\n        plt.xlabel('Predicted Class')\n        plt.show()\n\n    def plot_roc_auc(self, y_true, y_pred, title):\n        fpr, tpr, _ = roc_curve(y_true, y_pred)\n        roc_auc = auc(fpr, tpr)\n        plt.figure()\n        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(title)\n        plt.legend(loc=\"lower right\")\n        plt.show()\n\nclass DT(BaseModel):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.clf = DecisionTreeClassifier()\n\n    def run_bayesian_search(self):\n        print(\"\\nRunning Bayesian Search for Decision Tree...\")\n        # Define the parameter space\n        search_spaces = {\n            'max_features': Categorical(['sqrt', 'log2']),\n            'ccp_alpha': Real(0.001, 0.1, prior='log-uniform'),\n            'max_depth': Integer(20, 30),\n            'criterion': Categorical(['gini', 'entropy']),\n            'min_samples_split': Integer(2, 4),\n            'min_samples_leaf': Integer(2, 4)\n        }\n\n        # Initialize BayesSearchCV\n        cv = RepeatedStratifiedKFold(n_splits=self.n_splits, n_repeats=self.n_repeats, random_state=self.random_state)\n        bayes_search = BayesSearchCV(estimator=self.clf, search_spaces=search_spaces, cv=cv, n_iter=10, scoring='accuracy', random_state=self.random_state, verbose=1, n_jobs=-1)\n        \n        # Apply SMOTEENN to the training data if balance is 'imbalanced'\n        X_resampled, y_resampled = self.apply_smoteenn()\n\n        # Fit BayesSearchCV with the resampled data\n        t0 = time.time()\n        bayes_result = bayes_search.fit(X_resampled, y_resampled)\n        print(f'\\nTime taken = {round(time.time() - t0, 2)} sec')\n\n        # Print best score and parameters\n        print(f'Best score = {round(bayes_result.best_score_, 3)} using params: {bayes_result.best_params_}')\n\n        # Evaluate on test data\n        y_pred = bayes_result.best_estimator_.predict(self.X_test)\n        accuracy = accuracy_score(self.y_test, y_pred)\n        print(f'Test accuracy = {round(accuracy, 3)}')\n\n        return bayes_result, y_pred\n\nclass RandomForest(BaseModel):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.clf = RandomForestClassifier()\n\n    def run_bayesian_search(self):\n        print(\"\\nRunning Bayesian Search for Random Forest...\")\n        # Define the parameter space\n        search_spaces = {\n            'n_estimators': Integer(80, 150),\n            'max_features': Categorical(['sqrt', 'log2']),\n            'max_depth': Integer(20, 30),\n            'criterion': Categorical(['gini', 'entropy']),\n            'min_samples_split': Integer(2, 4),\n            'min_samples_leaf': Integer(2, 4)\n        }\n\n        # Initialize BayesSearchCV\n        cv = RepeatedStratifiedKFold(n_splits=self.n_splits, n_repeats=self.n_repeats, random_state=self.random_state)\n        bayes_search = BayesSearchCV(estimator=self.clf, search_spaces=search_spaces, cv=cv, n_iter=10, scoring='accuracy', random_state=self.random_state, verbose=1, n_jobs=-1)\n        \n        # Apply SMOTEENN to the training data if balance is 'imbalanced'\n        X_resampled, y_resampled = self.apply_smoteenn()\n\n        # Fit BayesSearchCV with the resampled data\n        t0 = time.time()\n        bayes_result = bayes_search.fit(X_resampled, y_resampled)\n        print(f'\\nTime taken = {round(time.time() - t0, 2)} sec')\n\n        # Print best score and parameters\n        print(f'Best score = {round(bayes_result.best_score_, 3)} using params: {bayes_result.best_params_}')\n\n        # Evaluate on test data\n        y_pred = bayes_result.best_estimator_.predict(self.X_test)\n        accuracy = accuracy_score(self.y_test, y_pred)\n        print(f'Test accuracy = {round(accuracy, 3)}')\n\n        return bayes_result, y_pred\n\nclass XGBoost(BaseModel):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n    def run_bayesian_search(self):\n        print(\"\\nRunning Bayesian Search for XGBoost...\")\n        # Define the parameter space\n        search_spaces = {\n            'n_estimators': Integer(80, 150),\n            'max_depth': Integer(20, 30),\n            'learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n            'subsample': Real(0.5, 1.0),\n            'colsample_bytree': Real(0.5, 1.0)\n        }\n\n        # Initialize BayesSearchCV\n        cv = RepeatedStratifiedKFold(n_splits=self.n_splits, n_repeats=self.n_repeats, random_state=self.random_state)\n        bayes_search = BayesSearchCV(estimator=self.clf, search_spaces=search_spaces, cv=cv, n_iter=10, scoring='accuracy', random_state=self.random_state, verbose=1, n_jobs=-1)\n        \n        # Apply SMOTEENN to the training data if balance is 'imbalanced'\n        X_resampled, y_resampled = self.apply_smoteenn()\n\n        # Fit BayesSearchCV with the resampled data\n        t0 = time.time()\n        bayes_result = bayes_search.fit(X_resampled, y_resampled)\n        print(f'\\nTime taken = {round(time.time() - t0, 2)} sec')\n\n        # Print best score and parameters\n        print(f'Best score = {round(bayes_result.best_score_, 3)} using params: {bayes_result.best_params_}')\n\n        # Evaluate on test data\n        y_pred = bayes_result.best_estimator_.predict(self.X_test)\n        accuracy = accuracy_score(self.y_test, y_pred)\n        print(f'Test accuracy = {round(accuracy, 3)}')\n\n        return bayes_result, y_pred\n\nclass LightGBM(BaseModel):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.clf = LGBMClassifier()\n\n    def run_bayesian_search(self):\n        print(\"\\nRunning Bayesian Search for LightGBM...\")\n        # Define the parameter space\n        search_spaces = {\n            'n_estimators': Integer(80, 150),\n            'max_depth': Integer(20, 30),\n            'learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n            'subsample': Real(0.5, 1.0),\n            'colsample_bytree': Real(0.5, 1.0)\n        }\n\n        # Initialize BayesSearchCV\n        cv = RepeatedStratifiedKFold(n_splits=self.n_splits, n_repeats=self.n_repeats, random_state=self.random_state)\n        bayes_search = BayesSearchCV(estimator=self.clf, search_spaces=search_spaces, cv=cv, n_iter=10, scoring='accuracy', random_state=self.random_state, verbose=1, n_jobs=-1)\n        \n        # Apply SMOTEENN to the training data if balance is 'imbalanced'\n        X_resampled, y_resampled = self.apply_smoteenn()\n\n        # Fit BayesSearchCV with the resampled data\n        t0 = time.time()\n        bayes_result = bayes_search.fit(X_resampled, y_resampled)\n        print(f'\\nTime taken = {round(time.time() - t0, 2)} sec')\n\n        # Print best score and parameters\n        print(f'Best score = {round(bayes_result.best_score_, 3)} using params: {bayes_result.best_params_}')\n\n        # Evaluate on test data\n        y_pred = bayes_result.best_estimator_.predict(self.X_test)\n        accuracy = accuracy_score(self.y_test, y_pred)\n        print(f'Test accuracy = {round(accuracy, 3)}')\n\n        return bayes_result, y_pred\n\nclass AutoML:\n    def __init__(self, cleaned_df, target_column, balance='imbalanced', n_splits=5, n_repeats=3, random_state=123, secondary_metric='precision'):\n        self.cleaned_df = cleaned_df\n        self.target_column = target_column\n        self.balance = balance\n        self.n_splits = n_splits\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        self.secondary_metric = secondary_metric\n        \n        # Initialize model classes\n        self.models = {\n            'DecisionTree': DT(cleaned_df, target_column, balance, n_splits, n_repeats, random_state),\n            'RandomForest': RandomForest(cleaned_df, target_column, balance, n_splits, n_repeats, random_state),\n            'XGBoost': XGBoost(cleaned_df, target_column, balance, n_splits, n_repeats, random_state),\n            'LightGBM': LightGBM(cleaned_df, target_column, balance, n_splits, n_repeats, random_state)\n        }\n\n    def evaluate_models(self):\n        results = {}\n        for name, model in self.models.items():\n            print(f'\\nEvaluating {name}...')\n            best_model, y_pred = model.run_bayesian_search()\n            \n            # Compute metrics\n            accuracy = accuracy_score(model.y_test, y_pred)\n            precision = precision_score(model.y_test, y_pred, average='weighted')\n            recall = recall_score(model.y_test, y_pred, average='weighted')\n            f1 = 2 * (precision * recall) / (precision + recall)\n            \n            results[name] = {\n                'accuracy': accuracy,\n                'precision': precision,\n                'recall': recall,\n                'f1': f1,\n                'classification_report': classification_report(model.y_test, y_pred),\n                'confusion_matrix': model.show_matrix(confusion_matrix(model.y_test, y_pred))\n            }\n            \n            # Print Classification Report and Confusion Matrix\n            print(f'Classification Report for {name}:\\n{results[name][\"classification_report\"]}')\n            \n            # ROC and AUC\n            y_test_binarized = label_binarize(model.y_test, classes=np.unique(model.y_test))\n            y_pred_binarized = label_binarize(y_pred, classes=np.unique(model.y_test))\n            if y_test_binarized.shape[1] > 1:\n                for i in range(y_test_binarized.shape[1]):\n                    model.plot_roc_auc(y_test_binarized[:, i], y_pred_binarized[:, i], f'{name} ROC Curve for Class {i}')\n            \n        # Determine the best model\n        sorted_results = sorted(results.items(), key=lambda x: (x[1]['accuracy'], x[1][self.secondary_metric]), reverse=True)\n        best_model_name, best_model_metrics = sorted_results[0]\n        print(f'\\nBest Model: {best_model_name}')\n        print(f'Accuracy: {best_model_metrics[\"accuracy\"]}')\n        print(f'{self.secondary_metric.capitalize()}: {best_model_metrics[self.secondary_metric]}')\n        \n        return best_model_name, best_model_metrics\n\n# Example usage\n# Assuming `transformed_df` is your DataFrame and 'thirtydaymortality' is your target column\nauto_ml = AutoML(reduced_df, target_column='thirtydaymortality', balance='imbalanced', secondary_metric='recall')\nbest_model_name, best_model_metrics = auto_ml.evaluate_models()\n\nprint(f'\\nBest Model: {best_model_name}')\nprint(f'Accuracy: {best_model_metrics[\"accuracy\"]}')\nprint(f'Precision: {best_model_metrics[\"precision\"]}')\nprint(f'Recall: {best_model_metrics[\"recall\"]}')\nprint(f'F1 Score: {best_model_metrics[\"f1\"]}')\nprint(f'Confusion Matrix:\\n{best_model_metrics[\"confusion_matrix\"]}')\n```\n:::\n\n\nEvaluating DecisionTree...\n\nTime taken = 38.33 sec\n\nBest score = 0.882 using params: OrderedDict(\\[('ccp_alpha', 0.001131086677421503), ('criterion', 'entropy'), ('max_depth', 24), ('max_features', 'log2'), ('min_samples_leaf', 3), ('min_samples_split', 3)\\])\\\n**Test accuracy = [0.85]{.underline}**\n\n![](images/clipboard-59382711.png)\n\n![](images/clipboard-3531112163.png)\n\nEvaluating RandomForest...\n\nTime taken = 891.38 sec Best score = 0.97 using params: OrderedDict(\\[('criterion', 'entropy'), ('max_depth', 27), ('max_features', 'sqrt'), ('min_samples_leaf', 2), ('min_samples_split', 3), ('n_estimators', 82)\\]) **Test accuracy = [0.956]{.underline}**\n\n![](images/clipboard-2689837012.png)\n\n![](images/clipboard-925563829.png)\n\nEvaluating XGBoost\n\nTime taken = 487.2 sec Best score = 0.973 using params: OrderedDict(\\[('colsample_bytree', 0.8636816590466002), ('learning_rate', 0.0645354435221669), ('max_depth', 29), ('n_estimators', 108), ('subsample', 0.9220560088509978)\\]) **Test accuracy = 0.952**\n\n![](images/clipboard-388346725.png)\n\n![](images/clipboard-1451616604.png)\n\nEvaluating LightGBM...\n\nTime taken = 230.12 sec Best score = 0.958 using params: OrderedDict(\\[('colsample_bytree', 0.5133739717626367), ('learning_rate', 0.1941545477346783), ('max_depth', 24), ('n_estimators', 131), ('subsample', 0.8487299825534435)\\]) **Test accuracy = 0.941**\n\n![![](images/clipboard-433414607.png)](images/clipboard-2732899064.png)\n\n[**Best Model: RandomForest**]{.underline}\n\nAccuracy: 0.9561266060795989\n\nRecall: 0.9561266060795989\n\n[**Best Model: RandomForest**]{.underline}\n\nAccuracy: 0.9561266060795989\n\nPrecision: 0.9905793259715808\n\nRecall: 0.9561266060795989\n\nF1 Score: 0.9730480946301695\n\n[**Future Work**]{.underline}\n\nI'm intending to make some changes to choose model based on having least number of false negatives.\n\n",
    "supporting": [
      "AutoML_Binary_Classification_files"
    ],
    "filters": [],
    "includes": {}
  }
}